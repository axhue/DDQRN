{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN from openAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T19:19:00.825269Z",
     "start_time": "2017-12-05T19:16:56.950397Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"d2066554-a04d-401e-aeee-df44db6b430c\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id !== undefined) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var element_id = msg.content.text.trim();\n",
       "            Bokeh.index[element_id].model.document.clear();\n",
       "            delete Bokeh.index[element_id];\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(`.${CLASS_NAME.split(' ')[0]}`);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[0].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[0].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[0]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"d2066554-a04d-401e-aeee-df44db6b430c\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"d2066554-a04d-401e-aeee-df44db6b430c\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'd2066554-a04d-401e-aeee-df44db6b430c' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.10.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"d2066554-a04d-401e-aeee-df44db6b430c\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"d2066554-a04d-401e-aeee-df44db6b430c\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"d2066554-a04d-401e-aeee-df44db6b430c\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'd2066554-a04d-401e-aeee-df44db6b430c' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.10.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"d2066554-a04d-401e-aeee-df44db6b430c\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import MalmoPython\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "from baselines import deepq\n",
    "from baselines import logger\n",
    "from baselines.deepq.replay_buffer import ReplayBuffer\n",
    "from baselines.common.schedules import LinearSchedule\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as layers\n",
    "import baselines.common.tf_util as U\n",
    "\n",
    "\n",
    "from IPython.display import clear_output,display\n",
    "import numpy as np\n",
    "\n",
    "from keras import backend as Kend\n",
    "from keras.layers import GRU,Dense,Activation,Input,LSTM\n",
    "from keras.models import Sequential\n",
    "\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import output_notebook, push_notebook, show\n",
    "from bokeh.driving import linear\n",
    "from bokeh.layouts import row,gridplot\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T19:39:50.471110Z",
     "start_time": "2017-12-05T19:39:29.688162Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pdb;\n",
    "import scipy.misc as scimisc\n",
    "\n",
    "from tkinter import *\n",
    "from PIL import Image\n",
    "from PIL import ImageTk\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.animation as animation\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T19:40:29.305647Z",
     "start_time": "2017-12-05T19:40:29.299046Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from baselines.acktr.utils import conv, fc, dense, conv_to_fc, sample, kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T19:19:02.921995Z",
     "start_time": "2017-12-05T19:19:00.863711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 2110787999399032106\n",
      ", name: \"/gpu:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11324823962\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 18147453029250201654\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T19:19:11.902994Z",
     "start_time": "2017-12-05T19:19:10.462975Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Env:\n",
    "    def __init__(self,actions,obs_shape,grid_shape,scale = 1/12):\n",
    "        self.world_state = None\n",
    "        self.my_mission_record = MalmoPython.MissionRecordSpec()\n",
    "        self.data = None\n",
    "        #self.observation_space = np.zeros(shape=(obs_shape**2,))\n",
    "        self.obs_shape = obs_shape\n",
    "        \n",
    "\n",
    "        self.actions = actions\n",
    "        self.scale = scale\n",
    "        self.grid_shape = grid_shape\n",
    "        self.host = MalmoPython.AgentHost()\n",
    "        self.obs = None\n",
    "        try:\n",
    "            self.host.parse( sys.argv )\n",
    "        except RuntimeError as e:\n",
    "            print ('ERROR:',e)\n",
    "            print (self.host.getUsage())\n",
    "            if self.host.receivedArgument(\"help\"):\n",
    "                print (self.host.getUsage())\n",
    "                exit(0)\n",
    "    def _dist(self,x,y):\n",
    "        return np.sqrt(np.sum((x-y)**2))\n",
    "    \n",
    "    def waitForInitialState( self ):\n",
    "        '''Before a command has been sent we wait for an observation of the world and a frame.'''\n",
    "        # wait for a valid observation\n",
    "        world_state = self.host.peekWorldState()\n",
    "        while world_state.is_mission_running and all(e.text=='{}' for e in world_state.observations):\n",
    "            world_state = self.host.peekWorldState()\n",
    "        # wait for a frame to arrive after that\n",
    "        num_frames_seen = world_state.number_of_video_frames_since_last_state\n",
    "        while world_state.is_mission_running and world_state.number_of_video_frames_since_last_state == num_frames_seen:\n",
    "            world_state = self.host.peekWorldState()\n",
    "        world_state = self.host.getWorldState()\n",
    "\n",
    "        reward = 0\n",
    "        smaller = None\n",
    "        data = None\n",
    "        if world_state.is_mission_running:\n",
    "                \n",
    "            assert len(world_state.video_frames) > 0, 'No video frames!?'\n",
    "            \n",
    "            obs = json.loads( world_state.observations[-1].text )\n",
    "            frame = world_state.video_frames[-1]\n",
    "            reward,smaller,data,_ = self.process(world_state)\n",
    "            return reward,smaller,data,world_state\n",
    "        else:\n",
    "            return None\n",
    "    def waitForNextState( self ):\n",
    "        '''After each command has been sent we wait for the observation to change as expected and a frame.'''\n",
    "        # wait for the observation position to have changed\n",
    "        while True:\n",
    "            world_state = self.host.peekWorldState()\n",
    "            if not world_state.is_mission_running:\n",
    "                print('mission ended.')\n",
    "                break\n",
    "            if not all(e.text=='{}' for e in world_state.observations):\n",
    "                obs = json.loads( world_state.observations[-1].text )\n",
    "                break\n",
    "        # wait for the render position to have changed\n",
    "        while True:\n",
    "            world_state = self.host.peekWorldState()\n",
    "            if len(world_state.video_frames) > 0:\n",
    "                frame = world_state.video_frames[-1]\n",
    "                break\n",
    "            if not world_state.is_mission_running:\n",
    "                break\n",
    "\n",
    "        reward = 0\n",
    "        smaller = None\n",
    "        data = None\n",
    "        num_frames_before_get = len(world_state.video_frames)\n",
    "        world_state = self.host.getWorldState()\n",
    "\n",
    "        if world_state.is_mission_running:\n",
    "            assert len(world_state.video_frames) > 0, 'No video frames!?'\n",
    "            num_frames_after_get = len(world_state.video_frames)\n",
    "            assert num_frames_after_get >= num_frames_before_get, 'Fewer frames after getWorldState!?'\n",
    "            frame = world_state.video_frames[-1]\n",
    "            reward,smaller,data,_ = self.process(world_state)\n",
    "        return reward,smaller,data,world_state\n",
    "    def process(self,world_state):\n",
    "        obs = json.loads( world_state.observations[-1].text )\n",
    "        reward = 1\n",
    "        if world_state.number_of_rewards_since_last_state > 0:\n",
    "            reward = world_state.rewards[0].getValue()\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        # reformat grid to a vector that only show the floor with blocks\n",
    "        vec = []    \n",
    "        for item in obs['grid'][::-1]:\n",
    "            if 'lava' in item:\n",
    "                vec.append(1)\n",
    "            elif 'lapis' in item:\n",
    "                vec.append(2)\n",
    "            else:\n",
    "                vec.append(0)\n",
    "\n",
    "        # read frame into numpy array (height,width,color(RGB))\n",
    "        frame = np.array(world_state.video_frames[-1].pixels).reshape(self.obs_shape)\n",
    "        \n",
    "        # grayscale\n",
    "        gray_frame = np.dot(frame[...,:3],[0.299,0.587,0.114]).reshape((self.obs_shape[0],self.obs_shape[1]))\n",
    "        \n",
    "        # scale down\n",
    "        # scimisc will output an array of type uint8 for further preprocessing the data needs to be casted to float\n",
    "        smaller = scimisc.imresize(gray_frame,1/12,mode='L').astype('float64')\n",
    "        smaller = np.expand_dims(smaller,2)\n",
    "        \n",
    "        # compute reward depending on distance to target\n",
    "        new_state = np.array(vec)\n",
    "        tmp = np.array(vec).reshape(self.grid_shape)\n",
    "        idx2 = np.argwhere(tmp == 2)\n",
    "        \n",
    "        size = self.grid_shape[0]\n",
    "        idx1 = (np.ceil(size/2),np.ceil(size/2))\n",
    "                     \n",
    "        a = (self._dist(idx2,idx1))\n",
    "        if(a > 0):\n",
    "            try:\n",
    "                dist_reward = 2000/(a)\n",
    "            except:\n",
    "                dist_reward = 0\n",
    "            reward += dist_reward\n",
    "            #print(\"close to objective reward : {}\".format(dist_reward))\n",
    "        return(reward,smaller,self.data,world_state) # return r,s,data,extra_info\n",
    "    \n",
    "    def observe(self,init=False):\n",
    "        if( init ):\n",
    "            tmp = self.waitForInitialState()\n",
    "            while(tmp == None):\n",
    "                tmp = self.waitForInitialState()\n",
    "            return tmp\n",
    "        else:\n",
    "            return self.waitForNextState()\n",
    "        # wait for the observation position to have changed\n",
    "        '''\n",
    "        while True:\n",
    "            world_state = self.host.peekWorldState()\n",
    "\n",
    "            if not all(e.text=='{}' for e in world_state.observations):\n",
    "                self.obs = json.loads( world_state.observations[-1].text )\n",
    "                break\n",
    "            if not world_state.is_mission_running:\n",
    "                break\n",
    "                \n",
    "        \n",
    "                # wait for the render position to have changed\n",
    "        while True:\n",
    "            world_state = self.host.peekWorldState()\n",
    "            if not world_state.is_mission_running:\n",
    "                break\n",
    "            if len(world_state.video_frames) > 0:\n",
    "                break\n",
    "        num_frames_before_get = len(world_state.video_frames)\n",
    "        world_state = self.host.getWorldState()\n",
    "        \n",
    "        if world_state.is_mission_running:\n",
    "            assert len(world_state.video_frames) > 0, 'No video frames!?'\n",
    "            num_frames_after_get = len(world_state.video_frames)\n",
    "            assert num_frames_after_get >= num_frames_before_get, 'Fewer frames after getWorldState!?'\n",
    "            frame = world_state.video_frames[-1]\n",
    "            self.obs = json.loads( world_state.observations[-1].text )\n",
    "        \n",
    "        self.obs = json.loads( world_state.observations[-1].text )\n",
    "        reward = 1\n",
    "        if world_state.number_of_rewards_since_last_state > 0:\n",
    "            reward = world_state.rewards[0].getValue()\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        # reformat grid to a vector that only show the floor with blocks\n",
    "        vec = []    \n",
    "        for item in self.obs['grid'][::-1]:\n",
    "            if 'lava' in item:\n",
    "                vec.append(1)\n",
    "            elif 'lapis' in item:\n",
    "                vec.append(2)\n",
    "            else:\n",
    "                vec.append(0)\n",
    "\n",
    "        # read frame into numpy array (height,width,color(RGB))\n",
    "        frame = np.array(world_state.video_frames[-1].pixels).reshape(self.obs_shape)\n",
    "        \n",
    "        # grayscale\n",
    "        gray_frame = np.dot(frame[...,:3],[0.299,0.587,0.114]).reshape((self.obs_shape[0],self.obs_shape[1]))\n",
    "        \n",
    "        # scale down\n",
    "        smaller = scimisc.imresize(gray_frame,1/12,mode='L')\n",
    "        smaller = np.expand_dims(smaller,2)\n",
    "    \n",
    "        # compute reward depending on distance to target\n",
    "        new_state = np.array(vec)\n",
    "        tmp = np.array(vec).reshape(self.grid_shape)\n",
    "        idx2 = np.argwhere(tmp == 2)\n",
    "        \n",
    "        size = self.grid_shape[0]\n",
    "        idx1 = (np.ceil(size/2),np.ceil(size/2))\n",
    "                     \n",
    "        a = (self._dist(idx2,idx1))\n",
    "        if(a > 0):\n",
    "            dist_reward = 2000 - a\n",
    "            reward += dist_reward\n",
    "            #print(\"close to objective reward : {}\".format(dist_reward))\n",
    "            \n",
    "    \n",
    "        \n",
    "        \n",
    "        return(reward,smaller,self.data,world_state) # return r,s,data,extra_info\n",
    "        '''\n",
    "    def startworld(self,world_file):\n",
    "        with open(world_file,'r') as f:\n",
    "            my_mission = MalmoPython.MissionSpec(f.read(), True)\n",
    "        my_mission_record = MalmoPython.MissionRecordSpec()\n",
    "        # Attempt to start a mission:\n",
    "        max_retries = 3\n",
    "        for retry in range(max_retries):\n",
    "            try:\n",
    "                self.host.startMission( my_mission, my_mission_record )\n",
    "                sys.stdout.write(\"Mission Started\")\n",
    "                break\n",
    "            except RuntimeError as e:\n",
    "                if retry == max_retries - 1:\n",
    "                    print (\"Error starting mission:{}\".format(e))\n",
    "                    exit(1)\n",
    "                else:\n",
    "                    time.sleep(2)\n",
    "        # Loop until mission starts:\n",
    "        #print (\"Waiting for the mission to start \")\n",
    "        self.world_state = self.host.getWorldState()\n",
    "        while (not self.world_state.has_mission_begun):\n",
    "            sys.stdout.write(\".\")\n",
    "            time.sleep(0.1)\n",
    "            self.world_state = self.host.getWorldState()\n",
    "            for error in self.world_state.errors:\n",
    "                print (\"Error:\",error.text)\n",
    "                \n",
    "        ## wait until a valid observation        \n",
    "        while self.world_state.is_mission_running and all(e.text=='{}' for e in self.world_state.observations):\n",
    "            self.world_state = self.host.peekWorldState()\n",
    "        #populate emtpy fields for init\n",
    "        self.data = json.loads(self.world_state.observations[-1].text)\n",
    "        \n",
    "        return self.observe(True)\n",
    "    def quit(self):\n",
    "        self.host.sendCommand('quit')\n",
    "        \n",
    "    def step(self,action):\n",
    "        self.host.sendCommand(self.actions[action])\n",
    "        return self.observe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T19:19:19.093940Z",
     "start_time": "2017-12-05T19:19:19.089164Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def update(x,y,handle,plot):\n",
    "    plot.data_source.data['x'] += [x]\n",
    "    plot.data_source.data['y'] += [y]\n",
    "    push_notebook(handle=handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T19:19:19.415796Z",
     "start_time": "2017-12-05T19:19:19.305096Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div class=\"bk-root\">\n",
       "    <div class=\"bk-plotdiv\" id=\"5bbfc45a-9ded-42b4-a65c-318b7b1dbf69\"></div>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    var docs_json = {\"aa17995b-e6ef-4b67-81a2-eb6428c14c13\":{\"roots\":{\"references\":[{\"attributes\":{\"source\":{\"id\":\"4b277ce5-94b0-419d-8b7b-12e0b7ae4a89\",\"type\":\"ColumnDataSource\"}},\"id\":\"ce085909-a4b1-4662-adb6-81ebaceeaf06\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"dd00aff6-bfe5-4e26-aba4-7c0aa4482afd\",\"type\":\"PanTool\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"x\",\"y\"],\"data\":{\"x\":[],\"y\":[]}},\"id\":\"4b277ce5-94b0-419d-8b7b-12e0b7ae4a89\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"below\":[{\"id\":\"ab4fadef-6227-4cf4-8731-40fdb6396c3d\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"b1e753c0-aecb-47e0-b074-48e18e76bcd2\",\"type\":\"LinearAxis\"}],\"plot_height\":400,\"plot_width\":400,\"renderers\":[{\"id\":\"ab4fadef-6227-4cf4-8731-40fdb6396c3d\",\"type\":\"LinearAxis\"},{\"id\":\"0e52b904-f61d-4d74-abed-8a323260a57f\",\"type\":\"Grid\"},{\"id\":\"b1e753c0-aecb-47e0-b074-48e18e76bcd2\",\"type\":\"LinearAxis\"},{\"id\":\"09e0d7b4-a9e1-459f-97a2-e3d8ded037fe\",\"type\":\"Grid\"},{\"id\":\"3cdde920-bd36-4e37-af21-e93be1474f64\",\"type\":\"BoxAnnotation\"},{\"id\":\"1410b58a-352f-4452-ae06-1bfbfccde8bb\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"7df53af4-4714-4da2-9f26-36fcecdc9e88\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"eedbdb84-09fd-4ddc-a2ed-b390939f16d1\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"327c1a23-c2c2-44e9-a19f-b2be73fe72db\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"c5982d4b-5129-40c5-915b-cceb601d1769\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"1907c14f-e174-42fb-956d-0bc6595a223c\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"c2240779-4040-4394-b8a3-69f35f6513a1\",\"type\":\"LinearScale\"}},\"id\":\"c44b4731-2e88-412e-931f-b7829cc5db53\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"9d266a57-7f01-45a8-b6cd-94f3ebe32056\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"a526faab-1467-4cf9-8271-b429b1288527\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"109eff80-0cdd-4d14-99d1-3b313aebe92a\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"data_source\":{\"id\":\"4b277ce5-94b0-419d-8b7b-12e0b7ae4a89\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"2c27c0ba-e377-42ab-a1fb-039767dbdb4a\",\"type\":\"Line\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"5ea51746-1dc8-4d9c-86e9-7f7a41d29554\",\"type\":\"Line\"},\"selection_glyph\":null,\"view\":{\"id\":\"ce085909-a4b1-4662-adb6-81ebaceeaf06\",\"type\":\"CDSView\"}},\"id\":\"1410b58a-352f-4452-ae06-1bfbfccde8bb\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"c5982d4b-5129-40c5-915b-cceb601d1769\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"e955e998-5f34-4411-807f-9f65d27a84c1\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"21dc9f4f-2af6-42ea-b0a5-b86feb198f49\",\"type\":\"SaveTool\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"dd00aff6-bfe5-4e26-aba4-7c0aa4482afd\",\"type\":\"PanTool\"},{\"id\":\"0ffc5730-c939-4ef4-9f4e-1df506884f61\",\"type\":\"WheelZoomTool\"},{\"id\":\"7c1c1311-e63b-46b1-a797-3008a9fc5af9\",\"type\":\"BoxZoomTool\"},{\"id\":\"21dc9f4f-2af6-42ea-b0a5-b86feb198f49\",\"type\":\"SaveTool\"},{\"id\":\"9d266a57-7f01-45a8-b6cd-94f3ebe32056\",\"type\":\"ResetTool\"},{\"id\":\"29bb6651-16ce-4aca-9461-1c90ffa7a043\",\"type\":\"HelpTool\"}]},\"id\":\"eedbdb84-09fd-4ddc-a2ed-b390939f16d1\",\"type\":\"Toolbar\"},{\"attributes\":{\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"line_width\":{\"value\":2},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"5ea51746-1dc8-4d9c-86e9-7f7a41d29554\",\"type\":\"Line\"},{\"attributes\":{\"line_color\":{\"value\":\"firebrick\"},\"line_width\":{\"value\":2},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"2c27c0ba-e377-42ab-a1fb-039767dbdb4a\",\"type\":\"Line\"},{\"attributes\":{\"callback\":null},\"id\":\"327c1a23-c2c2-44e9-a19f-b2be73fe72db\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"75f1c2f9-ad84-4cc0-87bc-b8816bc7f317\",\"type\":\"BasicTicker\"},{\"attributes\":{\"callback\":null},\"id\":\"1907c14f-e174-42fb-956d-0bc6595a223c\",\"type\":\"DataRange1d\"},{\"attributes\":{\"plot\":null,\"text\":\"rewards\"},\"id\":\"7df53af4-4714-4da2-9f26-36fcecdc9e88\",\"type\":\"Title\"},{\"attributes\":{\"axis_label\":\"x\",\"formatter\":{\"id\":\"e955e998-5f34-4411-807f-9f65d27a84c1\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"c44b4731-2e88-412e-931f-b7829cc5db53\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"75f1c2f9-ad84-4cc0-87bc-b8816bc7f317\",\"type\":\"BasicTicker\"}},\"id\":\"ab4fadef-6227-4cf4-8731-40fdb6396c3d\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"29bb6651-16ce-4aca-9461-1c90ffa7a043\",\"type\":\"HelpTool\"},{\"attributes\":{\"axis_label\":\"y\",\"formatter\":{\"id\":\"109eff80-0cdd-4d14-99d1-3b313aebe92a\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"c44b4731-2e88-412e-931f-b7829cc5db53\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"a526faab-1467-4cf9-8271-b429b1288527\",\"type\":\"BasicTicker\"}},\"id\":\"b1e753c0-aecb-47e0-b074-48e18e76bcd2\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"c2240779-4040-4394-b8a3-69f35f6513a1\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"0ffc5730-c939-4ef4-9f4e-1df506884f61\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"3cdde920-bd36-4e37-af21-e93be1474f64\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"c44b4731-2e88-412e-931f-b7829cc5db53\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"a526faab-1467-4cf9-8271-b429b1288527\",\"type\":\"BasicTicker\"}},\"id\":\"09e0d7b4-a9e1-459f-97a2-e3d8ded037fe\",\"type\":\"Grid\"},{\"attributes\":{\"overlay\":{\"id\":\"3cdde920-bd36-4e37-af21-e93be1474f64\",\"type\":\"BoxAnnotation\"}},\"id\":\"7c1c1311-e63b-46b1-a797-3008a9fc5af9\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"plot\":{\"id\":\"c44b4731-2e88-412e-931f-b7829cc5db53\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"75f1c2f9-ad84-4cc0-87bc-b8816bc7f317\",\"type\":\"BasicTicker\"}},\"id\":\"0e52b904-f61d-4d74-abed-8a323260a57f\",\"type\":\"Grid\"}],\"root_ids\":[\"c44b4731-2e88-412e-931f-b7829cc5db53\"]},\"title\":\"Bokeh Application\",\"version\":\"0.12.10\"}};\n",
       "    var render_items = [{\"docid\":\"aa17995b-e6ef-4b67-81a2-eb6428c14c13\",\"elementid\":\"5bbfc45a-9ded-42b4-a65c-318b7b1dbf69\",\"modelid\":\"c44b4731-2e88-412e-931f-b7829cc5db53\",\"notebook_comms_target\":\"531d3b76-b93e-440e-84f8-c8ae99ec1820\"}];\n",
       "\n",
       "    root.Bokeh.embed.embed_items(docs_json, render_items);\n",
       "  }\n",
       "\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        embed_document(root);\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "      attempts++;\n",
       "      if (attempts > 100) {\n",
       "        console.log(\"Bokeh: ERROR: Unable to embed document because BokehJS library is missing\")\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "c44b4731-2e88-412e-931f-b7829cc5db53"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig1 = figure(plot_width=400, plot_height=400,title=\"rewards\",\n",
    "                      x_axis_label=\"x\",\n",
    "                      y_axis_label=\"y\")\n",
    "rplot = fig1.line([],[],color=\"firebrick\",line_width=2)\n",
    "# make a grid\n",
    "handle1 = show(fig1, notebook_handle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T19:19:46.829313Z",
     "start_time": "2017-12-05T19:19:46.821809Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_actions = {\n",
    "    'strafe':{\n",
    "        'left': 'strafe -1',\n",
    "        'right': 'strafe 1'\n",
    "    },\n",
    "    'move':{\n",
    "        'back':'move -1',\n",
    "        'forward':'move 1'\n",
    "    }   \n",
    "}\n",
    "# flatten dict of actions\n",
    "ractions = []\n",
    "for action_type in simple_actions.keys():\n",
    "    \n",
    "    for action in simple_actions[action_type]:\n",
    "        ractions.append(simple_actions[action_type][action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T19:48:16.880260Z",
     "start_time": "2017-12-05T19:48:16.832519Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(inpt, nact, scope, reuse=False):\n",
    "    \"\"\"This model takes as input an observation and returns values of all actions.\"\"\"\n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "        h = conv(tf.cast(inpt, tf.float32)/255., 'c1', nf=32, rf=8, stride=4, init_scale=np.sqrt(2))\n",
    "        h2 = conv(h, 'c2', nf=64, rf=4, stride=2, init_scale=np.sqrt(2))\n",
    "        h3 = conv(h2, 'c3', nf=32, rf=3, stride=1, init_scale=np.sqrt(2))\n",
    "        h3 = conv_to_fc(h3)\n",
    "        h4 = fc(h3, 'fc1', nh=512, init_scale=np.sqrt(2))\n",
    "        pi = fc(h4, 'pi', nact, act=lambda x:x)\n",
    "        vf = fc(h4, 'v', 1, act=lambda x:x)\n",
    "        return vf\n",
    "def new_model(inpt,num_actions,scope,reuse=False):\n",
    "    \n",
    "    with tf.variable_scope(scope,reuse=reuse):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(32,activation='relu',input_shape=(25,35,1)))\n",
    "        model.add(Dense(num_actions,activation=\"softmax\"))\n",
    "        return model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T19:48:19.152515Z",
     "start_time": "2017-12-05T19:48:18.888414Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Train(env,world):\n",
    "    U.reset()\n",
    "    with U.make_session(2) as sess:\n",
    "        replay_buffer = ReplayBuffer(5000)\n",
    "        exploration = LinearSchedule(schedule_timesteps=1000, initial_p=0.9, final_p=0.5)\n",
    "        episode_rewards = [0.0]\n",
    "        \n",
    "        Kend.set_session(sess)\n",
    "        \n",
    "        r,s,data,ws = env.startworld(world)\n",
    "        \n",
    "        \n",
    "        act, train, update_target, debug = deepq.build_train(\n",
    "        make_obs_ph=lambda name: U.BatchInput((25,35,1), name=name), # prev 49\n",
    "        q_func=new_model,\n",
    "        num_actions= len(env.actions), #prev len(ractions)\n",
    "        optimizer=tf.train.AdamOptimizer(learning_rate=0.5)\n",
    "        )\n",
    "        U.initialize()\n",
    "        update_target()\n",
    "        \n",
    "        R = 0\n",
    "        episode = 0\n",
    "        for t in itertools.count():\n",
    "            # exploration schedule update_eps=exploration.value(t)\n",
    "            update_eps=exploration.value(t)\n",
    "            action = act(s[None])[0]\n",
    "\n",
    "            r,s_,data,ws = env.step(action)\n",
    "\n",
    "            done = ws.is_mission_running is False\n",
    "            replay_buffer.add(s,action,r,s_,done)\n",
    "\n",
    "\n",
    "            s = s_\n",
    "\n",
    "            episode_rewards[-1] += r\n",
    "            \n",
    "            R += r\n",
    "            #writer = tf.summary.FileWriter(\"logs\", sess.graph)\n",
    "            if done: #mission is done\n",
    "                _,s,_,ws = env.startworld('CliffWalking.xml')\n",
    "                clear_output(wait=True) \n",
    "                display(\"mission done reward : {} @ t = {}\".format(episode_rewards[-1],t))\n",
    "                update(episode,episode_rewards[-1],rewards_plot,handle)\n",
    "                episode_rewards.append(0)\n",
    "                episode+=1\n",
    "                time.sleep(0.5) # give env time to reset\n",
    "                #s = gym_env.reset()\n",
    "\n",
    "\n",
    "            is_solved = t > 100 and np.mean(episode_rewards) >= 10000\n",
    "            \n",
    "            if t%100 == 0:\n",
    "                display('reward @ t= {} is {}'.format(t,r))\n",
    "            \n",
    "            if is_solved:\n",
    "                # Show off the result\n",
    "                whaa = 5+2\n",
    "            else:\n",
    "                # Minimize the error in Bellman's equation on a batch sampled from replay buffer.\n",
    "                if t > 1000:\n",
    "                    obses_t, actions, rewards, obses_tp1, dones = replay_buffer.sample(32)\n",
    "                    train(obses_t, actions, rewards, obses_tp1, dones, np.ones_like(rewards))\n",
    "                # Update target network periodically.\n",
    "                if t % 1000 == 0:\n",
    "                    update_target()\n",
    "                    clear_output(wait=True)             \n",
    "                    display(r)\n",
    "\n",
    "                if t % 100 == 0 and t > 5:\n",
    "                    #display(r)\n",
    "                    whaa = 5\n",
    "\n",
    "            if done and len(episode_rewards) % 10 == 0:\n",
    "                logger.record_tabular(\"steps\", t)\n",
    "                logger.record_tabular(\"episodes\", len(episode_rewards))\n",
    "                logger.record_tabular(\"mean episode reward\", round(np.mean(episode_rewards[-101:-1]), 1))\n",
    "                logger.record_tabular(\"% time spent exploring\", int(100 * exploration.value(t)))\n",
    "                logger.dump_tabular()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T19:48:22.269153Z",
     "start_time": "2017-12-05T19:48:21.478781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: unrecognised option '-f'\n",
      "Malmo version: 0.31.0\n",
      "\n",
      "Allowed options:\n",
      "  -h [ --help ]         show description of allowed options\n",
      "  --test                run this as an integration test\n",
      "\n",
      "\n",
      "Mission Started...."
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shapes must be equal rank, but are 1 and 3 for 'deepq/Select' (op: 'Select') with input shapes: [?], [?], [?,35,4].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    653\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    655\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/casper/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shapes must be equal rank, but are 1 and 3 for 'deepq/Select' (op: 'Select') with input shapes: [?], [?], [?,35,4].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-54bbab4e5b0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mractions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m420\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m41\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m41\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'CliffWalking.xml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-eff7ae92d118>\u001b[0m in \u001b[0;36mTrain\u001b[0;34m(env, world)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mq_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mnum_actions\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#prev len(ractions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         )\n\u001b[1;32m     19\u001b[0m         \u001b[0mU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/baselines/baselines/deepq/build_graph.py\u001b[0m in \u001b[0;36mbuild_train\u001b[0;34m(make_obs_ph, q_func, num_actions, optimizer, grad_norm_clipping, gamma, double_q, scope, reuse, param_noise, param_noise_filter_func)\u001b[0m\n\u001b[1;32m    339\u001b[0m             param_noise_filter_func=param_noise_filter_func)\n\u001b[1;32m    340\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0mact_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_act\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_obs_ph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/baselines/baselines/deepq/build_graph.py\u001b[0m in \u001b[0;36mbuild_act\u001b[0;34m(make_obs_ph, q_func, num_actions, scope, reuse)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mrandom_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mchose_random\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mstochastic_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchose_random\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0moutput_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstochastic_ph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstochastic_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdeterministic_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mwhere\u001b[0;34m(condition, x, y, name)\u001b[0m\n\u001b[1;32m   2365\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2366\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2367\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2368\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2369\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must both be non-None or both be None.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m_select\u001b[0;34m(condition, t, e, name)\u001b[0m\n\u001b[1;32m   2253\u001b[0m   \"\"\"\n\u001b[1;32m   2254\u001b[0m   result = _op_def_lib.apply_op(\"Select\", condition=condition, t=t, e=e,\n\u001b[0;32m-> 2255\u001b[0;31m                                 name=name)\n\u001b[0m\u001b[1;32m   2256\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    765\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    766\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    768\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2630\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2631\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2632\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2633\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2634\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1909\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m~/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    593\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    594\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    596\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    657\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes must be equal rank, but are 1 and 3 for 'deepq/Select' (op: 'Select') with input shapes: [?], [?], [?,35,4]."
     ]
    }
   ],
   "source": [
    "env = Env(ractions,(300,420,3),(41,41))\n",
    "Train(env,'CliffWalking.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:casper]",
   "language": "python",
   "name": "conda-env-casper-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
