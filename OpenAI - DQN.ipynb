{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T20:48:55.969385Z",
     "start_time": "2017-12-27T20:48:45.019497Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import itertools\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as layers\n",
    "\n",
    "import baselines.common.tf_util as U\n",
    "\n",
    "from baselines import logger\n",
    "from baselines import deepq\n",
    "from baselines.deepq.replay_buffer import PrioritizedReplayBuffer\n",
    "from baselines.common.schedules import LinearSchedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T20:48:56.101308Z",
     "start_time": "2017-12-27T20:48:56.040879Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import gym_minecraft\n",
    "from MinecraftGym import MinecraftWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T20:48:56.226551Z",
     "start_time": "2017-12-27T20:48:56.187959Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Sequential,model_from_json\n",
    "from keras.layers import Dense, Activation,GRU,Input,LSTM,Conv2D,Flatten\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T20:48:56.885889Z",
     "start_time": "2017-12-27T20:48:56.306540Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"05ef7b4f-d980-4b79-84d5-5ac17151a98e\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id !== undefined) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var element_id = msg.content.text.trim();\n",
       "            Bokeh.index[element_id].model.document.clear();\n",
       "            delete Bokeh.index[element_id];\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(`.${CLASS_NAME.split(' ')[0]}`);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[0].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[0].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[0]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"05ef7b4f-d980-4b79-84d5-5ac17151a98e\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"05ef7b4f-d980-4b79-84d5-5ac17151a98e\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '05ef7b4f-d980-4b79-84d5-5ac17151a98e' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.10.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"05ef7b4f-d980-4b79-84d5-5ac17151a98e\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"05ef7b4f-d980-4b79-84d5-5ac17151a98e\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"05ef7b4f-d980-4b79-84d5-5ac17151a98e\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '05ef7b4f-d980-4b79-84d5-5ac17151a98e' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.10.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"05ef7b4f-d980-4b79-84d5-5ac17151a98e\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.plotting import figure\n",
    "from bokeh.io import output_notebook, push_notebook, show\n",
    "from bokeh.driving import linear\n",
    "from bokeh.layouts import row,gridplot\n",
    "from IPython.display import clear_output,display\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T20:48:56.975086Z",
     "start_time": "2017-12-27T20:48:56.960188Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hyperdash import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T20:48:57.116981Z",
     "start_time": "2017-12-27T20:48:57.048313Z"
    }
   },
   "outputs": [],
   "source": [
    "pre_env = gym.make(\"MinecraftCliffWalking1-v0\")\n",
    "pre_env.init(videoResolution=[400,400],allowContinuousMovement=[\"move\", \"turn\", \"strafe\"],observeGrid=[20,-1,20,20,-1,20],observeDistance=[4,45,12])\n",
    "env = MinecraftWrapper(pre_env,1/10,(41,41))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T20:48:57.216794Z",
     "start_time": "2017-12-27T20:48:57.206283Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def proc2_reward(info):\n",
    "    if info is None:\n",
    "        return 0\n",
    "    elif 'observation' not in info.keys():\n",
    "        return 0\n",
    "    elif info['observation'] is None:\n",
    "        return 0\n",
    "    elif 'distanceFromdist' in info['observation'].keys():\n",
    "        return 10/(0.001 + info['observation']['distanceFromdist'])\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T20:48:57.335047Z",
     "start_time": "2017-12-27T20:48:57.305870Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(inpt, num_actions, scope, reuse=False):\n",
    "    \"\"\"This model takes as input an observation and returns values of all actions.\"\"\"\n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32,(8,8),input_shape=env.observation_space.shape,activation='relu'))\n",
    "        model.add(Conv2D(64,(4,4),activation='relu'))\n",
    "        model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(60,activation='relu'))\n",
    "        model.add(Dense(32,activation='relu'))\n",
    "        model.add(Dense(output_dim=num_actions,activation='softmax'))\n",
    "        \n",
    "        '''\n",
    "        a = Conv2D(32,(8,8),input_shape=env.observation_space.shape,activation='relu')(inpt)\n",
    "        b = Conv2D(64,(3,3),activation='relu')(a)\n",
    "        d = Flatten()(b)\n",
    "        c = Dense(output_dim=num_actions,activation='softmax')(d)\n",
    "        '''\n",
    "        return model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T20:48:57.472869Z",
     "start_time": "2017-12-27T20:48:57.446501Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def old_model(inpt, num_actions, scope, reuse=False):\n",
    "    \"\"\"This model takes as input an observation and returns values of all actions.\"\"\"\n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "        print(inpt.shape)\n",
    "        out = inpt\n",
    "\n",
    "        out =  tf.layers.conv2d(\n",
    "                inputs=out,\n",
    "                filters=32,\n",
    "                kernel_size=[8, 8],\n",
    "                padding=\"same\",\n",
    "                activation=tf.nn.relu)\n",
    "        out =  tf.layers.conv2d(\n",
    "                inputs=out,\n",
    "                filters=64,\n",
    "                kernel_size=[4, 4],\n",
    "                padding=\"same\",\n",
    "                activation=tf.nn.relu)\n",
    "        out =  tf.layers.conv2d(\n",
    "                inputs=out,\n",
    "                filters=64,\n",
    "                kernel_size=[5, 5],\n",
    "                padding=\"same\",\n",
    "                activation=tf.nn.relu)\n",
    "        out2 = tf.contrib.layers.flatten(out)\n",
    "        out2 = tf.layers.dense(inputs=out2, units=64)\n",
    "        out2 = tf.layers.dense(inputs=out2, units=num_actions)\n",
    "    return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T21:06:37.386326Z",
     "start_time": "2017-12-27T21:03:39.883685Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/baselines/baselines/deepq/build_graph.py:366: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "(?, 40, 40, 1)\n",
      "(?, 40, 40, 1)\n",
      "(?, 40, 40, 1)\n",
      "(?, 40, 40, 1)\n",
      "| reward: -95.277886 |\n",
      "| reward: -96.205312 |\n",
      "| reward: -95.248804 |\n",
      "| reward: -96.217131 |\n",
      "| reward: -96.222051 |\n",
      "| reward: -96.210500 |\n",
      "| reward: -95.247247 |\n",
      "| reward: -93.389679 |\n",
      "| reward: -96.212986 |\n",
      "-------------------------------------\n",
      "| % time spent exploring | 99       |\n",
      "| episodes               | 10       |\n",
      "| mean episode reward    | -95.6    |\n",
      "| steps                  | 50       |\n",
      "-------------------------------------\n",
      "| reward: -96.214437 |\n",
      "| reward: -95.282010 |\n",
      "| reward: -86.660289 |\n",
      "| reward: -96.217131 |\n",
      "| reward: -95.248688 |\n",
      "| reward: -95.256792 |\n",
      "| reward: -95.248418 |\n",
      "| reward: -94.289390 |\n",
      "| reward: -96.211992 |\n",
      "| reward: -90.522791 |\n",
      "-------------------------------------\n",
      "| % time spent exploring | 98       |\n",
      "| episodes               | 20       |\n",
      "| mean episode reward    | -94.8    |\n",
      "| steps                  | 122      |\n",
      "-------------------------------------\n",
      "| reward: -96.213771 |\n",
      "| reward: -73.912467 |\n",
      "| reward: -91.483358 |\n",
      "| reward: -97.161095 |\n",
      "| reward: -96.216993 |\n",
      "| reward: -96.215062 |\n",
      "| reward: -95.288611 |\n",
      "| reward: -94.291509 |\n",
      "| reward: -95.276697 |\n",
      "| reward: -72.394439 |\n",
      "-------------------------------------\n",
      "| % time spent exploring | 97       |\n",
      "| episodes               | 30       |\n",
      "| mean episode reward    | -93.4    |\n",
      "| steps                  | 228      |\n",
      "-------------------------------------\n",
      "| reward: -95.282144 |\n",
      "| reward: -91.470877 |\n",
      "| reward: -94.313913 |\n",
      "| reward: -94.352492 |\n",
      "| reward: -95.248080 |\n",
      "| reward: -87.712513 |\n",
      "| reward: -96.208738 |\n",
      "| reward: -95.248060 |\n",
      "| reward: -92.439622 |\n",
      "| reward: -89.580509 |\n",
      "-------------------------------------\n",
      "| % time spent exploring | 96       |\n",
      "| episodes               | 40       |\n",
      "| mean episode reward    | -93.4    |\n",
      "| steps                  | 310      |\n",
      "-------------------------------------\n",
      "| reward: -95.287617 |\n",
      "| reward: -90.588031 |\n",
      "| reward: -95.281693 |\n",
      "| reward: -96.215091 |\n",
      "| reward: -94.337686 |\n",
      "| reward: -95.283382 |\n",
      "| reward: -93.386658 |\n",
      "| reward: -94.347925 |\n",
      "| reward: -94.299236 |\n",
      "| reward: -96.216270 |\n",
      "-------------------------------------\n",
      "| % time spent exploring | 96       |\n",
      "| episodes               | 50       |\n",
      "| mean episode reward    | -93.6    |\n",
      "| steps                  | 378      |\n",
      "-------------------------------------\n",
      "| reward: -97.160651 |\n",
      "| reward: -94.330019 |\n",
      "| reward: -94.291856 |\n",
      "| reward: -95.248236 |\n",
      "| reward: -95.283092 |\n",
      "| reward: -96.216681 |\n",
      "| reward: -96.207733 |\n",
      "| reward: -95.246871 |\n",
      "| reward: -96.211003 |\n",
      "| reward: -96.202682 |\n",
      "-------------------------------------\n",
      "| % time spent exploring | 95       |\n",
      "| episodes               | 60       |\n",
      "| mean episode reward    | -94      |\n",
      "| steps                  | 434      |\n",
      "-------------------------------------\n",
      "| reward: -93.389461 |\n",
      "| reward: -94.340591 |\n",
      "| reward: -93.397781 |\n",
      "| reward: -82.737741 |\n",
      "| reward: -95.244312 |\n",
      "| reward: -96.209296 |\n",
      "| reward: -95.240537 |\n",
      "| reward: -95.249502 |\n",
      "| reward: -95.268307 |\n",
      "| reward: -96.214437 |\n",
      "-------------------------------------\n",
      "| % time spent exploring | 95       |\n",
      "| episodes               | 70       |\n",
      "| mean episode reward    | -93.9    |\n",
      "| steps                  | 510      |\n",
      "-------------------------------------\n",
      "| reward: -95.282104 |\n",
      "| reward: -97.158468 |\n",
      "| reward: -95.279120 |\n",
      "| reward: -91.444391 |\n",
      "| reward: -95.242511 |\n",
      "| reward: -93.367695 |\n",
      "| reward: -93.332869 |\n",
      "| reward: -97.160434 |\n",
      "| reward: -95.283359 |\n",
      "| reward: -95.239437 |\n",
      "-------------------------------------\n",
      "| % time spent exploring | 94       |\n",
      "| episodes               | 80       |\n",
      "| mean episode reward    | -94      |\n",
      "| steps                  | 574      |\n",
      "-------------------------------------\n",
      "| reward: -96.212986 |\n",
      "| reward: -96.211783 |\n",
      "| reward: -96.217681 |\n",
      "| reward: -96.195007 |\n",
      "| reward: -94.304947 |\n",
      "| reward: -94.341718 |\n",
      "| reward: -94.299509 |\n",
      "| reward: -95.265576 |\n",
      "| reward: -96.217122 |\n",
      "| reward: -95.243454 |\n",
      "-------------------------------------\n",
      "| % time spent exploring | 93       |\n",
      "| episodes               | 90       |\n",
      "| mean episode reward    | -94.2    |\n",
      "| steps                  | 632      |\n",
      "-------------------------------------\n",
      "| reward: -95.252385 |\n",
      "| reward: -96.213912 |\n",
      "| reward: -96.222640 |\n",
      "| reward: -94.348653 |\n",
      "| reward: -52.307874 |\n",
      "| reward: -95.252223 |\n",
      "| reward: -94.327883 |\n",
      "| reward: -94.297594 |\n",
      "| reward: -96.214832 |\n",
      "| reward: -94.329289 |\n",
      "-------------------------------------\n",
      "| % time spent exploring | 92       |\n",
      "| episodes               | 100      |\n",
      "| mean episode reward    | -93.9    |\n",
      "| steps                  | 729      |\n",
      "-------------------------------------\n",
      "| reward: -92.403673 |\n",
      "| reward: -95.263063 |\n",
      "| reward: -94.320488 |\n",
      "| reward: -94.305399 |\n",
      "| reward: -95.292192 |\n",
      "| reward: -94.349987 |\n",
      "| reward: -95.248101 |\n",
      "| reward: -96.217126 |\n",
      "| reward: -95.280396 |\n",
      "-------------------------------------\n",
      "| % time spent exploring | 92       |\n",
      "| episodes               | 110      |\n",
      "| mean episode reward    | -93.8    |\n",
      "| steps                  | 792      |\n",
      "-------------------------------------\n",
      "| reward: -95.242040 |\n",
      "| reward: -96.202740 |\n",
      "| reward: -88.659803 |\n",
      "| reward: -91.514275 |\n",
      "| reward: -94.340189 |\n",
      "| reward: -94.329871 |\n",
      "| reward: -95.268317 |\n",
      "| reward: -94.325969 |\n",
      "| reward: -89.557952 |\n",
      "| reward: -91.476146 |\n",
      "-------------------------------------\n",
      "| % time spent exploring | 91       |\n",
      "| episodes               | 120      |\n",
      "| mean episode reward    | -93.7    |\n",
      "| steps                  | 875      |\n",
      "-------------------------------------\n",
      "| reward: -97.158683 |\n",
      "| reward: -96.217131 |\n",
      "| reward: -93.388648 |\n",
      "| reward: -91.555870 |\n",
      "| reward: -92.450910 |\n",
      "| reward: -96.214959 |\n",
      "| reward: -95.289318 |\n",
      "| reward: -96.215691 |\n",
      "| reward: -95.262405 |\n",
      "| reward: -96.213469 |\n",
      "-------------------------------------\n",
      "| % time spent exploring | 90       |\n",
      "| episodes               | 130      |\n",
      "| mean episode reward    | -94.1    |\n",
      "| steps                  | 938      |\n",
      "-------------------------------------\n",
      "| reward: -95.248747 |\n",
      "| reward: -96.209192 |\n",
      "| reward: -90.521437 |\n",
      "| reward: -96.211929 |\n",
      "| reward: -96.209909 |\n",
      "| reward: -96.202779 |\n",
      "| reward: -95.285862 |\n",
      "| reward: -87.635811 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Agent missed 1 observation(s).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| reward: -93.391489 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Agent missed 2 observation(s).\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[32,32,40,40]\n\t [[Node: deepq_1/gradients/deepq_1/q_func/conv2d_2/convolution_grad/Conv2DBackpropInput = Conv2DBackpropInput[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](deepq_1/gradients/deepq_1/q_func/conv2d_2/convolution_grad/Shape, deepq/q_func/conv2d_1/kernel/read, deepq_1/gradients/deepq_1/q_func/conv2d_2/BiasAdd_grad/tuple/control_dependency)]]\n\nCaused by op 'deepq_1/gradients/deepq_1/q_func/conv2d_2/convolution_grad/Conv2DBackpropInput', defined at:\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-5127933ec47d>\", line 11, in <module>\n    optimizer=tf.train.AdamOptimizer(learning_rate=5e-4),\n  File \"/home/ubuntu/baselines/baselines/deepq/build_graph.py\", line 387, in build_train\n    optimize_expr = optimizer.minimize(weighted_error, var_list=q_func_vars)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 315, in minimize\n    grad_loss=grad_loss)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 386, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 542, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 348, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 542, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/ops/nn_grad.py\", line 446, in _Conv2DGrad\n    op.get_attr(\"data_format\")),\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 486, in conv2d_backprop_input\n    data_format=data_format, name=name)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\n...which was originally created as op 'deepq_1/q_func/conv2d_2/convolution', defined at:\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 19 identical lines from previous traceback]\n  File \"<ipython-input-14-5127933ec47d>\", line 11, in <module>\n    optimizer=tf.train.AdamOptimizer(learning_rate=5e-4),\n  File \"/home/ubuntu/baselines/baselines/deepq/build_graph.py\", line 353, in build_train\n    q_t = q_func(obs_t_input.get(), num_actions, scope=\"q_func\", reuse=True)  # reuse parameters from act\n  File \"<ipython-input-9-52e0a8943aba>\", line 18, in old_model\n    activation=tf.nn.relu)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/layers/convolutional.py\", line 551, in conv2d\n    return layer.apply(inputs)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/layers/base.py\", line 503, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/layers/base.py\", line 450, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/layers/convolutional.py\", line 158, in call\n    data_format=utils.convert_data_format(self.data_format, self.rank + 2))\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 672, in convolution\n    op=op)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 338, in with_space_to_batch\n    return op(input, num_spatial_dims, padding)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 664, in op\n    name=name)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 131, in _non_atrous_convolution\n    name=name)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 397, in conv2d\n    data_format=data_format, name=name)\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,32,40,40]\n\t [[Node: deepq_1/gradients/deepq_1/q_func/conv2d_2/convolution_grad/Conv2DBackpropInput = Conv2DBackpropInput[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](deepq_1/gradients/deepq_1/q_func/conv2d_2/convolution_grad/Shape, deepq/q_func/conv2d_1/kernel/read, deepq_1/gradients/deepq_1/q_func/conv2d_2/BiasAdd_grad/tuple/control_dependency)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/casper/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[32,32,40,40]\n\t [[Node: deepq_1/gradients/deepq_1/q_func/conv2d_2/convolution_grad/Conv2DBackpropInput = Conv2DBackpropInput[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](deepq_1/gradients/deepq_1/q_func/conv2d_2/convolution_grad/Shape, deepq/q_func/conv2d_1/kernel/read, deepq_1/gradients/deepq_1/q_func/conv2d_2/BiasAdd_grad/tuple/control_dependency)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-5127933ec47d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mobses_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobses_tp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplay_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobses_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobses_tp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;31m# Update target network periodically.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/baselines/baselines/common/tf_util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgivens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgivens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/baselines/baselines/common/tf_util.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minpt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgivens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgivens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs_update\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_nan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[32,32,40,40]\n\t [[Node: deepq_1/gradients/deepq_1/q_func/conv2d_2/convolution_grad/Conv2DBackpropInput = Conv2DBackpropInput[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](deepq_1/gradients/deepq_1/q_func/conv2d_2/convolution_grad/Shape, deepq/q_func/conv2d_1/kernel/read, deepq_1/gradients/deepq_1/q_func/conv2d_2/BiasAdd_grad/tuple/control_dependency)]]\n\nCaused by op 'deepq_1/gradients/deepq_1/q_func/conv2d_2/convolution_grad/Conv2DBackpropInput', defined at:\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-5127933ec47d>\", line 11, in <module>\n    optimizer=tf.train.AdamOptimizer(learning_rate=5e-4),\n  File \"/home/ubuntu/baselines/baselines/deepq/build_graph.py\", line 387, in build_train\n    optimize_expr = optimizer.minimize(weighted_error, var_list=q_func_vars)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 315, in minimize\n    grad_loss=grad_loss)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 386, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 542, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 348, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 542, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/ops/nn_grad.py\", line 446, in _Conv2DGrad\n    op.get_attr(\"data_format\")),\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 486, in conv2d_backprop_input\n    data_format=data_format, name=name)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\n...which was originally created as op 'deepq_1/q_func/conv2d_2/convolution', defined at:\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 19 identical lines from previous traceback]\n  File \"<ipython-input-14-5127933ec47d>\", line 11, in <module>\n    optimizer=tf.train.AdamOptimizer(learning_rate=5e-4),\n  File \"/home/ubuntu/baselines/baselines/deepq/build_graph.py\", line 353, in build_train\n    q_t = q_func(obs_t_input.get(), num_actions, scope=\"q_func\", reuse=True)  # reuse parameters from act\n  File \"<ipython-input-9-52e0a8943aba>\", line 18, in old_model\n    activation=tf.nn.relu)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/layers/convolutional.py\", line 551, in conv2d\n    return layer.apply(inputs)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/layers/base.py\", line 503, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/layers/base.py\", line 450, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/layers/convolutional.py\", line 158, in call\n    data_format=utils.convert_data_format(self.data_format, self.rank + 2))\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 672, in convolution\n    op=op)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 338, in with_space_to_batch\n    return op(input, num_spatial_dims, padding)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 664, in op\n    name=name)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 131, in _non_atrous_convolution\n    name=name)\n  File \"/home/ubuntu/miniconda2/envs/casper/lib/python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 397, in conv2d\n    data_format=data_format, name=name)\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,32,40,40]\n\t [[Node: deepq_1/gradients/deepq_1/q_func/conv2d_2/convolution_grad/Conv2DBackpropInput = Conv2DBackpropInput[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](deepq_1/gradients/deepq_1/q_func/conv2d_2/convolution_grad/Shape, deepq/q_func/conv2d_1/kernel/read, deepq_1/gradients/deepq_1/q_func/conv2d_2/BiasAdd_grad/tuple/control_dependency)]]\n"
     ]
    }
   ],
   "source": [
    "U.reset()\n",
    "exp  = Experiment(\"openAI DQN\")\n",
    "with U.make_session(2) as sess:\n",
    "    # Create all the functions necessary to train the model\n",
    "    K.set_session(sess)\n",
    "\n",
    "    act, train, update_target, debug = deepq.build_train(\n",
    "        make_obs_ph=lambda name: U.BatchInput((40,40,1), name=name),\n",
    "        q_func=old_model,\n",
    "        num_actions=env.action_space.n,\n",
    "        optimizer=tf.train.AdamOptimizer(learning_rate=5e-4),\n",
    "    )\n",
    "    \n",
    "    # Create the replay buffer\n",
    "    replay_buffer = PrioritizedReplayBuffer(50000,0.9)\n",
    "    # Create the schedule for exploration starting from 1 (every action is random) down to\n",
    "    # 0.02 (98% of actions are selected according to values predicted by the model).\n",
    "    exploration = LinearSchedule(schedule_timesteps=10000, initial_p=1.0, final_p=0.02)\n",
    "\n",
    "    # Initialize the parameters and copy them to the target network.\n",
    "    U.initialize()\n",
    "    update_target()\n",
    "\n",
    "    episode_rewards = [0.0]\n",
    "    obs = env.reset()\n",
    "    for t in itertools.count():\n",
    "        # Take action and update exploration to the newest value\n",
    "        action = act(obs[None], update_eps=exploration.value(t))[0]\n",
    "        new_obs, rew, done, info = env.step(action)\n",
    "        rew += proc2_reward(info)\n",
    "        # Store transition in the replay buffer.\n",
    "        replay_buffer.add(obs, action, rew, new_obs, float(done))\n",
    "        obs = new_obs\n",
    "\n",
    "        episode_rewards[-1] += rew\n",
    "        if done:\n",
    "            obs = env.reset()\n",
    "            exp.metric(\"reward\",episode_rewards[-1])\n",
    "            episode_rewards.append(0)\n",
    "\n",
    "        is_solved = t > 100 and np.mean(episode_rewards[-101:-1]) >= 200\n",
    "        if is_solved:\n",
    "            # Show off the result\n",
    "            #env.render()\n",
    "            print(\"Solved\")\n",
    "        else:\n",
    "            # Minimize the error in Bellman's equation on a batch sampled from replay buffer.\n",
    "            if t > 1000:\n",
    "                obses_t, actions, rewards, obses_tp1, dones, _,_ = replay_buffer.sample(32,0.9)\n",
    "                train(obses_t, actions, rewards, obses_tp1, dones, np.ones_like(rewards))\n",
    "            # Update target network periodically.\n",
    "            if t % 1000 == 0:\n",
    "                update_target()\n",
    "\n",
    "        if done and len(episode_rewards) % 10 == 0:\n",
    "            logger.record_tabular(\"steps\", t)\n",
    "            logger.record_tabular(\"episodes\", len(episode_rewards))\n",
    "            logger.record_tabular(\"mean episode reward\", round(np.mean(episode_rewards[-101:-1]), 1))\n",
    "            logger.record_tabular(\"% time spent exploring\", int(100 * exploration.value(t)))\n",
    "            logger.dump_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T21:03:32.621578Z",
     "start_time": "2017-12-27T21:03:31.432087Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        Returns\n",
    "        -------\n",
    "        obs_batch: np.array\n",
    "            batch of observations\n",
    "        act_batch: np.array\n",
    "            batch of actions executed given obs_batch\n",
    "        rew_batch: np.array\n",
    "            rewards received as results of executing act_batch\n",
    "        next_obs_batch: np.array\n",
    "            next set of observations seen after executing act_batch\n",
    "        done_mask: np.array\n",
    "            done_mask[i] = 1 if executing act_batch[i] resulted in\n",
    "            the end of an episode and 0 otherwise.\n",
    "        \"\"\"\n",
    "        \n",
    "                Returns\n",
    "        -------\n",
    "        obs_batch: np.array\n",
    "            batch of observations\n",
    "        act_batch: np.array\n",
    "            batch of actions executed given obs_batch\n",
    "        rew_batch: np.array\n",
    "            rewards received as results of executing act_batch\n",
    "        next_obs_batch: np.array\n",
    "            next set of observations seen after executing act_batch\n",
    "        done_mask: np.array\n",
    "            done_mask[i] = 1 if executing act_batch[i] resulted in\n",
    "            the end of an episode and 0 otherwise.\n",
    "        weights: np.array\n",
    "            Array of shape (batch_size,) and dtype np.float32\n",
    "            denoting importance weight of each sampled transition\n",
    "        idxes: np.array\n",
    "            Array of shape (batch_size,) and dtype np.int32\n",
    "            idexes in buffer of sampled experiences\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T20:40:17.426676Z",
     "start_time": "2017-12-27T20:40:17.418613Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T20:27:24.193205Z",
     "start_time": "2017-12-27T20:27:24.146277Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reward_proc(info,grid_shape = (41,41)):\n",
    "    if \"grid\" not in info['observation'].keys():\n",
    "        return 0\n",
    "    # reformat grid to a vector that only show the floor with blocks\n",
    "    vec = []    \n",
    "    for item in info['observation']['grid'][::-1]:\n",
    "        if 'lava' in item:\n",
    "            vec.append(1)\n",
    "        elif 'lapis' in item:\n",
    "            vec.append(2)\n",
    "        else:\n",
    "            vec.append(0)\n",
    "\n",
    "     # compute reward depending on distance to target\n",
    "    new_state = np.array(vec)\n",
    "    tmp = np.array(vec).reshape(grid_shape)\n",
    "    idx2 = np.argwhere(tmp == 2)\n",
    "\n",
    "    size = grid_shape[0]\n",
    "    idx1 = (np.ceil(size/2),np.ceil(size/2))\n",
    "\n",
    "    a = (self._dist(idx2,idx1))\n",
    "    if(a > 0):\n",
    "        try:\n",
    "            dist_reward = 2000/(a)\n",
    "        except:\n",
    "            dist_reward = 0\n",
    "        return dist_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T20:37:22.909889Z",
     "start_time": "2017-12-27T20:37:22.903651Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update(x,y,handle,plot):\n",
    "    plot.data_source.data['x'] += [x]\n",
    "    plot.data_source.data['y'] += [y]\n",
    "    push_notebook(handle=handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T20:40:52.294008Z",
     "start_time": "2017-12-27T20:40:52.191419Z"
    }
   },
   "outputs": [],
   "source": [
    "fig_test = figure(plot_width=1000, plot_height=400,title=\"rewards_test\",\n",
    "                      x_axis_label=\"x\",\n",
    "                      y_axis_label=\"y\")\n",
    "test_plot = fig_test.line([],[],color=\"navy\",line_width=2)\n",
    "# make a grid\n",
    "handle_test = show(fig_test, notebook_handle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T20:41:38.507864Z",
     "start_time": "2017-12-27T20:41:17.103285Z"
    }
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for e in range(100):\n",
    "    done = False\n",
    "    obs = env.reset()\n",
    "    #env.render()\n",
    "    count = 0\n",
    "    while not done:\n",
    "        \n",
    "        #env.render()\n",
    "        a = env.action_space.sample()\n",
    "        s,r,done,info = env.step(a)\n",
    "        r_ = proc2_reward(info)\n",
    "        print(r_)\n",
    "        r += r_\n",
    "        update(count,r_,handle_test,test_plot)\n",
    "        count += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T20:27:35.534116Z",
     "start_time": "2017-12-27T20:27:35.491428Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T20:16:30.979433Z",
     "start_time": "2017-12-27T20:16:30.328041Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env.reset()\n",
    "s,r,done,info = env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T20:16:31.562802Z",
     "start_time": "2017-12-27T20:16:31.511331Z"
    }
   },
   "outputs": [],
   "source": [
    "s,r,done,info = env.step(0)\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T20:16:35.591597Z",
     "start_time": "2017-12-27T20:16:35.581697Z"
    }
   },
   "outputs": [],
   "source": [
    "proc2_reward(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:casper]",
   "language": "python",
   "name": "conda-env-casper-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
