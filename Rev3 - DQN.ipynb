{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T04:14:58.353657Z",
     "start_time": "2018-01-23T04:14:43.306610Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pdb;\n",
    "import scipy.misc as scimisc\n",
    "\n",
    "from tkinter import *\n",
    "from PIL import Image\n",
    "from PIL import ImageTk\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.animation as animation\n",
    "from PIL import Image\n",
    "\n",
    "import MalmoPython\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "from IPython.display import clear_output,display\n",
    "import logging\n",
    "import math\n",
    "\n",
    "\n",
    "import gym\n",
    "import gym_minecraft\n",
    "import itertools\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as layers\n",
    "\n",
    "import baselines.common.tf_util as U\n",
    "\n",
    "from baselines import logger\n",
    "from baselines import deepq\n",
    "from baselines.deepq.replay_buffer import ReplayBuffer,PrioritizedReplayBuffer\n",
    "from baselines.common.schedules import LinearSchedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T04:14:59.042404Z",
     "start_time": "2018-01-23T04:14:58.389487Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"b191cff8-a125-4b88-aaa9-e92870b6ae8f\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id !== undefined) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var element_id = msg.content.text.trim();\n",
       "            Bokeh.index[element_id].model.document.clear();\n",
       "            delete Bokeh.index[element_id];\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(`.${CLASS_NAME.split(' ')[0]}`);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[0].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[0].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[0]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"b191cff8-a125-4b88-aaa9-e92870b6ae8f\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"b191cff8-a125-4b88-aaa9-e92870b6ae8f\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'b191cff8-a125-4b88-aaa9-e92870b6ae8f' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.10.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"b191cff8-a125-4b88-aaa9-e92870b6ae8f\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"b191cff8-a125-4b88-aaa9-e92870b6ae8f\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"b191cff8-a125-4b88-aaa9-e92870b6ae8f\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'b191cff8-a125-4b88-aaa9-e92870b6ae8f' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.10.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"b191cff8-a125-4b88-aaa9-e92870b6ae8f\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.plotting import figure\n",
    "from bokeh.io import output_notebook, push_notebook, show\n",
    "from bokeh.driving import linear\n",
    "from bokeh.layouts import row,gridplot\n",
    "from IPython.display import clear_output,display\n",
    "import bokeh\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T04:14:59.235418Z",
     "start_time": "2018-01-23T04:14:59.071854Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Sequential,model_from_json,Model\n",
    "from keras.layers import Conv2D,LSTM,GRU,TimeDistributed,Dense,Flatten,Input,Lambda\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T04:14:59.275645Z",
     "start_time": "2018-01-23T04:14:59.268111Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_minecraft\n",
    "from MinecraftGym import MinecraftWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epsilon Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T04:14:59.316276Z",
     "start_time": "2018-01-23T04:14:59.308768Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Policy:\n",
    "    \"\"\"Base class representing an MDP policy.\n",
    "\n",
    "    Policies are used by the agent to choose actions.\n",
    "\n",
    "    Policies are designed to be stacked to get interesting behaviors\n",
    "    of choices. For instances in a discrete action space the lowest\n",
    "    level policy may take in Q-Values and select the action index\n",
    "    corresponding to the largest value. If this policy is wrapped in\n",
    "    an epsilon greedy policy then with some probability epsilon, a\n",
    "    random action will be chosen.\n",
    "    \"\"\"\n",
    "\n",
    "    def select_action(self, **kwargs):\n",
    "        \"\"\"Used by agents to select actions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Any:\n",
    "          An object representing the chosen action. Type depends on\n",
    "          the hierarchy of policy instances.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError('This method should be overriden.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T04:33:18.473949Z",
     "start_time": "2018-01-23T04:33:18.434236Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LinearDecayGreedyEpsilonPolicy(Policy):\n",
    "    \"\"\"Policy with a parameter that decays linearly.\n",
    "\n",
    "    Like GreedyEpsilonPolicy but the epsilon decays from a start value\n",
    "    to an end value over k steps.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    start_value: int, float\n",
    "      The initial value of the parameter\n",
    "    end_value: int, float\n",
    "      The value of the policy at the end of the decay.\n",
    "    num_steps: int\n",
    "      The number of steps over which to decay the value.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, start_value, end_value, num_steps):  # noqa: D102\n",
    "        self.start_value = start_value\n",
    "        self.decay_rate = float(end_value - start_value) / num_steps\n",
    "        self.end_value = end_value\n",
    "        self.step = 0\n",
    "        self.epsilon = start_value\n",
    "\n",
    "    def update(self,is_training = True):\n",
    "        \"\"\"Decay parameter and select action.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        q_values: np.array\n",
    "          The Q-values for each action.\n",
    "        is_training: bool, optional\n",
    "          If true then parameter will be decayed. Defaults to true.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Any:\n",
    "          Selected action.\n",
    "        \"\"\"\n",
    "        epsilon = self.start_value\n",
    "        if is_training:\n",
    "            epsilon += self.decay_rate * self.step\n",
    "            self.step += 1\n",
    "        self.epsilon = max(epsilon, self.end_value)\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Start the decay over at the start value.\"\"\"\n",
    "        self.step = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T04:14:59.453748Z",
     "start_time": "2018-01-23T04:14:59.415744Z"
    },
    "code_folding": [],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    \"\"\"Preprocessor base class.\n",
    "\n",
    "    This is a suggested interface for the preprocessing steps. \n",
    "\n",
    "    Preprocessor can be used to perform some fixed operations on the\n",
    "    raw state from an environment. For example, in ConvNet based\n",
    "    networks which use image as the raw state, it is often useful to\n",
    "    convert the image to greyscale or downsample the image.\n",
    "\n",
    "    Preprocessors are implemented as class so that they can have\n",
    "    internal state. This can be useful for things like the\n",
    "    AtariPreproccessor which maxes over k frames.\n",
    "\n",
    "    If you're using internal states, such as for keeping a sequence of\n",
    "    inputs like in Atari, you should probably call reset when a new\n",
    "    episode begins so that state doesn't leak in from episode to\n",
    "    episode.\n",
    "    \"\"\"\n",
    "\n",
    "    def process_state_for_network(self, state):\n",
    "        \"\"\"Preprocess the given state before giving it to the network.\n",
    "\n",
    "        Should be called just before the action is selected.\n",
    "\n",
    "        This is a different method from the process_state_for_memory\n",
    "        because the replay memory may require a different storage\n",
    "        format to reduce memory usage. For example, storing images as\n",
    "        uint8 in memory is a lot more efficient thant float32, but the\n",
    "        networks work better with floating point images.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        state: np.ndarray\n",
    "          Generally a numpy array. A single state from an environment.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        processed_state: np.ndarray\n",
    "          Generally a numpy array. The state after processing. Can be\n",
    "          modified in anyway.\n",
    "        \"\"\"\n",
    "        return state\n",
    "\n",
    "    def process_state_for_memory(self, state):\n",
    "        \"\"\"Preprocess the given state before giving it to the replay memory.\n",
    "\n",
    "        Should be called just before appending this to the replay memory.\n",
    "\n",
    "        This is a different method from the process_state_for_network\n",
    "        because the replay memory may require a different storage\n",
    "        format to reduce memory usage. For example, storing images as\n",
    "        uint8 in memory and the network expecting images in floating\n",
    "        point.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        state: np.ndarray\n",
    "          A single state from an environmnet. Generally a numpy array.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        processed_state: np.ndarray\n",
    "          Generally a numpy array. The state after processing. Can be\n",
    "          modified in any manner.\n",
    "        \"\"\"\n",
    "        return state\n",
    "\n",
    "    def process_batch(self, samples):\n",
    "        \"\"\"Process batch of samples.\n",
    "\n",
    "        If your replay memory storage format is different than your\n",
    "        network input, you may want to apply this function to your\n",
    "        sampled batch before running it through your update function.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        samples: list(tensorflow_rl.core.Sample)\n",
    "          List of samples to process\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        processed_samples: list(tensorflow_rl.core.Sample)\n",
    "          Samples after processing. Can be modified in anyways, but\n",
    "          the list length will generally stay the same.\n",
    "        \"\"\"\n",
    "        return samples\n",
    "\n",
    "    def process_reward(self, reward):\n",
    "        \"\"\"Process the reward.\n",
    "\n",
    "        Useful for things like reward clipping. The Atari environments\n",
    "        from DQN paper do this. Instead of taking real score, they\n",
    "        take the sign of the delta of the score.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        reward: float\n",
    "          Reward to process\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        processed_reward: float\n",
    "          The processed reward\n",
    "        \"\"\"\n",
    "        return reward\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset any internal state.\n",
    "\n",
    "        Will be called at the start of every new episode. Makes it\n",
    "        possible to do history snapshots.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T04:14:59.536161Z",
     "start_time": "2018-01-23T04:14:59.480733Z"
    },
    "code_folding": [
     6,
     14,
     31
    ],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class AtariPreprocessor(Preprocessor):\n",
    "    \"\"\"Converts images to greyscale and downscales.\n",
    "\n",
    "    Based on the preprocessing step described in:\n",
    "\n",
    "    @article{mnih15_human_level_contr_throug_deep_reinf_learn,\n",
    "    author =\t {Volodymyr Mnih and Koray Kavukcuoglu and David\n",
    "                  Silver and Andrei A. Rusu and Joel Veness and Marc\n",
    "                  G. Bellemare and Alex Graves and Martin Riedmiller\n",
    "                  and Andreas K. Fidjeland and Georg Ostrovski and\n",
    "                  Stig Petersen and Charles Beattie and Amir Sadik and\n",
    "                  Ioannis Antonoglou and Helen King and Dharshan\n",
    "                  Kumaran and Daan Wierstra and Shane Legg and Demis\n",
    "                  Hassabis},\n",
    "    title =\t {Human-Level Control Through Deep Reinforcement\n",
    "                  Learning},\n",
    "    journal =\t {Nature},\n",
    "    volume =\t 518,\n",
    "    number =\t 7540,\n",
    "    pages =\t {529-533},\n",
    "    year =\t 2015,\n",
    "    doi =        {10.1038/nature14236},\n",
    "    url =\t {http://dx.doi.org/10.1038/nature14236},\n",
    "    }\n",
    "\n",
    "    You may also want to max over frames to remove flickering. Some\n",
    "    games require this (based on animations and the limited sprite\n",
    "    drawing capabilities of the original Atari).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    new_size: 2 element tuple\n",
    "      The size that each image in the state should be scaled to. e.g\n",
    "      (84, 84) will make each image in the output have shape (84, 84).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,new_state_shape):\n",
    "        self.new_state_shape = new_state_shape\n",
    "    def process_state_for_memory(self, state):\n",
    "        \"\"\"Scale, convert to greyscale and store as uint8.\n",
    "\n",
    "        We don't want to save floating point numbers in the replay\n",
    "        memory. We get the same resolution as uint8, but use a quarter\n",
    "        to an eigth of the bytes (depending on float32 or float64)\n",
    "\n",
    "        We recommend using the Python Image Library (PIL) to do the\n",
    "        image conversions.\n",
    "        \"\"\"\n",
    "        img = Image.fromarray(state).convert('L').resize(self.new_state_shape[:2], Image.BILINEAR)\n",
    "        state = np.array(img)\n",
    "        return np.expand_dims(state,-1)\n",
    "    def process_for_network(self, state):\n",
    "        \"\"\"Scale, convert to greyscale and store as float32.\n",
    "\n",
    "        Basically same as process state for memory, but this time\n",
    "        outputs float32 images.\n",
    "        \"\"\"\n",
    "        state = np.float32(state / 255.0)\n",
    "        return state\n",
    "\n",
    "    def process_batch(self, samples):\n",
    "        \"\"\"The batches from replay memory will be uint8, convert to float32.\n",
    "\n",
    "        Same as process_state_for_network but works on a batch of\n",
    "        samples from the replay memory. Meaning you need to convert\n",
    "        both state and next state values.\n",
    "        \"\"\"\n",
    "        return np.float32(samples / 255.0)\n",
    "            \n",
    "\n",
    "    def process_reward(self, reward):\n",
    "        \"\"\"Clip reward between -1 and 1.\"\"\"\n",
    "        #return np.clip(reward, -1, 1) \n",
    "    \n",
    "    def reset(self):\n",
    "        self.last_state = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T04:14:59.867220Z",
     "start_time": "2018-01-23T04:14:59.561574Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self,stateCnt,actionCnt,recurrent,mode,learning_rate):\n",
    "        self.stateCnt = stateCnt\n",
    "        self.actionCnt = actionCnt\n",
    "        self.learning_rate = learning_rate\n",
    "        #self.batch_size = batch_size\n",
    "        \n",
    "        self.recurrent = recurrent\n",
    "        self.mode = mode\n",
    "        \n",
    "    def build(self):\n",
    "        model = Sequential()\n",
    "        # Lets try a CNN to take screen as input\n",
    "        # batch size is 64, 320x240 video RGB channels with an extra channel for depth\n",
    "        #conv1 = \n",
    "        model.add(TimeDistributed(Conv2D(64, (3, 3)),\n",
    "                          input_shape=self.stateCnt,batch_size=self.batch_size))\n",
    "        \n",
    "        #model.add(layers.TimeDistributed(layers.Conv2D(32,(8,8),input_shape=self.stateCnt,activation='relu')))\n",
    "        conv2 = layers.Conv2D(64,(4,4),activation='relu')\n",
    "        conv3 = layers.Conv2D(64,(3,3),activation='relu')\n",
    "        model.add(layers.TimeDistributed(conv2))\n",
    "        model.add(layers.TimeDistributed(conv3))\n",
    "        model.add(layers.TimeDistributed(layers.Flatten()))\n",
    "        #model.add(layers.Flatten())\n",
    "        #model.add(layers.Permute((0,2,1)))\n",
    "        #self.add(Reshape(input_width, num_filters))\n",
    "        model.add(layers.GRU(units=70,stateful=True))\n",
    "        #model.add(layers.Dense(256,activation='relu')\n",
    "        model.add(layers.Dense(output_dim=self.actionCnt))\n",
    "        \n",
    "        model.compile(loss=self._huber_loss,optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "    def build2(self):\n",
    "        inpt = Input(shape = self.stateCnt, name = \"input\")\n",
    "        \n",
    "        if self.mode == \"linear\":\n",
    "            \n",
    "            flatten_hidden = Flatten(name = \"flatten\")(input_data)\n",
    "            output = Dense(num_actions, name = \"output\")(flatten_hidden)\n",
    "        else:\n",
    "            if self.recurrent:\n",
    "                # shape should be (timesteps,height,width,color)\n",
    "                conv1 = TimeDistributed(Conv2D(32, (8, 8), strides = 4, activation = \"relu\", name = \"conv1\"))(inpt)\n",
    "                conv2 = TimeDistributed(Conv2D(64, (4, 4), strides = 2, activation = \"relu\", name = \"conv2\"))(conv1)\n",
    "                conv3 = TimeDistributed(Conv2D(64, (3, 3), strides = 1, activation = \"relu\", name = \"conv3\"))(conv2)\n",
    "                flatten_hidden = TimeDistributed(Flatten())(conv3)\n",
    "                hidden_input = TimeDistributed(Dense(512, activation = 'relu', name = 'flat_to_512')) (flatten_hidden)\n",
    "                context = GRU(512, return_sequences=False, stateful=False) (hidden_input)\n",
    "                \n",
    "            if self.mode == \"dqn\":\n",
    "                h4 = Dense(512, activation='relu', name = \"fc\")(context)\n",
    "                output = Dense(num_actions, name = \"output\")(h4)\n",
    "            elif self.mode == \"duel\":\n",
    "                value_hidden = Dense(512, activation = 'relu', name = 'value_fc')(context)\n",
    "                value = Dense(1, name = \"value\")(value_hidden)\n",
    "                \n",
    "                action_hidden = Dense(512, activation = 'relu', name = 'action_fc')(context)\n",
    "                action = Dense(self.actionCnt, name = \"action\")(action_hidden)\n",
    "                \n",
    "                action_mean = Lambda(lambda x: K.mean(x, axis = 1, keepdims = True), name = 'action_mean')(action) \n",
    "                output = Lambda(lambda x: x[0] + x[1] - x[2], name = 'output')([action, value, action_mean])\n",
    "        model = Model(inputs = inpt, outputs = output)\n",
    "        model.compile(loss=self._huber_loss,optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "            \n",
    "        \n",
    "    def _huber_loss(self, target, prediction):\n",
    "        # sqrt(1+error^2)-1\n",
    "        error = prediction - target\n",
    "        return K.mean(K.sqrt(1+K.square(error))-1, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T04:14:59.919699Z",
     "start_time": "2018-01-23T04:14:59.893019Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class ShortMemory():\n",
    "    def __init__(self,hist_len,state_dim):\n",
    "        self.history_length = hist_len\n",
    "        self.state_dim = state_dim\n",
    "        self.mem_hist = np.zeros((hist_len,) + state_dim , dtype = np.float32)\n",
    "        self.current = 0\n",
    "    def add(self,state):\n",
    "        self.mem_hist[self.current % self.history_length] = state\n",
    "        self.current += 1\n",
    "    def get(self):\n",
    "        '''\n",
    "        This function provides the recent history of length history_length.\n",
    "        The sample in the beginning will be padded at the beginning. (0,0,0..data)\n",
    "        '''\n",
    "        return self.mem_hist[::-1]\n",
    "    \n",
    "    def forget(self):\n",
    "        self.mem_hist = np.zeros((self.history_length,) + self.state_dim, dtype = np.float32)\n",
    "        self.current = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T04:15:00.180327Z",
     "start_time": "2018-01-23T04:14:59.950227Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Memory():\n",
    "    def __init__(self,capacity,hist_len,s_dim):\n",
    "        '''\n",
    "        capacity: how many episodes to store?\n",
    "        hist_len: what is the history length of each episode?\n",
    "        s_dim: the size of your state in a tuple ex. (80,80,1) \n",
    "        '''\n",
    "        self.memory_size = capacity\n",
    "        self.history_length = hist_len\n",
    "        self.state_dim = s_dim\n",
    "        self.mem_a = np.zeros(self.memory_size, dtype = np.int8)\n",
    "        self.mem_r = np.zeros(self.memory_size, dtype = np.int8)\n",
    "        self.mem_s = np.zeros((self.memory_size,) + s_dim , dtype = np.uint8)\n",
    "        self.dones = np.zeros(self.memory_size, dtype = np.bool)\n",
    "        self.current = 0\n",
    "    def get_state(self,idx):\n",
    "        state = self.mem_s[idx - self.history_length + 1:idx + 1, :, :]\n",
    "        assert len(state) <= self.history_length\n",
    "        #print(len(state))\n",
    "        if len(state) < self.history_length:\n",
    "            pad = self.history_length - len(state)\n",
    "            pad_shape = (pad,) + (80,80,1)\n",
    "            #print(\"pad {}\".format(pad_shape))\n",
    "            pad_arr = np.zeros((pad,) + (80,80,1))\n",
    "\n",
    "            state = np.concatenate((pad_arr,state),axis=0)\n",
    "            #print(state.shape)\n",
    "\n",
    "        return state\n",
    "    def add(self,s,a,r,done):\n",
    "        self.mem_a[self.current % self.memory_size] = a\n",
    "        self.mem_r[self.current % self.memory_size] = r\n",
    "        self.mem_s[self.current % self.memory_size] = s\n",
    "        self.dones[self.current % self.memory_size] = done\n",
    "        self.current += 1 \n",
    "    def sample(self, batch_size):\n",
    "        indexes = []\n",
    "        # ensure enough frames to sample\n",
    "        assert self.current > self.history_length\n",
    "        # -1 because still need next frame\n",
    "        end = min(self.current, self.memory_size) - 1\n",
    "\n",
    "        while len(indexes) < batch_size: \n",
    "            index = np.random.randint(self.history_length - 1, end)\n",
    "            # sampled state shouldn't contain episode end\n",
    "            if self.dones[index - self.history_length + 1: index + 1].any():\n",
    "                continue\n",
    "            indexes.append(index)\n",
    "\n",
    "        smp_s = []\n",
    "        smp_a = [] \n",
    "        smp_r = []\n",
    "        smp_s_ = []\n",
    "        smp_done = []\n",
    "        for idx in indexes:\n",
    "            smp_s.append(self.get_state(idx))\n",
    "            smp_a.append(self.mem_a[idx])\n",
    "            smp_r.append(self.mem_r[idx])\n",
    "            smp_s_.append(self.get_state(idx + 1))\n",
    "            smp_done.append(self.dones[idx])\n",
    "        return np.array(smp_s),np.array(smp_a),np.array(smp_r),np.array(smp_s_),np.array(smp_done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T04:15:00.377778Z",
     "start_time": "2018-01-23T04:15:00.214698Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class ReplayMemory:\n",
    "    \"\"\"Interface for replay memories.\n",
    "    Methods\n",
    "    -------\n",
    "    append(state, action, reward, debug_info=None)\n",
    "      Add a sample to the replay memory. \n",
    "    end_episode(final_state, is_terminal, debug_info=None)\n",
    "      Set the final state of an episode and mark whether it was a true\n",
    "      terminal state (i.e. the env returned is_terminal=True), of it\n",
    "      is an artificial terminal state (i.e. agent quit the episode\n",
    "      early, but agent could have kept running episode).\n",
    "    sample(batch_size, indexes=None)\n",
    "      Return list of samples from the memory. Each class will\n",
    "      implement a different method of choosing the\n",
    "      samples. Optionally, specify the sample indexes manually.\n",
    "    clear()\n",
    "      Reset the memory. Deletes all references to the samples.\n",
    "    \"\"\"\n",
    "    def __init__(self, args):\n",
    "        \"\"\"Setup memory.\n",
    "        You should specify the maximum size o the memory. Once the\n",
    "        memory fills up oldest values should be removed. You can try\n",
    "        the collections.deque class as the underlying storage, but\n",
    "        your sample method will be very slow.\n",
    "        We recommend using a list as a ring buffer. Just track the\n",
    "        index where the next sample should be inserted in the list.\n",
    "        \"\"\"\n",
    "        self.memory_size = args.replay_memory_size\n",
    "        self.history_length = args.num_frames\n",
    "        self.actions = np.zeros(self.memory_size, dtype = np.int8)\n",
    "        self.rewards = np.zeros(self.memory_size, dtype = np.int8)\n",
    "        self.screens = np.zeros((self.memory_size, args.frame_height, args.frame_width), dtype = np.uint8)\n",
    "        self.terminals = np.zeros(self.memory_size, dtype = np.bool)\n",
    "        self.current = 0\n",
    "\n",
    "    def append(self, state, action, reward, is_terminal):\n",
    "        self.actions[self.current % self.memory_size] = action\n",
    "        self.rewards[self.current % self.memory_size] = reward\n",
    "        self.screens[self.current % self.memory_size] = state\n",
    "        self.terminals[self.current % self.memory_size] = is_terminal\n",
    "        # img = Image.fromarray(state, mode = 'L')\n",
    "        # path = \"./tmp/%05d-%s.png\" % (self.current, is_terminal)\n",
    "        # img.save(path)\n",
    "        self.current += 1\n",
    "\n",
    "    def get_state(self, index):\n",
    "        state = self.screens[index - self.history_length + 1:index + 1, :, :]\n",
    "        # history dimention last\n",
    "        return state \n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        samples = []\n",
    "        indexes = []\n",
    "        # ensure enough frames to sample\n",
    "        assert self.current > self.history_length\n",
    "        # -1 because still need next frame\n",
    "        end = min(self.current, self.memory_size) - 1\n",
    "\n",
    "        while len(indexes) < batch_size: \n",
    "            index = np.random.randint(self.history_length - 1, end)\n",
    "            # sampled state shouldn't contain episode end\n",
    "            if self.terminals[index - self.history_length + 1: index + 1].any():\n",
    "                continue\n",
    "            indexes.append(index)\n",
    "\n",
    "        for idx in indexes:\n",
    "            new_sample = Sample(self.get_state(idx), self.actions[idx],\n",
    "                self.rewards[idx], self.get_state(idx + 1), self.terminals[idx])\n",
    "            samples.append(new_sample)\n",
    "        return samples\n",
    "\n",
    "    def clear(self):\n",
    "        self.current = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-20T04:49:59.287765Z",
     "start_time": "2018-01-20T04:49:59.278537Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "b_s,b_a,b_r,b_s_,b_d = t_mem.sample(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-20T04:50:00.655058Z",
     "start_time": "2018-01-20T04:50:00.636862Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 5, 80, 80, 1)\n",
      "(32,)\n",
      "(32,)\n",
      "(32, 5, 80, 80, 1)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "print(b_s.shape)\n",
    "print(b_a.shape)\n",
    "print(b_r.shape)\n",
    "print(b_s_.shape)\n",
    "print(b_d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-20T04:50:13.544620Z",
     "start_time": "2018-01-20T04:50:13.482881Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         ..., \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       "\n",
       "\n",
       "        [[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         ..., \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       "\n",
       "\n",
       "        [[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         ..., \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [1],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       "\n",
       "\n",
       "        [[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         ..., \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       "\n",
       "\n",
       "        [[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         ..., \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         ..., \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       "\n",
       "\n",
       "        [[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         ..., \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       "\n",
       "\n",
       "        [[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         ..., \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       "\n",
       "\n",
       "        [[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         ..., \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [1],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       "\n",
       "\n",
       "        [[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         ..., \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         ..., \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       "\n",
       "\n",
       "        [[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         ..., \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       "\n",
       "\n",
       "        [[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         ..., \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       "\n",
       "\n",
       "        [[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         ..., \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       "\n",
       "\n",
       "        [[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         ..., \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]]],\n",
       "\n",
       "\n",
       "\n",
       "       ..., \n",
       "       [[[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         ..., \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       "\n",
       "\n",
       "        [[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         ..., \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       "\n",
       "\n",
       "        [[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         ..., \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       "\n",
       "\n",
       "        [[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         ..., \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [1],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       "\n",
       "\n",
       "        [[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         ..., \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         ..., \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       "\n",
       "\n",
       "        [[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         ..., \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       "\n",
       "\n",
       "        [[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         ..., \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       "\n",
       "\n",
       "        [[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         ..., \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       "\n",
       "\n",
       "        [[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         ..., \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         ..., \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       "\n",
       "\n",
       "        [[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         ..., \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       "\n",
       "\n",
       "        [[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         ..., \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       "\n",
       "\n",
       "        [[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         ..., \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [1],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]],\n",
       "\n",
       "\n",
       "        [[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         ..., \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       "\n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ..., \n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]]]], dtype=uint8)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T05:04:54.904960Z",
     "start_time": "2018-01-23T05:04:53.891970Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self,stateCnt,actionCnt,capacity,epsilon_policy,gamma,num_frames,learning_rate,train_start,train_freq,target_update_freq,batch_size,name,preprocessor,output_path=\"./logs\"):\n",
    "        \n",
    "        self.preprocessor = AtariPreprocessor((84,84,1))\n",
    "        stateCnt = self.preprocessor.new_state_shape\n",
    "        inpt = (num_frames,) + stateCnt\n",
    "        self.stateCnt = stateCnt\n",
    "        self.actionCnt = actionCnt\n",
    "        self.model = Network(inpt,actionCnt,True,'duel',learning_rate).build2() # model\n",
    "        self.target_model = Network(inpt,actionCnt,True,'duel',learning_rate).build2() # target model\n",
    "        self.writer = tf.summary.FileWriter(output_path)\n",
    "        self.epsilon_policy = epsilon_policy\n",
    "        self.gamma = gamma\n",
    "        self.steps = 0\n",
    "        self.longmem = Memory(capacity,num_frames,stateCnt)\n",
    "        self.shortmem = ShortMemory(num_frames,stateCnt)\n",
    "        self.name = name\n",
    "        self.num_frames = num_frames\n",
    "        self.train_start = train_start\n",
    "        self.train_freq = train_freq\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.target_update_freq = target_update_freq\n",
    "        self.loss_count = 0\n",
    "        \n",
    "        \n",
    "        self.log_path = output_path\n",
    "    def save_model(self,name):\n",
    "        self.model.save_weights(self.log_path + \"/\" + name)\n",
    "    def remember(self,s,a,r,done):\n",
    "        self.longmem.add(s,a,r,done)\n",
    "    def save_scalar(self,step, name, value):\n",
    "        \"\"\"Save a scalar value to tensorboard.\n",
    "          Parameters\n",
    "          ----------\n",
    "          step: int\n",
    "            Training step (sets the position on x-axis of tensorboard graph.\n",
    "          name: str\n",
    "            Name of variable. Will be the name of the graph in tensorboard.\n",
    "          value: float\n",
    "            The value of the variable at this step.\n",
    "          writer: tf.FileWriter\n",
    "            The tensorboard FileWriter instance.\n",
    "          \"\"\"\n",
    "        summary = tf.Summary()\n",
    "        summary_value = summary.value.add()\n",
    "        summary_value.simple_value = float(value)\n",
    "        summary_value.tag = name\n",
    "        self.writer.add_summary(summary, step)\n",
    "    def update_target_model(self):\n",
    "        # copy weights from model to target_model\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "    def act(self, s):\n",
    "        # Epsilon greedy action selection\n",
    "        s = s[None][None] # increase the rank of tensor to have a batch_size of 1 and length 1\n",
    "        if np.random.rand() <= self.epsilon_policy.epsilon:\n",
    "            return random.randrange(self.actionCnt)\n",
    "        act_values = self.model.predict(s)\n",
    "        return np.argmax(act_values[0]) # returns action\n",
    "    def replay2(self,batch_size):\n",
    "        prebatch_s,batch_a,batch_r,prebatch_s_,batch_done = self.longmem.sample(batch_size)# a batch of episode of parameter length\n",
    "        \n",
    "        batch_s = self.preprocessor.process_batch(prebatch_s)\n",
    "        batch_s_ = self.preprocessor.process_batch(prebatch_s_)\n",
    "        a_ = self.model.predict(batch_s_)\n",
    "        a_idx = np.argmax(a_,axis=1)\n",
    "        behaviour_q = self.target_model.predict(batch_s_)\n",
    "        target = self.model.predict(batch_s)\n",
    "        \n",
    "        target[range(batch_size),batch_a.astype('int')] = batch_r + self.gamma * (behaviour_q[range(batch_size),a_idx]) \n",
    "        loss = self.model.train_on_batch(batch_s,target)\n",
    "        self.save_scalar(self.loss_count,\"/Loss\",loss)\n",
    "        self.loss_count +=1\n",
    "        \n",
    "        self.epsilon_policy.update()\n",
    "        return loss\n",
    "    def replay(self, batch_size,length):\n",
    "        #print(\"sample\")\n",
    "        batch = self.memory.old_sample_episode(batch_size,length) # tensor size batch_size,length,frame\n",
    "        #print(np.array(batch).size)\n",
    "        for mini in batch:\n",
    "            #print(\"reset\")\n",
    "            self.model.reset_states() # we do this because the RNN is stateful\n",
    "            self.target_model.reset_states()\n",
    "            \n",
    "            for s,a,r,s_,done in mini:\n",
    "                s = s[None][None]\n",
    "                s_ = s_[None][None]\n",
    "                #print(\"predict\")\n",
    "                target = self.model.predict(s)\n",
    "                if done:\n",
    "                    target[0][a] = r\n",
    "                else:\n",
    "                    a_ = self.model.predict(s_)[0]\n",
    "                    t = self.target_model.predict(s)[0]\n",
    "                    target[0][a] = r + self.gamma * t[np.argmax(a_)]\n",
    "                #print(\"fit\")\n",
    "                res = self.model.fit(s, target, epochs=1,batch_size=1, verbose=0,shuffle=False)\n",
    "                self.save_scalar(self.loss_count,\"Loss\",res.history['loss'][0])\n",
    "                \n",
    "        '''     \n",
    "        for s, a, r, s_, done in minibatch:\n",
    "            state = state\n",
    "            next_state = next_state\n",
    "            \n",
    "            target = self.model.predict(state)\n",
    "            if done:\n",
    "                target[0][action] = reward\n",
    "            else:\n",
    "                a = self.model.predict(next_state)[0]\n",
    "                t = self.target_model.predict(next_state)[0]\n",
    "                target[0][action] = reward + self.gamma * t[np.argmax(a)]\n",
    "            self.model.fit(state, target, epochs=1, verbose=0,shuffle=False)\n",
    "        '''\n",
    "\n",
    "    def train(self,env,episodes):\n",
    "        # play loop\n",
    "        for e in range(episodes):\n",
    "            R = [0.0]\n",
    "            #agent.model.reset_states()\n",
    "            pre_s = env.reset()\n",
    "            mem_s = self.preprocessor.process_state_for_memory(pre_s) #scaled and grayscaled\n",
    "            net_s = self.preprocessor.process_for_network(mem_s) # normalized\n",
    "            done = False\n",
    "            self.shortmem.forget # forget short term memory for recurrent network \n",
    "            self.shortmem.add(net_s) \n",
    "            for t in itertools.count():\n",
    "                hist_s = self.shortmem.get()\n",
    "                # take action using net_s and receive a\n",
    "                a = self.act(hist_s)\n",
    "                #env.render()\n",
    "\n",
    "                pre_s_, r, done, info = env.step(a)\n",
    "                mem_s_ = self.preprocessor.process_state_for_memory(pre_s) #scaled and grayscaled\n",
    "                net_s_ = self.preprocessor.process_for_network(mem_s) # normalized\n",
    "\n",
    "                agent.shortmem.add(net_s_)\n",
    "                agent.remember(mem_s,a,r,done)\n",
    "                R[-1] += r\n",
    "                if done:\n",
    "\n",
    "                    agent.save_scalar(e,\"/reward per episode\",R[-1])\n",
    "                    #print(\"episode: {}/{}, score: {}, e: {}\".format(e, episodes, t, agent.epsilon))\n",
    "                    #exp.metric(\"reward\",R[-1])\n",
    "                    #update(e,R[-1],handle1,rplot)\n",
    "                    R = [0.0]\n",
    "                    break\n",
    "            if e % self.target_update_freq == 0:\n",
    "                self.update_target_model()\n",
    "            #if e % 100 == 0:\n",
    "            #    agent.save_model(\"Exp00-CNN\")\n",
    "            if e % 4 == 0 and e > self.train_start:\n",
    "                #print(\"replay\")\n",
    "                self.replay2(self.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-12-29T07:36:50.138Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def preprocess(rgb_array,scale = 1/12):\n",
    "    frame_shape = rgb_array.shape\n",
    "    \n",
    "    frame = np.array(rgb_array)\n",
    "    gray_frame = np.dot(frame[...,:3],[0.299,0.587,0.114]).reshape((frame_shape[0],frame_shape[1]))\n",
    "    smaller = scimisc.imresize(gray_frame,scale,mode='L').astype('float64')\n",
    "    smaller /= 255.0\n",
    "    smaller = np.expand_dims(smaller,2) # convert to a 3D array of shape (height,width,grayscale)\n",
    "    smaller = np.reshape(smaller, [1, *(smaller.shape)])\n",
    "    return smaller.astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-19T00:05:33.116500Z",
     "start_time": "2017-12-19T00:05:33.107652Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def render(obs,root,canvas):\n",
    "    obs = np.squeeze(obs,2)\n",
    "    image = Image.fromarray(obs.astype('int8'),mode='L')\n",
    "    photo = ImageTk.PhotoImage(image)\n",
    "    root.one = photo\n",
    "    canvas.delete(\"all\")\n",
    "    canvas.create_image(frame_height,frame_width, image=photo)\n",
    "    root.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T02:00:12.157341Z",
     "start_time": "2018-01-17T02:00:12.102560Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_output_folder(args, parent_dir, env_name, task_name):\n",
    "    \"\"\"Return save folder.\n",
    "    Assumes folders in the parent_dir have suffix -run{run\n",
    "    number}. Finds the highest run number and sets the output folder\n",
    "    to that number + 1. This is just convenient so that if you run the\n",
    "    same script multiple times tensorboard can plot all of the results\n",
    "    on the same plots with different names.\n",
    "    Parameters\n",
    "    ----------\n",
    "    parent_dir: str\n",
    "      Path of the directory containing all experiment runs.\n",
    "    Returns\n",
    "    -------\n",
    "    parent_dir/run_dir\n",
    "      Path to this run's save directory.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "        print('===== Folder did not exist; creating... %s'%parent_dir)\n",
    "    experiment_id = 0\n",
    "    for folder_name in os.listdir(parent_dir):\n",
    "        if not os.path.isdir(os.path.join(parent_dir, folder_name)):\n",
    "            continue\n",
    "        try:\n",
    "            folder_name = int(folder_name.split('-run')[-1])\n",
    "            if folder_name > experiment_id:\n",
    "                experiment_id = folder_name\n",
    "        except:\n",
    "            pass\n",
    "    experiment_id += 1\n",
    "\n",
    "    parent_dir = os.path.join(parent_dir, env_name)\n",
    "    parent_dir = parent_dir + '-run{}'.format(experiment_id) + '-' + task_name\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "        print('===== Folder did not exist; creating... %s'%parent_dir)\n",
    "    else:\n",
    "        print('===== Folder exists; delete? %s'%parent_dir)\n",
    "        input(\"Press Enter to continue...\")\n",
    "        os.system('rm -rf %s/' % (parent_dir))\n",
    "    os.makedirs(parent_dir+'/videos/')\n",
    "    os.makedirs(parent_dir+'/images/')\n",
    "    return parent_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "root = Tk()\n",
    "root_frame = Frame(root)\n",
    "canvas = Canvas(root_frame, borderwidth=0, highlightthickness=0, width=200, height=130, bg=\"black\" )\n",
    "root_frame.pack()\n",
    "canvas.pack()\n",
    "\n",
    "frame_height = 25\n",
    "frame_width = 35\n",
    "\n",
    "\n",
    "env = gym.make(\"MinecraftBasic-v0\")\n",
    "env.load_mission_file(\"./CliffWalking.xml\")\n",
    "env.init(videoResolution=[420,300],allowContinuousMovement=[\"move\", \"turn\", \"strafe\"])\n",
    "\n",
    "\n",
    "scale = 1/12 # scale image down by 1/12\n",
    "newshape = (env.video_height*scale,env.video_width*scale,1) # dimension of 1 for grayscale\n",
    "newshape = tuple(map(int,newshape))\n",
    "\n",
    "# the pre processor will adjust the observation space therefore we will edit the property of the environment to take the pre processor into accoutn\n",
    "env.observation_space = gym.spaces.Box(low=0, high=255,\n",
    "shape=newshape)\n",
    "\n",
    "done = False\n",
    "\n",
    "for i in range(1000):\n",
    "    try:\n",
    "        env.reset()\n",
    "        while True:\n",
    "            action = env.action_space.sample()\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            proc_obs = preprocess(obs)\n",
    "            \n",
    "            render(proc_obs,root_frame,canvas)\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "    except:\n",
    "        root.destroy()\n",
    "        env.close()\n",
    "        raise\n",
    "env.close()\n",
    "root.destroy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-05T23:32:27.244253Z",
     "start_time": "2018-01-05T23:32:27.238751Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def update(x,y,handle,plot):\n",
    "    plot.data_source.data['x'] += [x]\n",
    "    plot.data_source.data['y'] += [y]\n",
    "    push_notebook(handle=handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-05T23:49:20.416109Z",
     "start_time": "2018-01-05T23:49:20.320487Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inferno = bokeh.palettes.Inferno9\n",
    "fig1 = figure(plot_width=400, plot_height=400,title=\"rewards\",\n",
    "                      x_axis_label=\"x\",\n",
    "                      y_axis_label=\"y\")\n",
    "rplot = fig1.line([],[],line_width=2)\n",
    "# make a grid\n",
    "handle1 = show(fig1, notebook_handle=True)\n",
    "\n",
    "reward_plot = {\"handle\":handle1,\"plot\":rplot}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T04:15:18.734281Z",
     "start_time": "2018-01-23T04:15:18.659928Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_env = gym.make(\"MinecraftCliffWalking1-v0\")\n",
    "pre_env.init(videoResolution=[400,400],allowContinuousMovement=[\"move\", \"turn\", \"strafe\"],observeGrid=[20,-1,20,20,-1,20],observeDistance=[4,45,12])\n",
    "env = MinecraftWrapper(pre_env,1/5,(41,41))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T04:15:19.268218Z",
     "start_time": "2018-01-23T04:15:18.883413Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atari_env = gym.make('Seaquest-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-22T04:50:53.003771Z",
     "start_time": "2018-01-22T04:50:52.916839Z"
    },
    "code_folding": [],
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(env,agent,episodes):\n",
    "    # play loop\n",
    "    batch_size = 32\n",
    "    train_start = 50\n",
    "    for e in range(episodes):\n",
    "        R = [0.0]\n",
    "        #agent.model.reset_states()\n",
    "        pre_s = env.reset()\n",
    "        mem_s = pre.process_state_for_memory(pre_s) #scaled and grayscaled\n",
    "        net_s = pre.process_for_network(mem_s) # normalized\n",
    "        done = False\n",
    "        agent.shortmem.forget # forget short term memory for recurrent network \n",
    "        agent.shortmem.add(net_s) \n",
    "        for t in itertools.count():\n",
    "            hist_s = agent.shortmem.get()\n",
    "            # take action using net_s and receive a\n",
    "            a = agent.act(hist_s)\n",
    "            env.render()\n",
    "            \n",
    "            pre_s_, r, done, info = env.step(a)\n",
    "            mem_s_ = agent.preprocessor.process_state_for_memory(pre_s) #scaled and grayscaled\n",
    "            net_s_ = agent.preprocessor.process_for_network(mem_s) # normalized\n",
    "            \n",
    "            agent.shortmem.add(net_s_)\n",
    "            agent.remember(mem_s,a,r,done)\n",
    "            R[-1] += r\n",
    "            if done:\n",
    "                \n",
    "                agent.save_scalar(e,\"/reward per episode\",R[-1])\n",
    "                #print(\"episode: {}/{}, score: {}, e: {}\".format(e, episodes, t, agent.epsilon))\n",
    "                #exp.metric(\"reward\",R[-1])\n",
    "                #update(e,R[-1],handle1,rplot)\n",
    "                R = [0.0]\n",
    "                break\n",
    "        #if e % 100 == 0:\n",
    "        #    agent.save_model(\"Exp00-CNN\")\n",
    "        if e % 4 == 0 and e > 32:\n",
    "            #print(\"replay\")\n",
    "            agent.replay2(batch_size)\n",
    "            agent.update_target_model()\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T04:20:31.587245Z",
     "start_time": "2018-01-23T04:20:31.527715Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_output_folder(args, parent_dir, env_name, task_name):\n",
    "    \"\"\"Return save folder.\n",
    "    Assumes folders in the parent_dir have suffix -run{run\n",
    "    number}. Finds the highest run number and sets the output folder\n",
    "    to that number + 1. This is just convenient so that if you run the\n",
    "    same script multiple times tensorboard can plot all of the results\n",
    "    on the same plots with different names.\n",
    "    Parameters\n",
    "    ----------\n",
    "    parent_dir: str\n",
    "      Path of the directory containing all experiment runs.\n",
    "    Returns\n",
    "    -------\n",
    "    parent_dir/run_dir\n",
    "      Path to this run's save directory.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "        print('===== Folder did not exist; creating... %s'%parent_dir)\n",
    "    experiment_id = 0\n",
    "    for folder_name in os.listdir(parent_dir):\n",
    "        if not os.path.isdir(os.path.join(parent_dir, folder_name)):\n",
    "            continue\n",
    "        try:\n",
    "            folder_name = int(folder_name.split('-run')[-1])\n",
    "            if folder_name > experiment_id:\n",
    "                experiment_id = folder_name\n",
    "        except:\n",
    "            pass\n",
    "    experiment_id += 1\n",
    "\n",
    "    parent_dir = os.path.join(parent_dir, env_name)\n",
    "    parent_dir = parent_dir + '-run{}'.format(experiment_id) + '-' + task_name\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "        print('===== Folder did not exist; creating... %s'%parent_dir)\n",
    "    else:\n",
    "        print('===== Folder exists; delete? %s'%parent_dir)\n",
    "        input(\"Press Enter to continue...\")\n",
    "        os.system('rm -rf %s/' % (parent_dir))\n",
    "    #s.makedirs(parent_dir+'/videos/')\n",
    "    #os.makedirs(parent_dir+'/images/')\n",
    "    return parent_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T16:11:26.444954Z",
     "start_time": "2018-01-23T16:11:26.441039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Folder did not exist; creating... ./logs\n",
      "===== Folder did not exist; creating... ./logs/Seaquest-v1-run1-DQRN-Batch\n"
     ]
    }
   ],
   "source": [
    "doc = get_output_folder(None,\"./logs\",\"Seaquest-v1\",\"DQRN-Batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T16:11:29.846231Z",
     "start_time": "2018-01-23T16:11:29.842745Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./logs/Seaquest-v1-run1-DQRN-Batch'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T16:11:38.448020Z",
     "start_time": "2018-01-23T16:11:37.154297Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "episodes = 1000000\n",
    "stateCnt = atari_env.observation_space.shape\n",
    "actionCnt = atari_env.action_space.n\n",
    "epsilon_policy = LinearDecayGreedyEpsilonPolicy(1,0.05,episodes)\n",
    "gamma =  0.99\n",
    "lr = 0.0001\n",
    "num_frames = 5\n",
    "mem_size = 1000000\n",
    "target_update = 10000\n",
    "train_start = 200\n",
    "train_freq = 4\n",
    "batch_size = 32\n",
    "name = \"DRQN-Batch\"\n",
    "\n",
    "agent = Agent(stateCnt=stateCnt,actionCnt=actionCnt,capacity = mem_size,epsilon_policy=epsilon_policy,gamma= gamma,num_frames= num_frames,learning_rate=lr,\\\n",
    "        train_start=train_start,train_freq= train_freq, target_update_freq = target_update,batch_size = batch_size,name = name,preprocessor=True,output_path=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T17:41:45.314104Z",
     "start_time": "2018-01-23T17:41:42.534977Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected input to have 5 dimensions, but got array with shape (1, 1, 5, 84, 84, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-ecb06c754b2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matari_env\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepisodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-1dc4d43cbbc7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, env, episodes)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mhist_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshortmem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0;31m# take action using net_s and receive a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0;31m#env.render()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-1dc4d43cbbc7>\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactionCnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mact_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# returns action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreplay2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/casper/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1694\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1696\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/casper/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    130\u001b[0m                                  \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                                  \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                                  str(array.shape))\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking : expected input to have 5 dimensions, but got array with shape (1, 1, 5, 84, 84, 1)"
     ]
    }
   ],
   "source": [
    "agent.train(atari_env,episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T16:07:47.716419Z",
     "start_time": "2018-01-23T16:07:47.712812Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99997435"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.epsilon_policy.epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Chasewind hyper parameters for seaquest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_epsilon = 1.0\n",
    "final_epsilon = 0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-21T23:43:04.359394Z",
     "start_time": "2018-01-21T23:43:04.354721Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.shortmem.current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-06T19:15:14.192482Z",
     "start_time": "2018-01-06T19:15:00.875277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "target + tderr: [ 0.14771423  0.07921243  0.06676368  0.44944486  1.28734303  0.194103  ]\n",
      "action: 4\n",
      "argmax next_action: 3\n",
      "reward: 0.9469377736886901\n",
      "next_action [ 0.13986205  0.070917    0.0599833   0.4784835   0.05363334  0.19712088]\n",
      "behavioural [ 0.15228666  0.08425859  0.07051608  0.42550659  0.06783158  0.19960055]\n",
      "target [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "target + tderr: [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  1.30741799]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: 0.9470193796151806\n",
      "next_action [ 0.13846093  0.06952428  0.05884152  0.48347369  0.05215491  0.19754465]\n",
      "behavioural [ 0.14546727  0.07650387  0.06417615  0.45049819  0.05894516  0.20440933]\n",
      "target [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "target + tderr: [ 0.13843787  0.06950153  0.05882287  1.31043613  0.0521309   0.19755137]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: 0.9470122049038944\n",
      "next_action [ 0.13843472  0.06949845  0.05882033  0.48356655  0.05212763  0.19755226]\n",
      "behavioural [ 0.14439327  0.07535081  0.06323156  0.4542799   0.05766767  0.20507681]\n",
      "target [ 0.13843432  0.06949806  0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "target + tderr: [ 0.13843432  0.06949806  0.05882001  1.30918729  0.05212722  0.19755244]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: 0.945347387749924\n",
      "next_action [ 0.13843426  0.069498    0.05881996  0.48356816  0.05212716  0.19755244]\n",
      "behavioural [ 0.14424479  0.07519273  0.06310202  0.45479983  0.0574934   0.20516732]\n",
      "target [ 0.13843423  0.06949798  0.05881995  0.48356828  0.05212715  0.19755246]\n",
      "target + tderr: [  1.38434231e-01  -1.00000000e+02   5.88199496e-02   4.83568281e-01\n",
      "   5.21271490e-02   1.97552457e-01]\n",
      "action: 1\n",
      "argmax next_action: 3\n",
      "reward: -100.0\n",
      "next_action [ 0.13843426  0.069498    0.05881996  0.48356816  0.05212716  0.19755244]\n",
      "behavioural [ 0.14424479  0.07519273  0.06310202  0.45479983  0.0574934   0.20516732]\n",
      "target [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "target + tderr: [ 0.14771423  1.28734303  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "action: 1\n",
      "argmax next_action: 3\n",
      "reward: 0.9469377736886901\n",
      "next_action [ 0.13986205  0.070917    0.0599833   0.4784835   0.05363334  0.19712088]\n",
      "behavioural [ 0.15228666  0.08425859  0.07051608  0.42550659  0.06783158  0.19960055]\n",
      "target [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "target + tderr: [ 0.138631    0.06969203  0.0589791   1.30704522  0.05233217  0.19749497]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: 0.9466466179534939\n",
      "next_action [ 0.13846093  0.06952428  0.05884152  0.48347369  0.05215491  0.19754465]\n",
      "behavioural [ 0.14546727  0.07650387  0.06417615  0.45049819  0.05894516  0.20440933]\n",
      "target [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "target + tderr: [ 0.13843787  0.06950153  0.05882287  1.30930281  0.0521309   0.19755137]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: 0.9458789355362225\n",
      "next_action [ 0.13843472  0.06949845  0.05882033  0.48356655  0.05212763  0.19755226]\n",
      "behavioural [ 0.14439327  0.07535081  0.06323156  0.4542799   0.05766767  0.20507681]\n",
      "target [ 0.13843432  0.06949806  0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "target + tderr: [ 0.13843432  1.30308557  0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "action: 1\n",
      "argmax next_action: 3\n",
      "reward: 0.939245734955561\n",
      "next_action [ 0.13843426  0.069498    0.05881996  0.48356816  0.05212716  0.19755244]\n",
      "behavioural [ 0.14424479  0.07519273  0.06310202  0.45479983  0.0574934   0.20516732]\n",
      "target [ 0.13843423  0.06949798  0.05881995  0.48356828  0.05212715  0.19755246]\n",
      "target + tderr: [ -1.00000000e+02   6.94979802e-02   5.88199496e-02   4.83568281e-01\n",
      "   5.21271490e-02   1.97552457e-01]\n",
      "action: 0\n",
      "argmax next_action: 3\n",
      "reward: -100.0\n",
      "next_action [ 0.13843426  0.069498    0.05881996  0.48356816  0.05212716  0.19755244]\n",
      "behavioural [ 0.14424479  0.07519273  0.06310202  0.45479983  0.0574934   0.20516732]\n",
      "target [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "target + tderr: [ 0.14771423  1.28930151  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "action: 1\n",
      "argmax next_action: 3\n",
      "reward: 0.9488962438891083\n",
      "next_action [ 0.13986205  0.070917    0.0599833   0.4784835   0.05363334  0.19712088]\n",
      "behavioural [ 0.15228666  0.08425859  0.07051608  0.42550659  0.06783158  0.19960055]\n",
      "target [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "target + tderr: [ 1.3102423   0.06969203  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "action: 0\n",
      "argmax next_action: 3\n",
      "reward: 0.9498436937217611\n",
      "next_action [ 0.13846093  0.06952428  0.05884152  0.48347369  0.05215491  0.19754465]\n",
      "behavioural [ 0.14546727  0.07650387  0.06417615  0.45049819  0.05894516  0.20440933]\n",
      "target [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "target + tderr: [ 0.13843787  0.06950153  0.05882287  1.31501365  0.0521309   0.19755137]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: 0.9515897734550226\n",
      "next_action [ 0.13843472  0.06949845  0.05882033  0.48356655  0.05212763  0.19755226]\n",
      "behavioural [ 0.14439327  0.07535081  0.06323156  0.4542799   0.05766767  0.20507681]\n",
      "target [ 0.13843432  0.06949806  0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "target + tderr: [ 0.13843432  0.06949806  0.05882001  1.32068193  0.05212722  0.19755244]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: 0.9568421148315791\n",
      "next_action [ 0.13843426  0.069498    0.05881996  0.48356816  0.05212716  0.19755244]\n",
      "behavioural [ 0.14424479  0.07519273  0.06310202  0.45479983  0.0574934   0.20516732]\n",
      "target [ 0.13843423  0.06949798  0.05881995  0.48356828  0.05212715  0.19755246]\n",
      "target + tderr: [ 1.33048105  0.06949798  0.05881995  0.48356828  0.05212715  0.19755246]\n",
      "action: 0\n",
      "argmax next_action: 3\n",
      "reward: 0.9665848710329302\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422464  0.07517131  0.06308445  0.45487025  0.05746979  0.20517959]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 0.13843423  1.34428549  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "action: 1\n",
      "argmax next_action: 3\n",
      "reward: 0.9803816802349857\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422193  0.07516839  0.06308208  0.45487982  0.05746659  0.20518126]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 0.13843423  0.06949797  0.05881993  0.48356828  1.36042297  0.19755241]\n",
      "action: 4\n",
      "argmax next_action: 3\n",
      "reward: 0.9965181655296396\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422153  0.075168    0.06308176  0.45488104  0.05746615  0.20518148]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 0.13843423  0.06949797  1.37611639  0.48356828  0.05212714  0.19755241]\n",
      "action: 2\n",
      "argmax next_action: 3\n",
      "reward: 1.0122114197894825\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422148  0.07516794  0.06308171  0.45488125  0.0574661   0.20518151]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  1.38631868]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: 1.0224136589557253\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.1442215   0.07516795  0.0630817   0.45488131  0.05746609  0.20518149]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 1.3824805   0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "action: 0\n",
      "argmax next_action: 3\n",
      "reward: 1.0185754550002022\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422147  0.07516793  0.0630817   0.45488131  0.05746609  0.20518149]\n",
      "target [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "target + tderr: [ 0.14771423  0.07921243  0.06676368  0.44944486  1.28734303  0.194103  ]\n",
      "action: 4\n",
      "argmax next_action: 3\n",
      "reward: 0.9469377736886901\n",
      "next_action [ 0.13986205  0.070917    0.0599833   0.4784835   0.05363334  0.19712088]\n",
      "behavioural [ 0.15228666  0.08425859  0.07051608  0.42550659  0.06783158  0.19960055]\n",
      "target [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  0.19749497]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target + tderr: [ 0.138631    0.06969203  0.0589791   0.48287073  1.30741799  0.19749497]\n",
      "action: 4\n",
      "argmax next_action: 3\n",
      "reward: 0.9470193796151806\n",
      "next_action [ 0.13846093  0.06952428  0.05884152  0.48347369  0.05215491  0.19754465]\n",
      "behavioural [ 0.14546727  0.07650387  0.06417615  0.45049819  0.05894516  0.20440933]\n",
      "target [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "target + tderr: [ 1.3108592   0.06950153  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "action: 0\n",
      "argmax next_action: 3\n",
      "reward: 0.9474353399066398\n",
      "next_action [ 0.13843472  0.06949845  0.05882033  0.48356655  0.05212763  0.19755226]\n",
      "behavioural [ 0.14439327  0.07535081  0.06323156  0.4542799   0.05766767  0.20507681]\n",
      "target [ 0.13843432  0.06949806  0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "target + tderr: [ 0.13843432  0.06949806  0.05882001  0.48356801  1.31312752  0.19755244]\n",
      "action: 4\n",
      "argmax next_action: 3\n",
      "reward: 0.9492876308296347\n",
      "next_action [ 0.13843426  0.069498    0.05881996  0.48356816  0.05212716  0.19755244]\n",
      "behavioural [ 0.14424479  0.07519273  0.06310202  0.45479983  0.0574934   0.20516732]\n",
      "target [ 0.13843423  0.06949798  0.05881995  0.48356828  0.05212715  0.19755246]\n",
      "target + tderr: [ 1.31782413  0.06949798  0.05881995  0.48356828  0.05212715  0.19755246]\n",
      "action: 0\n",
      "argmax next_action: 3\n",
      "reward: 0.953927950966577\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422464  0.07517131  0.06308445  0.45487025  0.05746979  0.20517959]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  1.32554376]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: 0.961639942291987\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422193  0.07516839  0.06308208  0.45487982  0.05746659  0.20518126]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ -1.00000000e+02   6.94979727e-02   5.88199347e-02   4.83568281e-01\n",
      "   5.21271378e-02   1.97552413e-01]\n",
      "action: 0\n",
      "argmax next_action: 3\n",
      "reward: -100.0\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422193  0.07516839  0.06308208  0.45487982  0.05746659  0.20518126]\n",
      "target [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "target + tderr: [ 1.28734303  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "action: 0\n",
      "argmax next_action: 3\n",
      "reward: 0.9469377736886901\n",
      "next_action [ 0.13986205  0.070917    0.0599833   0.4784835   0.05363334  0.19712088]\n",
      "behavioural [ 0.15228666  0.08425859  0.07051608  0.42550659  0.06783158  0.19960055]\n",
      "target [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "target + tderr: [ 0.138631    0.06969203  1.30762768  0.48287073  0.05233217  0.19749497]\n",
      "action: 2\n",
      "argmax next_action: 3\n",
      "reward: 0.947229153439993\n",
      "next_action [ 0.13846093  0.06952428  0.05884152  0.48347369  0.05215491  0.19754465]\n",
      "behavioural [ 0.14546727  0.07650387  0.06417615  0.45049819  0.05894516  0.20440933]\n",
      "target [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "target + tderr: [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   1.31455016]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: 0.9511261904770963\n",
      "next_action [ 0.13843472  0.06949845  0.05882033  0.48356655  0.05212763  0.19755226]\n",
      "behavioural [ 0.14439327  0.07535081  0.06323156  0.4542799   0.05766767  0.20507681]\n",
      "target [ 0.13843432  0.06949806  0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "target + tderr: [ 0.13843432  0.06949806  1.32398617  0.48356801  0.05212722  0.19755244]\n",
      "action: 2\n",
      "argmax next_action: 3\n",
      "reward: 0.9601462494767203\n",
      "next_action [ 0.13843426  0.069498    0.05881996  0.48356816  0.05212716  0.19755244]\n",
      "behavioural [ 0.14424479  0.07519273  0.06310202  0.45479983  0.0574934   0.20516732]\n",
      "target [ 0.13843423  0.06949798  0.05881995  0.48356828  0.05212715  0.19755246]\n",
      "target + tderr: [  1.38434231e-01  -1.00000000e+02   5.88199496e-02   4.83568281e-01\n",
      "   5.21271490e-02   1.97552457e-01]\n",
      "action: 1\n",
      "argmax next_action: 3\n",
      "reward: -100.0\n",
      "next_action [ 0.13843426  0.069498    0.05881996  0.48356816  0.05212716  0.19755244]\n",
      "behavioural [ 0.14424479  0.07519273  0.06310202  0.45479983  0.0574934   0.20516732]\n",
      "target [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "target + tderr: [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  1.28734303]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: 0.9469377736886901\n",
      "next_action [ 0.13986205  0.070917    0.0599833   0.4784835   0.05363334  0.19712088]\n",
      "behavioural [ 0.15228666  0.08425859  0.07051608  0.42550659  0.06783158  0.19960055]\n",
      "target [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "target + tderr: [ 0.138631    0.06969203  1.30725145  0.48287073  0.05233217  0.19749497]\n",
      "action: 2\n",
      "argmax next_action: 3\n",
      "reward: 0.9468528646512652\n",
      "next_action [ 0.13846093  0.06952428  0.05884152  0.48347369  0.05215491  0.19754465]\n",
      "behavioural [ 0.14546727  0.07650387  0.06417615  0.45049819  0.05894516  0.20440933]\n",
      "target [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "target + tderr: [ 0.13843787  0.06950153  1.31069744  0.48355547  0.0521309   0.19755137]\n",
      "action: 2\n",
      "argmax next_action: 3\n",
      "reward: 0.9472734793217542\n",
      "next_action [ 0.13843472  0.06949845  0.05882033  0.48356655  0.05212763  0.19755226]\n",
      "behavioural [ 0.14439327  0.07535081  0.06323156  0.4542799   0.05766767  0.20507681]\n",
      "target [ 0.13843432  0.06949806  0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "target + tderr: [ -1.00000000e+02   6.94980621e-02   5.88200055e-02   4.83568013e-01\n",
      "   5.21272197e-02   1.97552443e-01]\n",
      "action: 0\n",
      "argmax next_action: 3\n",
      "reward: -100.0\n",
      "next_action [ 0.13843472  0.06949845  0.05882033  0.48356655  0.05212763  0.19755226]\n",
      "behavioural [ 0.14439327  0.07535081  0.06323156  0.4542799   0.05766767  0.20507681]\n",
      "target [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "target + tderr: [ 0.14771423  0.07921243  0.06676368  0.44944486  1.28734303  0.194103  ]\n",
      "action: 4\n",
      "argmax next_action: 3\n",
      "reward: 0.9469377736886901\n",
      "next_action [ 0.13986205  0.070917    0.0599833   0.4784835   0.05363334  0.19712088]\n",
      "behavioural [ 0.15228666  0.08425859  0.07051608  0.42550659  0.06783158  0.19960055]\n",
      "target [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "target + tderr: [ 0.138631    0.06969203  1.30741799  0.48287073  0.05233217  0.19749497]\n",
      "action: 2\n",
      "argmax next_action: 3\n",
      "reward: 0.9470193796151806\n",
      "next_action [ 0.13846093  0.06952428  0.05884152  0.48347369  0.05215491  0.19754465]\n",
      "behavioural [ 0.14546727  0.07650387  0.06417615  0.45049819  0.05894516  0.20440933]\n",
      "target [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "target + tderr: [ 0.13843787  0.06950153  0.05882287  1.31038702  0.0521309   0.19755137]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: 0.9469630610543069\n",
      "next_action [ 0.13843472  0.06949845  0.05882033  0.48356655  0.05212763  0.19755226]\n",
      "behavioural [ 0.14439327  0.07535081  0.06323156  0.4542799   0.05766767  0.20507681]\n",
      "target [ 0.13843432  0.06949806  0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "target + tderr: [ 0.13843432  0.06949806  0.05882001  0.48356801  0.05212722  1.3109237 ]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: 0.9470837775156251\n",
      "next_action [ 0.13843426  0.069498    0.05881996  0.48356816  0.05212716  0.19755244]\n",
      "behavioural [ 0.14424479  0.07519273  0.06310202  0.45479983  0.0574934   0.20516732]\n",
      "target [ 0.13843423  0.06949798  0.05881995  0.48356828  0.05212715  0.19755246]\n",
      "target + tderr: [ 0.13843423  0.06949798  0.05881995  0.48356828  1.30989754  0.19755246]\n",
      "action: 4\n",
      "argmax next_action: 3\n",
      "reward: 0.946001299805786\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422464  0.07517131  0.06308445  0.45487025  0.05746979  0.20517959]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 1.31196725  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "action: 0\n",
      "argmax next_action: 3\n",
      "reward: 0.9480633814500782\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422193  0.07516839  0.06308208  0.45487982  0.05746659  0.20518126]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 1.31819737  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "action: 0\n",
      "argmax next_action: 3\n",
      "reward: 0.9542925366593864\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422153  0.075168    0.06308176  0.45488104  0.05746615  0.20518148]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 0.13843423  1.32928431  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "action: 1\n",
      "argmax next_action: 3\n",
      "reward: 0.9653792786937029\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422148  0.07516794  0.06308171  0.45488125  0.0574661   0.20518151]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [  1.38434231e-01   6.94979727e-02   5.88199347e-02   4.83568281e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   5.21271378e-02  -1.00000000e+02]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: -100.0\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422148  0.07516794  0.06308171  0.45488125  0.0574661   0.20518151]\n",
      "target [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "target + tderr: [ 1.28734303  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "action: 0\n",
      "argmax next_action: 3\n",
      "reward: 0.9469377736886901\n",
      "next_action [ 0.13986205  0.070917    0.0599833   0.4784835   0.05363334  0.19712088]\n",
      "behavioural [ 0.15228666  0.08425859  0.07051608  0.42550659  0.06783158  0.19960055]\n",
      "target [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "target + tderr: [ 0.138631    0.06969203  0.0589791   1.30762768  0.05233217  0.19749497]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: 0.947229153439993\n",
      "next_action [ 0.13846093  0.06952428  0.05884152  0.48347369  0.05215491  0.19754465]\n",
      "behavioural [ 0.14546727  0.07650387  0.06417615  0.45049819  0.05894516  0.20440933]\n",
      "target [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "target + tderr: [ 0.13843787  0.06950153  0.05882287  1.31142128  0.0521309   0.19755137]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: 0.9479974123462633\n",
      "next_action [ 0.13843472  0.06949845  0.05882033  0.48356655  0.05212763  0.19755226]\n",
      "behavioural [ 0.14439327  0.07535081  0.06323156  0.4542799   0.05766767  0.20507681]\n",
      "target [ 0.13843432  0.06949806  0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "target + tderr: [ 0.13843432  0.06949806  1.31858838  0.48356801  0.05212722  0.19755244]\n",
      "action: 2\n",
      "argmax next_action: 3\n",
      "reward: 0.954748546920449\n",
      "next_action [ 0.13843426  0.069498    0.05881996  0.48356816  0.05212716  0.19755244]\n",
      "behavioural [ 0.14424479  0.07519273  0.06310202  0.45479983  0.0574934   0.20516732]\n",
      "target [ 0.13843423  0.06949798  0.05881995  0.48356828  0.05212715  0.19755246]\n",
      "target + tderr: [  1.38434231e-01  -1.00000000e+02   5.88199496e-02   4.83568281e-01\n",
      "   5.21271490e-02   1.97552457e-01]\n",
      "action: 1\n",
      "argmax next_action: 3\n",
      "reward: -100.0\n",
      "next_action [ 0.13843426  0.069498    0.05881996  0.48356816  0.05212716  0.19755244]\n",
      "behavioural [ 0.14424479  0.07519273  0.06310202  0.45479983  0.0574934   0.20516732]\n",
      "target [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "target + tderr: [ 0.14771423  0.07921243  0.06676368  1.28734303  0.06276181  0.194103  ]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: 0.9469377736886901\n",
      "next_action [ 0.13986205  0.070917    0.0599833   0.4784835   0.05363334  0.19712088]\n",
      "behavioural [ 0.15228666  0.08425859  0.07051608  0.42550659  0.06783158  0.19960055]\n",
      "target [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "target + tderr: [ 1.30733633  0.06969203  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "action: 0\n",
      "argmax next_action: 3\n",
      "reward: 0.9469377736886901\n",
      "next_action [ 0.13846093  0.06952428  0.05884152  0.48347369  0.05215491  0.19754465]\n",
      "behavioural [ 0.14546727  0.07650387  0.06417615  0.45049819  0.05894516  0.20440933]\n",
      "target [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "target + tderr: [ 0.13843787  0.06950153  1.31180453  0.48355547  0.0521309   0.19755137]\n",
      "action: 2\n",
      "argmax next_action: 3\n",
      "reward: 0.9483805927189028\n",
      "next_action [ 0.13843472  0.06949845  0.05882033  0.48356655  0.05212763  0.19755226]\n",
      "behavioural [ 0.14439327  0.07535081  0.06323156  0.4542799   0.05766767  0.20507681]\n",
      "target [ 0.13843432  0.06949806  0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "target + tderr: [ 0.13843432  0.06949806  0.05882001  1.31693196  0.05212722  0.19755244]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: 0.9530921406592443\n",
      "next_action [ 0.13843426  0.069498    0.05881996  0.48356816  0.05212716  0.19755244]\n",
      "behavioural [ 0.14424479  0.07519273  0.06310202  0.45479983  0.0574934   0.20516732]\n",
      "target [ 0.13843423  0.06949798  0.05881995  0.48356828  0.05212715  0.19755246]\n",
      "target + tderr: [ 0.13843423  1.32600081  0.05881995  0.48356828  0.05212715  0.19755246]\n",
      "action: 1\n",
      "argmax next_action: 3\n",
      "reward: 0.962104623105135\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422464  0.07517131  0.06308445  0.45487025  0.05746979  0.20517959]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [  1.38434231e-01   6.94979727e-02   5.88199347e-02  -1.00000000e+02\n",
      "   5.21271378e-02   1.97552413e-01]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: -100.0\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422464  0.07517131  0.06308445  0.45487025  0.05746979  0.20517959]\n",
      "target [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "target + tderr: [ 0.14771423  1.28734303  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "action: 1\n",
      "argmax next_action: 3\n",
      "reward: 0.9469377736886901\n",
      "next_action [ 0.13986205  0.070917    0.0599833   0.4784835   0.05363334  0.19712088]\n",
      "behavioural [ 0.15228666  0.08425859  0.07051608  0.42550659  0.06783158  0.19960055]\n",
      "target [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "target + tderr: [ 0.138631    0.06969203  1.30704522  0.48287073  0.05233217  0.19749497]\n",
      "action: 2\n",
      "argmax next_action: 3\n",
      "reward: 0.9466466179534939\n",
      "next_action [ 0.13846093  0.06952428  0.05884152  0.48347369  0.05215491  0.19754465]\n",
      "behavioural [ 0.14546727  0.07650387  0.06417615  0.45049819  0.05894516  0.20440933]\n",
      "target [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "target + tderr: [ 1.30620337  0.06950153  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "action: 0\n",
      "argmax next_action: 3\n",
      "reward: 0.9427794174283146\n",
      "next_action [ 0.13843472  0.06949845  0.05882033  0.48356655  0.05212763  0.19755226]\n",
      "behavioural [ 0.14439327  0.07535081  0.06323156  0.4542799   0.05766767  0.20507681]\n",
      "target [ 0.13843432  0.06949806  0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "target + tderr: [ 0.13843432  1.30280793  0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "action: 1\n",
      "argmax next_action: 3\n",
      "reward: 0.9389681059764475\n",
      "next_action [ 0.13843426  0.069498    0.05881996  0.48356816  0.05212716  0.19755244]\n",
      "behavioural [ 0.14424479  0.07519273  0.06310202  0.45479983  0.0574934   0.20516732]\n",
      "target [ 0.13843423  0.06949798  0.05881995  0.48356828  0.05212715  0.19755246]\n",
      "target + tderr: [ 0.13843423  0.06949798  1.29811835  0.48356828  0.05212715  0.19755246]\n",
      "action: 2\n",
      "argmax next_action: 3\n",
      "reward: 0.9342221647571789\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422464  0.07517131  0.06308445  0.45487025  0.05746979  0.20517959]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [  1.38434231e-01   6.94979727e-02   5.88199347e-02   4.83568281e-01\n",
      "   5.21271378e-02  -1.00000000e+02]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: -100.0\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422464  0.07517131  0.06308445  0.45487025  0.05746979  0.20517959]\n",
      "target [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "target + tderr: [ 0.14771423  0.07921243  1.28734303  0.44944486  0.06276181  0.194103  ]\n",
      "action: 2\n",
      "argmax next_action: 3\n",
      "reward: 0.9469377736886901\n",
      "next_action [ 0.13986205  0.070917    0.0599833   0.4784835   0.05363334  0.19712088]\n",
      "behavioural [ 0.15228666  0.08425859  0.07051608  0.42550659  0.06783158  0.19960055]\n",
      "target [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "target + tderr: [ 0.138631    1.30733633  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "action: 1\n",
      "argmax next_action: 3\n",
      "reward: 0.9469377736886901\n",
      "next_action [ 0.13846093  0.06952428  0.05884152  0.48347369  0.05215491  0.19754465]\n",
      "behavioural [ 0.14546727  0.07650387  0.06417615  0.45049819  0.05894516  0.20440933]\n",
      "target [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "target + tderr: [ 0.13843787  0.06950153  0.05882287  1.31007886  0.0521309   0.19755137]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: 0.9466549521271858\n",
      "next_action [ 0.13843472  0.06949845  0.05882033  0.48356655  0.05212763  0.19755226]\n",
      "behavioural [ 0.14439327  0.07535081  0.06323156  0.4542799   0.05766767  0.20507681]\n",
      "target [ 0.13843432  0.06949806  0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "target + tderr: [ 0.13843432  0.06949806  0.05882001  0.48356801  1.30667758  0.19755244]\n",
      "action: 4\n",
      "argmax next_action: 3\n",
      "reward: 0.9428377284814025\n",
      "next_action [ 0.13843426  0.069498    0.05881996  0.48356816  0.05212716  0.19755244]\n",
      "behavioural [ 0.14424479  0.07519273  0.06310202  0.45479983  0.0574934   0.20516732]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target [ 0.13843423  0.06949798  0.05881995  0.48356828  0.05212715  0.19755246]\n",
      "target + tderr: [ 0.13843423  0.06949798  0.05881995  0.48356828  1.29938436  0.19755246]\n",
      "action: 4\n",
      "argmax next_action: 3\n",
      "reward: 0.9354881742133434\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422464  0.07517131  0.06308445  0.45487025  0.05746979  0.20517959]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [  1.38434231e-01   6.94979727e-02   5.88199347e-02   4.83568281e-01\n",
      "  -1.00000000e+02   1.97552413e-01]\n",
      "action: 4\n",
      "argmax next_action: 3\n",
      "reward: -100.0\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422464  0.07517131  0.06308445  0.45487025  0.05746979  0.20517959]\n",
      "target [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "target + tderr: [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  1.28734303]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: 0.9469377736886901\n",
      "next_action [ 0.13986205  0.070917    0.0599833   0.4784835   0.05363334  0.19712088]\n",
      "behavioural [ 0.15228666  0.08425859  0.07051608  0.42550659  0.06783158  0.19960055]\n",
      "target [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "target + tderr: [ 0.138631    0.06969203  0.0589791   0.48287073  1.30725145  0.19749497]\n",
      "action: 4\n",
      "argmax next_action: 3\n",
      "reward: 0.9468528646512652\n",
      "next_action [ 0.13846093  0.06952428  0.05884152  0.48347369  0.05215491  0.19754465]\n",
      "behavioural [ 0.14546727  0.07650387  0.06417615  0.45049819  0.05894516  0.20440933]\n",
      "target [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "target + tderr: [ 1.31028461  0.06950153  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "action: 0\n",
      "argmax next_action: 3\n",
      "reward: 0.946860664529539\n",
      "next_action [ 0.13843472  0.06949845  0.05882033  0.48356655  0.05212763  0.19755226]\n",
      "behavioural [ 0.14439327  0.07535081  0.06323156  0.4542799   0.05766767  0.20507681]\n",
      "target [ 0.13843432  0.06949806  0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "target + tderr: [ 0.13843432  0.06949806  0.05882001  0.48356801  1.31255078  0.19755244]\n",
      "action: 4\n",
      "argmax next_action: 3\n",
      "reward: 0.9487109769085645\n",
      "next_action [ 0.13843426  0.069498    0.05881996  0.48356816  0.05212716  0.19755244]\n",
      "behavioural [ 0.14424479  0.07519273  0.06310202  0.45479983  0.0574934   0.20516732]\n",
      "target [ 0.13843423  0.06949798  0.05881995  0.48356828  0.05212715  0.19755246]\n",
      "target + tderr: [ 0.13843423  0.06949798  0.05881995  0.48356828  0.05212715  1.31749868]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: 0.9536024717376068\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422464  0.07517131  0.06308445  0.45487025  0.05746979  0.20517959]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  1.32530999]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: 0.9614060833162204\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422193  0.07516839  0.06308208  0.45487982  0.05746659  0.20518126]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [  1.38434231e-01   6.94979727e-02   5.88199347e-02   4.83568281e-01\n",
      "  -1.00000000e+02   1.97552413e-01]\n",
      "action: 4\n",
      "argmax next_action: 3\n",
      "reward: -100.0\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422193  0.07516839  0.06308208  0.45487982  0.05746659  0.20518126]\n",
      "target [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "target + tderr: [ 0.14771423  0.07921243  0.06676368  0.44944486  1.28734303  0.194103  ]\n",
      "action: 4\n",
      "argmax next_action: 3\n",
      "reward: 0.9469377736886901\n",
      "next_action [ 0.13986205  0.070917    0.0599833   0.4784835   0.05363334  0.19712088]\n",
      "behavioural [ 0.15228666  0.08425859  0.07051608  0.42550659  0.06783158  0.19960055]\n",
      "target [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "target + tderr: [ 0.138631    0.06969203  0.0589791   1.30741799  0.05233217  0.19749497]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: 0.9470193796151806\n",
      "next_action [ 0.13846093  0.06952428  0.05884152  0.48347369  0.05215491  0.19754465]\n",
      "behavioural [ 0.14546727  0.07650387  0.06417615  0.45049819  0.05894516  0.20440933]\n",
      "target [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "target + tderr: [ 1.31083584  0.06950153  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "action: 0\n",
      "argmax next_action: 3\n",
      "reward: 0.9474119122457821\n",
      "next_action [ 0.13843472  0.06949845  0.05882033  0.48356655  0.05212763  0.19755226]\n",
      "behavioural [ 0.14439327  0.07535081  0.06323156  0.4542799   0.05766767  0.20507681]\n",
      "target [ 0.13843432  0.06949806  0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "target + tderr: [ 0.13843432  0.06949806  0.05882001  1.31541371  0.05212722  0.19755244]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: 0.951573836515428\n",
      "next_action [ 0.13843426  0.069498    0.05881996  0.48356816  0.05212716  0.19755244]\n",
      "behavioural [ 0.14424479  0.07519273  0.06310202  0.45479983  0.0574934   0.20516732]\n",
      "target [ 0.13843423  0.06949798  0.05881995  0.48356828  0.05212715  0.19755246]\n",
      "target + tderr: [ 0.13843423  0.06949798  0.05881995  1.32474685  0.05212715  0.19755246]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: 0.9608506218385012\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422464  0.07517131  0.06308445  0.45487025  0.05746979  0.20517959]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [  1.38434231e-01   6.94979727e-02   5.88199347e-02   4.83568281e-01\n",
      "   5.21271378e-02  -1.00000000e+02]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: -100.0\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422464  0.07517131  0.06308445  0.45487025  0.05746979  0.20517959]\n",
      "target [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "target + tderr: [ 0.14771423  0.07921243  0.06676368  0.44944486  1.28734303  0.194103  ]\n",
      "action: 4\n",
      "argmax next_action: 3\n",
      "reward: 0.9469377736886901\n",
      "next_action [ 0.13986205  0.070917    0.0599833   0.4784835   0.05363334  0.19712088]\n",
      "behavioural [ 0.15228666  0.08425859  0.07051608  0.42550659  0.06783158  0.19960055]\n",
      "target [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "target + tderr: [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  1.30733633]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: 0.9469377736886901\n",
      "next_action [ 0.13846093  0.06952428  0.05884152  0.48347369  0.05215491  0.19754465]\n",
      "behavioural [ 0.14546727  0.07650387  0.06417615  0.45049819  0.05894516  0.20440933]\n",
      "target [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "target + tderr: [ 0.13843787  0.06950153  0.05882287  0.48355547  1.31027675  0.19755137]\n",
      "action: 4\n",
      "argmax next_action: 3\n",
      "reward: 0.9468528646512652\n",
      "next_action [ 0.13843472  0.06949845  0.05882033  0.48356655  0.05212763  0.19755226]\n",
      "behavioural [ 0.14439327  0.07535081  0.06323156  0.4542799   0.05766767  0.20507681]\n",
      "target [ 0.13843432  0.06949806  0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "target + tderr: [ 0.13843432  1.3110193   0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "action: 1\n",
      "argmax next_action: 3\n",
      "reward: 0.9471794039248463\n",
      "next_action [ 0.13843426  0.069498    0.05881996  0.48356816  0.05212716  0.19755244]\n",
      "behavioural [ 0.14424479  0.07519273  0.06310202  0.45479983  0.0574934   0.20516732]\n",
      "target [ 0.13843423  0.06949798  0.05881995  0.48356828  0.05212715  0.19755246]\n",
      "target + tderr: [ 0.13843423  0.06949798  0.05881995  0.48356828  0.05212715  1.31006265]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: 0.9461664410848178\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422464  0.07517131  0.06308445  0.45487025  0.05746979  0.20517959]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  1.30564249]\n",
      "action: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argmax next_action: 3\n",
      "reward: 0.941738677499424\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422193  0.07516839  0.06308208  0.45487982  0.05746659  0.20518126]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 1.29789197  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "action: 0\n",
      "argmax next_action: 3\n",
      "reward: 0.9339870993965883\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422153  0.075168    0.06308176  0.45488104  0.05746615  0.20518148]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ -1.00000000e+02   6.94979727e-02   5.88199347e-02   4.83568281e-01\n",
      "   5.21271378e-02   1.97552413e-01]\n",
      "action: 0\n",
      "argmax next_action: 3\n",
      "reward: -100.0\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422153  0.075168    0.06308176  0.45488104  0.05746615  0.20518148]\n",
      "target [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "target + tderr: [ 1.28734303  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "action: 0\n",
      "argmax next_action: 3\n",
      "reward: 0.9469377736886901\n",
      "next_action [ 0.13986205  0.070917    0.0599833   0.4784835   0.05363334  0.19712088]\n",
      "behavioural [ 0.15228666  0.08425859  0.07051608  0.42550659  0.06783158  0.19960055]\n",
      "target [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "target + tderr: [ 0.138631    0.06969203  0.0589791   0.48287073  1.30762768  0.19749497]\n",
      "action: 4\n",
      "argmax next_action: 3\n",
      "reward: 0.947229153439993\n",
      "next_action [ 0.13846093  0.06952428  0.05884152  0.48347369  0.05215491  0.19754465]\n",
      "behavioural [ 0.14546727  0.07650387  0.06417615  0.45049819  0.05894516  0.20440933]\n",
      "target [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "target + tderr: [ 0.13843787  1.31145477  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "action: 1\n",
      "argmax next_action: 3\n",
      "reward: 0.9480308451315772\n",
      "next_action [ 0.13843472  0.06949845  0.05882033  0.48356655  0.05212763  0.19755226]\n",
      "behavioural [ 0.14439327  0.07535081  0.06323156  0.4542799   0.05766767  0.20507681]\n",
      "target [ 0.13843432  0.06949806  0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "target + tderr: [ 0.13843432  1.3147397   0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "action: 1\n",
      "argmax next_action: 3\n",
      "reward: 0.950899812720282\n",
      "next_action [ 0.13843426  0.069498    0.05881996  0.48356816  0.05212716  0.19755244]\n",
      "behavioural [ 0.14424479  0.07519273  0.06310202  0.45479983  0.0574934   0.20516732]\n",
      "target [ 0.13843423  0.06949798  0.05881995  0.48356828  0.05212715  0.19755246]\n",
      "target + tderr: [ 0.13843423  1.31479406  0.05881995  0.48356828  0.05212715  0.19755246]\n",
      "action: 1\n",
      "argmax next_action: 3\n",
      "reward: 0.9508978234614449\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422464  0.07517131  0.06308445  0.45487025  0.05746979  0.20517959]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 1.310377    0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "action: 0\n",
      "argmax next_action: 3\n",
      "reward: 0.9464731570747923\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422193  0.07516839  0.06308208  0.45487982  0.05746659  0.20518126]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 0.13843423  0.06949797  1.30499625  0.48356828  0.05212714  0.19755241]\n",
      "action: 2\n",
      "argmax next_action: 3\n",
      "reward: 0.9410914402086965\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422153  0.075168    0.06308176  0.45488104  0.05746615  0.20518148]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 0.13843423  1.30266857  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "action: 1\n",
      "argmax next_action: 3\n",
      "reward: 0.9387636051488931\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422148  0.07516794  0.06308171  0.45488125  0.0574661   0.20518151]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 0.13843423  1.29786777  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "action: 1\n",
      "argmax next_action: 3\n",
      "reward: 0.9339626747420816\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.1442215   0.07516795  0.0630817   0.45488131  0.05746609  0.20518149]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [  1.38434231e-01   6.94979727e-02   5.88199347e-02   4.83568281e-01\n",
      "   5.21271378e-02  -1.00000000e+02]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: -100.0\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.1442215   0.07516795  0.0630817   0.45488131  0.05746609  0.20518149]\n",
      "target [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "target + tderr: [ 1.28734303  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "action: 0\n",
      "argmax next_action: 3\n",
      "reward: 0.9469377736886901\n",
      "next_action [ 0.13986205  0.070917    0.0599833   0.4784835   0.05363334  0.19712088]\n",
      "behavioural [ 0.15228666  0.08425859  0.07051608  0.42550659  0.06783158  0.19960055]\n",
      "target [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "target + tderr: [ 0.138631    0.06969203  0.0589791   1.30762768  0.05233217  0.19749497]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: 0.947229153439993\n",
      "next_action [ 0.13846093  0.06952428  0.05884152  0.48347369  0.05215491  0.19754465]\n",
      "behavioural [ 0.14546727  0.07650387  0.06417615  0.45049819  0.05894516  0.20440933]\n",
      "target [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "target + tderr: [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   1.31142056]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: 0.9479966035177689\n",
      "next_action [ 0.13843472  0.06949845  0.05882033  0.48356655  0.05212763  0.19755226]\n",
      "behavioural [ 0.14439327  0.07535081  0.06323156  0.4542799   0.05766767  0.20507681]\n",
      "target [ 0.13843432  0.06949806  0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "target + tderr: [ 0.13843432  0.06949806  0.05882001  0.48356801  1.31538296  0.19755244]\n",
      "action: 4\n",
      "argmax next_action: 3\n",
      "reward: 0.9515431413008261\n",
      "next_action [ 0.13843426  0.069498    0.05881996  0.48356816  0.05212716  0.19755244]\n",
      "behavioural [ 0.14424479  0.07519273  0.06310202  0.45479983  0.0574934   0.20516732]\n",
      "target [ 0.13843423  0.06949798  0.05881995  0.48356828  0.05212715  0.19755246]\n",
      "target + tderr: [ 0.13843423  0.06949798  1.3259114   0.48356828  0.05212715  0.19755246]\n",
      "action: 2\n",
      "argmax next_action: 3\n",
      "reward: 0.9620151678045462\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422464  0.07517131  0.06308445  0.45487025  0.05746979  0.20517959]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [  1.38434231e-01   6.94979727e-02   5.88199347e-02   4.83568281e-01\n",
      "  -1.00000000e+02   1.97552413e-01]\n",
      "action: 4\n",
      "argmax next_action: 3\n",
      "reward: -100.0\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422464  0.07517131  0.06308445  0.45487025  0.05746979  0.20517959]\n",
      "target [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "target + tderr: [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  1.28734303]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: 0.9469377736886901\n",
      "next_action [ 0.13986205  0.070917    0.0599833   0.4784835   0.05363334  0.19712088]\n",
      "behavioural [ 0.15228666  0.08425859  0.07051608  0.42550659  0.06783158  0.19960055]\n",
      "target [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "target + tderr: [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  1.30725145]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: 0.9468528646512652\n",
      "next_action [ 0.13846093  0.06952428  0.05884152  0.48347369  0.05215491  0.19754465]\n",
      "behavioural [ 0.14546727  0.07650387  0.06417615  0.45049819  0.05894516  0.20440933]\n",
      "target [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   0.19755137]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target + tderr: [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   1.30970943]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: 0.9462855217842024\n",
      "next_action [ 0.13843472  0.06949845  0.05882033  0.48356655  0.05212763  0.19755226]\n",
      "behavioural [ 0.14439327  0.07535081  0.06323156  0.4542799   0.05766767  0.20507681]\n",
      "target [ 0.13843432  0.06949806  0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "target + tderr: [  1.38434321e-01   6.94980621e-02  -1.00000000e+02   4.83568013e-01\n",
      "   5.21272197e-02   1.97552443e-01]\n",
      "action: 2\n",
      "argmax next_action: 3\n",
      "reward: -100.0\n",
      "next_action [ 0.13843472  0.06949845  0.05882033  0.48356655  0.05212763  0.19755226]\n",
      "behavioural [ 0.14439327  0.07535081  0.06323156  0.4542799   0.05766767  0.20507681]\n",
      "target [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "target + tderr: [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  1.28669882]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: 0.9462935809594377\n",
      "next_action [ 0.13986205  0.070917    0.0599833   0.4784835   0.05363334  0.19712088]\n",
      "behavioural [ 0.15228666  0.08425859  0.07051608  0.42550659  0.06783158  0.19960055]\n",
      "target [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "target + tderr: [ 0.138631    0.06969203  0.0589791   0.48287073  1.31003559  0.19749497]\n",
      "action: 4\n",
      "argmax next_action: 3\n",
      "reward: 0.949637043973608\n",
      "next_action [ 0.13846093  0.06952428  0.05884152  0.48347369  0.05215491  0.19754465]\n",
      "behavioural [ 0.14546727  0.07650387  0.06417615  0.45049819  0.05894516  0.20440933]\n",
      "target [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "target + tderr: [ 0.13843787  0.06950153  1.32312977  0.48355547  0.0521309   0.19755137]\n",
      "action: 2\n",
      "argmax next_action: 3\n",
      "reward: 0.9597058386439856\n",
      "next_action [ 0.13843472  0.06949845  0.05882033  0.48356655  0.05212763  0.19755226]\n",
      "behavioural [ 0.14439327  0.07535081  0.06323156  0.4542799   0.05766767  0.20507681]\n",
      "target [ 0.13843432  0.06949806  0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "target + tderr: [ 0.13843432  0.06949806  0.05882001  0.48356801  1.33747804  0.19755244]\n",
      "action: 4\n",
      "argmax next_action: 3\n",
      "reward: 0.973638162565638\n",
      "next_action [ 0.13843426  0.069498    0.05881996  0.48356816  0.05212716  0.19755244]\n",
      "behavioural [ 0.14424479  0.07519273  0.06310202  0.45479983  0.0574934   0.20516732]\n",
      "target [ 0.13843423  0.06949798  0.05881995  0.48356828  0.05212715  0.19755246]\n",
      "target + tderr: [ 0.13843423  1.35312474  0.05881995  0.48356828  0.05212715  0.19755246]\n",
      "action: 1\n",
      "argmax next_action: 3\n",
      "reward: 0.9892284888308189\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422464  0.07517131  0.06308445  0.45487025  0.05746979  0.20517959]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 0.13843423  0.06949797  1.36731505  0.48356828  0.05212714  0.19755241]\n",
      "action: 2\n",
      "argmax next_action: 3\n",
      "reward: 1.003411196704316\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422193  0.07516839  0.06308208  0.45487982  0.05746659  0.20518126]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 0.13843423  1.37457716  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "action: 1\n",
      "argmax next_action: 3\n",
      "reward: 1.0106722951680567\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422153  0.075168    0.06308176  0.45488104  0.05746615  0.20518148]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 1.37136555  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "action: 0\n",
      "argmax next_action: 3\n",
      "reward: 1.0074605475930911\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422148  0.07516794  0.06308171  0.45488125  0.0574661   0.20518151]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 0.13843423  1.36289978  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "action: 1\n",
      "argmax next_action: 3\n",
      "reward: 0.9989947116216952\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.1442215   0.07516795  0.0630817   0.45488131  0.05746609  0.20518149]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  1.34985924]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: 0.9859542437368612\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422147  0.07516793  0.0630817   0.45488131  0.05746609  0.20518149]\n",
      "target [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "target + tderr: [ 0.14771423  1.28734303  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "action: 1\n",
      "argmax next_action: 3\n",
      "reward: 0.9469377736886901\n",
      "next_action [ 0.13986205  0.070917    0.0599833   0.4784835   0.05363334  0.19712088]\n",
      "behavioural [ 0.15228666  0.08425859  0.07051608  0.42550659  0.06783158  0.19960055]\n",
      "target [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "target + tderr: [ 0.138631    1.30704522  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "action: 1\n",
      "argmax next_action: 3\n",
      "reward: 0.9466466179534939\n",
      "next_action [ 0.13846093  0.06952428  0.05884152  0.48347369  0.05215491  0.19754465]\n",
      "behavioural [ 0.14546727  0.07650387  0.06417615  0.45049819  0.05894516  0.20440933]\n",
      "target [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "target + tderr: [ 0.13843787  1.30620503  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "action: 1\n",
      "argmax next_action: 3\n",
      "reward: 0.9427811062140965\n",
      "next_action [ 0.13843472  0.06949845  0.05882033  0.48356655  0.05212763  0.19755226]\n",
      "behavioural [ 0.14439327  0.07535081  0.06323156  0.4542799   0.05766767  0.20507681]\n",
      "target [ 0.13843432  0.06949806  0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "target + tderr: [ 0.13843432  0.06949806  1.29833603  0.48356801  0.05212722  0.19755244]\n",
      "action: 2\n",
      "argmax next_action: 3\n",
      "reward: 0.9344962079545626\n",
      "next_action [ 0.13843426  0.069498    0.05881996  0.48356816  0.05212716  0.19755244]\n",
      "behavioural [ 0.14424479  0.07519273  0.06310202  0.45479983  0.0574934   0.20516732]\n",
      "target [ 0.13843423  0.06949798  0.05881995  0.48356828  0.05212715  0.19755246]\n",
      "target + tderr: [ -1.00000000e+02   6.94979802e-02   5.88199496e-02   4.83568281e-01\n",
      "   5.21271490e-02   1.97552457e-01]\n",
      "action: 0\n",
      "argmax next_action: 3\n",
      "reward: -100.0\n",
      "next_action [ 0.13843426  0.069498    0.05881996  0.48356816  0.05212716  0.19755244]\n",
      "behavioural [ 0.14424479  0.07519273  0.06310202  0.45479983  0.0574934   0.20516732]\n",
      "target [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "target + tderr: [ 0.14771423  0.07921243  0.06676368  0.44944486  1.28734303  0.194103  ]\n",
      "action: 4\n",
      "argmax next_action: 3\n",
      "reward: 0.9469377736886901\n",
      "next_action [ 0.13986205  0.070917    0.0599833   0.4784835   0.05363334  0.19712088]\n",
      "behavioural [ 0.15228666  0.08425859  0.07051608  0.42550659  0.06783158  0.19960055]\n",
      "target [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "target + tderr: [ 0.138631    1.30741799  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "action: 1\n",
      "argmax next_action: 3\n",
      "reward: 0.9470193796151806\n",
      "next_action [ 0.13846093  0.06952428  0.05884152  0.48347369  0.05215491  0.19754465]\n",
      "behavioural [ 0.14546727  0.07650387  0.06417615  0.45049819  0.05894516  0.20440933]\n",
      "target [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "target + tderr: [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   1.31029868]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: 0.9468747404971414\n",
      "next_action [ 0.13843472  0.06949845  0.05882033  0.48356655  0.05212763  0.19755226]\n",
      "behavioural [ 0.14439327  0.07535081  0.06323156  0.4542799   0.05766767  0.20507681]\n",
      "target [ 0.13843432  0.06949806  0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "target + tderr: [ 0.13843432  0.06949806  1.30687988  0.48356801  0.05212722  0.19755244]\n",
      "action: 2\n",
      "argmax next_action: 3\n",
      "reward: 0.9430400063975835\n",
      "next_action [ 0.13843426  0.069498    0.05881996  0.48356816  0.05212716  0.19755244]\n",
      "behavioural [ 0.14424479  0.07519273  0.06310202  0.45479983  0.0574934   0.20516732]\n",
      "target [ 0.13843423  0.06949798  0.05881995  0.48356828  0.05212715  0.19755246]\n",
      "target + tderr: [ 0.13843423  0.06949798  0.05881995  1.30020523  0.05212715  0.19755246]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: 0.9363090733779804\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422464  0.07517131  0.06308445  0.45487025  0.05746979  0.20517959]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [  1.38434231e-01   6.94979727e-02   5.88199347e-02   4.83568281e-01\n",
      "  -1.00000000e+02   1.97552413e-01]\n",
      "action: 4\n",
      "argmax next_action: 3\n",
      "reward: -100.0\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422464  0.07517131  0.06308445  0.45487025  0.05746979  0.20517959]\n",
      "target [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "target + tderr: [ 0.14771423  0.07921243  0.06676368  1.28734303  0.06276181  0.194103  ]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: 0.9469377736886901\n",
      "next_action [ 0.13986205  0.070917    0.0599833   0.4784835   0.05363334  0.19712088]\n",
      "behavioural [ 0.15228666  0.08425859  0.07051608  0.42550659  0.06783158  0.19960055]\n",
      "target [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "target + tderr: [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  1.30733633]\n",
      "action: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argmax next_action: 3\n",
      "reward: 0.9469377736886901\n",
      "next_action [ 0.13846093  0.06952428  0.05884152  0.48347369  0.05215491  0.19754465]\n",
      "behavioural [ 0.14546727  0.07650387  0.06417615  0.45049819  0.05894516  0.20440933]\n",
      "target [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "target + tderr: [ 0.13843787  0.06950153  1.30734313  0.48355547  0.0521309   0.19755137]\n",
      "action: 2\n",
      "argmax next_action: 3\n",
      "reward: 0.943919211087426\n",
      "next_action [ 0.13843472  0.06949845  0.05882033  0.48356655  0.05212763  0.19755226]\n",
      "behavioural [ 0.14439327  0.07535081  0.06323156  0.4542799   0.05766767  0.20507681]\n",
      "target [ 0.13843432  0.06949806  0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "target + tderr: [  1.38434321e-01   6.94980621e-02   5.88200055e-02  -1.00000000e+02\n",
      "   5.21272197e-02   1.97552443e-01]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: -100.0\n",
      "next_action [ 0.13843472  0.06949845  0.05882033  0.48356655  0.05212763  0.19755226]\n",
      "behavioural [ 0.14439327  0.07535081  0.06323156  0.4542799   0.05766767  0.20507681]\n",
      "target [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "target + tderr: [ 0.14771423  0.07921243  0.06676368  1.28734303  0.06276181  0.194103  ]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: 0.9469377736886901\n",
      "next_action [ 0.13986205  0.070917    0.0599833   0.4784835   0.05363334  0.19712088]\n",
      "behavioural [ 0.15228666  0.08425859  0.07051608  0.42550659  0.06783158  0.19960055]\n",
      "target [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "target + tderr: [ 1.30733633  0.06969203  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "action: 0\n",
      "argmax next_action: 3\n",
      "reward: 0.9469377736886901\n",
      "next_action [ 0.13846093  0.06952428  0.05884152  0.48347369  0.05215491  0.19754465]\n",
      "behavioural [ 0.14546727  0.07650387  0.06417615  0.45049819  0.05894516  0.20440933]\n",
      "target [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "target + tderr: [ 0.13843787  0.06950153  1.310637    0.48355547  0.0521309   0.19755137]\n",
      "action: 2\n",
      "argmax next_action: 3\n",
      "reward: 0.9472130482007358\n",
      "next_action [ 0.13843472  0.06949845  0.05882033  0.48356655  0.05212763  0.19755226]\n",
      "behavioural [ 0.14439327  0.07535081  0.06323156  0.4542799   0.05766767  0.20507681]\n",
      "target [ 0.13843432  0.06949806  0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "target + tderr: [ 0.13843432  0.06949806  0.05882001  1.31483185  0.05212722  0.19755244]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: 0.9509919606943611\n",
      "next_action [ 0.13843426  0.069498    0.05881996  0.48356816  0.05212716  0.19755244]\n",
      "behavioural [ 0.14424479  0.07519273  0.06310202  0.45479983  0.0574934   0.20516732]\n",
      "target [ 0.13843423  0.06949798  0.05881995  0.48356828  0.05212715  0.19755246]\n",
      "target + tderr: [ 0.13843423  0.06949798  0.05881995  1.32303643  0.05212715  0.19755246]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: 0.9591402420332853\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422464  0.07517131  0.06308445  0.45487025  0.05746979  0.20517959]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [  1.38434231e-01   6.94979727e-02   5.88199347e-02  -1.00000000e+02\n",
      "   5.21271378e-02   1.97552413e-01]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: -100.0\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422464  0.07517131  0.06308445  0.45487025  0.05746979  0.20517959]\n",
      "target [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "target + tderr: [ 0.14771423  1.28734303  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "action: 1\n",
      "argmax next_action: 3\n",
      "reward: 0.9469377736886901\n",
      "next_action [ 0.13986205  0.070917    0.0599833   0.4784835   0.05363334  0.19712088]\n",
      "behavioural [ 0.15228666  0.08425859  0.07051608  0.42550659  0.06783158  0.19960055]\n",
      "target [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "target + tderr: [ 1.30704522  0.06969203  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "action: 0\n",
      "argmax next_action: 3\n",
      "reward: 0.9466466179534939\n",
      "next_action [ 0.13846093  0.06952428  0.05884152  0.48347369  0.05215491  0.19754465]\n",
      "behavioural [ 0.14546727  0.07650387  0.06417615  0.45049819  0.05894516  0.20440933]\n",
      "target [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "target + tderr: [ 0.13843787  0.06950153  1.31031322  0.48355547  0.0521309   0.19755137]\n",
      "action: 2\n",
      "argmax next_action: 3\n",
      "reward: 0.946889265182683\n",
      "next_action [ 0.13843472  0.06949845  0.05882033  0.48356655  0.05212763  0.19755226]\n",
      "behavioural [ 0.14439327  0.07535081  0.06323156  0.4542799   0.05766767  0.20507681]\n",
      "target [ 0.13843432  0.06949806  0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "target + tderr: [ 0.13843432  0.06949806  0.05882001  0.48356801  1.31381249  0.19755244]\n",
      "action: 4\n",
      "argmax next_action: 3\n",
      "reward: 0.9499725909158206\n",
      "next_action [ 0.13843426  0.069498    0.05881996  0.48356816  0.05212716  0.19755244]\n",
      "behavioural [ 0.14424479  0.07519273  0.06310202  0.45479983  0.0574934   0.20516732]\n",
      "target [ 0.13843423  0.06949798  0.05881995  0.48356828  0.05212715  0.19755246]\n",
      "target + tderr: [ 0.13843423  0.06949798  1.31866753  0.48356828  0.05212715  0.19755246]\n",
      "action: 2\n",
      "argmax next_action: 3\n",
      "reward: 0.9547713360840933\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422464  0.07517131  0.06308445  0.45487025  0.05746979  0.20517959]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 0.13843423  0.06949797  0.05881993  0.48356828  1.32416916  0.19755241]\n",
      "action: 4\n",
      "argmax next_action: 3\n",
      "reward: 0.9602652790449279\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422193  0.07516839  0.06308208  0.45487982  0.05746659  0.20518126]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  1.32896209]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: 0.9650573017248759\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422153  0.075168    0.06308176  0.45488104  0.05746615  0.20518148]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [  1.38434231e-01   6.94979727e-02   5.88199347e-02  -1.00000000e+02\n",
      "   5.21271378e-02   1.97552413e-01]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: -100.0\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422153  0.075168    0.06308176  0.45488104  0.05746615  0.20518148]\n",
      "target [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "target + tderr: [ 0.14771423  0.07921243  0.06676368  0.44944486  1.28734303  0.194103  ]\n",
      "action: 4\n",
      "argmax next_action: 3\n",
      "reward: 0.9469377736886901\n",
      "next_action [ 0.13986205  0.070917    0.0599833   0.4784835   0.05363334  0.19712088]\n",
      "behavioural [ 0.15228666  0.08425859  0.07051608  0.42550659  0.06783158  0.19960055]\n",
      "target [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "target + tderr: [ 0.138631    0.06969203  0.0589791   1.30741799  0.05233217  0.19749497]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: 0.9470193796151806\n",
      "next_action [ 0.13846093  0.06952428  0.05884152  0.48347369  0.05215491  0.19754465]\n",
      "behavioural [ 0.14546727  0.07650387  0.06417615  0.45049819  0.05894516  0.20440933]\n",
      "target [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "target + tderr: [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   1.31179142]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: 0.9483674612847952\n",
      "next_action [ 0.13843472  0.06949845  0.05882033  0.48356655  0.05212763  0.19755226]\n",
      "behavioural [ 0.14439327  0.07535081  0.06323156  0.4542799   0.05766767  0.20507681]\n",
      "target [ 0.13843432  0.06949806  0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "target + tderr: [ 0.13843432  0.06949806  1.31038463  0.48356801  0.05212722  0.19755244]\n",
      "action: 2\n",
      "argmax next_action: 3\n",
      "reward: 0.9465447378217791\n",
      "next_action [ 0.13843426  0.069498    0.05881996  0.48356816  0.05212716  0.19755244]\n",
      "behavioural [ 0.14424479  0.07519273  0.06310202  0.45479983  0.0574934   0.20516732]\n",
      "target [ 0.13843423  0.06949798  0.05881995  0.48356828  0.05212715  0.19755246]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target + tderr: [ 0.13843423  0.06949798  0.05881995  1.30776119  0.05212715  0.19755246]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: 0.9438649533126641\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422464  0.07517131  0.06308445  0.45487025  0.05746979  0.20517959]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 0.13843423  0.06949797  0.05881993  1.30381155  0.05212714  0.19755241]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: 0.93990766159151\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422193  0.07516839  0.06308208  0.45487982  0.05746659  0.20518126]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [  1.38434231e-01   6.94979727e-02   5.88199347e-02   4.83568281e-01\n",
      "   5.21271378e-02  -1.00000000e+02]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: -100.0\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422193  0.07516839  0.06308208  0.45487982  0.05746659  0.20518126]\n",
      "target [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "target + tderr: [ 0.14771423  1.28734303  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "action: 1\n",
      "argmax next_action: 3\n",
      "reward: 0.9469377736886901\n",
      "next_action [ 0.13986205  0.070917    0.0599833   0.4784835   0.05363334  0.19712088]\n",
      "behavioural [ 0.15228666  0.08425859  0.07051608  0.42550659  0.06783158  0.19960055]\n",
      "target [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "target + tderr: [ 0.138631    0.06969203  1.30704522  0.48287073  0.05233217  0.19749497]\n",
      "action: 2\n",
      "argmax next_action: 3\n",
      "reward: 0.9466466179534939\n",
      "next_action [ 0.13846093  0.06952428  0.05884152  0.48347369  0.05215491  0.19754465]\n",
      "behavioural [ 0.14546727  0.07650387  0.06417615  0.45049819  0.05894516  0.20440933]\n",
      "target [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "target + tderr: [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   1.30621636]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: 0.9427924834549347\n",
      "next_action [ 0.13843472  0.06949845  0.05882033  0.48356655  0.05212763  0.19755226]\n",
      "behavioural [ 0.14439327  0.07535081  0.06323156  0.4542799   0.05766767  0.20507681]\n",
      "target [ 0.13843432  0.06949806  0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "target + tderr: [ 0.13843432  0.06949806  0.05882001  1.30128741  0.05212722  0.19755244]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: 0.9374475029398355\n",
      "next_action [ 0.13843426  0.069498    0.05881996  0.48356816  0.05212716  0.19755244]\n",
      "behavioural [ 0.14424479  0.07519273  0.06310202  0.45479983  0.0574934   0.20516732]\n",
      "target [ 0.13843423  0.06949798  0.05881995  0.48356828  0.05212715  0.19755246]\n",
      "target + tderr: [  1.38434231e-01   6.94979802e-02   5.88199496e-02  -1.00000000e+02\n",
      "   5.21271490e-02   1.97552457e-01]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: -100.0\n",
      "next_action [ 0.13843426  0.069498    0.05881996  0.48356816  0.05212716  0.19755244]\n",
      "behavioural [ 0.14424479  0.07519273  0.06310202  0.45479983  0.0574934   0.20516732]\n",
      "target [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "target + tderr: [ 1.28734303  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "action: 0\n",
      "argmax next_action: 3\n",
      "reward: 0.9469377736886901\n",
      "next_action [ 0.13986205  0.070917    0.0599833   0.4784835   0.05363334  0.19712088]\n",
      "behavioural [ 0.15228666  0.08425859  0.07051608  0.42550659  0.06783158  0.19960055]\n",
      "target [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "target + tderr: [ 0.138631    0.06969203  1.30762768  0.48287073  0.05233217  0.19749497]\n",
      "action: 2\n",
      "argmax next_action: 3\n",
      "reward: 0.947229153439993\n",
      "next_action [ 0.13846093  0.06952428  0.05884152  0.48347369  0.05215491  0.19754465]\n",
      "behavioural [ 0.14546727  0.07650387  0.06417615  0.45049819  0.05894516  0.20440933]\n",
      "target [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "target + tderr: [ 0.13843787  1.31455171  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "action: 1\n",
      "argmax next_action: 3\n",
      "reward: 0.9511278188337385\n",
      "next_action [ 0.13843472  0.06949845  0.05882033  0.48356655  0.05212763  0.19755226]\n",
      "behavioural [ 0.14439327  0.07535081  0.06323156  0.4542799   0.05766767  0.20507681]\n",
      "target [ 0.13843432  0.06949806  0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "target + tderr: [ 0.13843432  0.06949806  0.05882001  0.48356801  1.31886065  0.19755244]\n",
      "action: 4\n",
      "argmax next_action: 3\n",
      "reward: 0.955020811813531\n",
      "next_action [ 0.13843426  0.069498    0.05881996  0.48356816  0.05212716  0.19755244]\n",
      "behavioural [ 0.14424479  0.07519273  0.06310202  0.45479983  0.0574934   0.20516732]\n",
      "target [ 0.13843423  0.06949798  0.05881995  0.48356828  0.05212715  0.19755246]\n",
      "target + tderr: [ 0.13843423  1.31591916  0.05881995  0.48356828  0.05212715  0.19755246]\n",
      "action: 1\n",
      "argmax next_action: 3\n",
      "reward: 0.9520229011012907\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422464  0.07517131  0.06308445  0.45487025  0.05746979  0.20517959]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  1.30633855]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: 0.9424346763184545\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422193  0.07516839  0.06308208  0.45487982  0.05746659  0.20518126]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 1.30112886  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "action: 0\n",
      "argmax next_action: 3\n",
      "reward: 0.9372239875356708\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422153  0.075168    0.06308176  0.45488104  0.05746615  0.20518148]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  1.30143726]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: 0.9375322276703262\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422148  0.07516794  0.06308171  0.45488125  0.0574661   0.20518151]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 0.13843423  0.06949797  0.05881993  0.48356828  1.30867016  0.19755241]\n",
      "action: 4\n",
      "argmax next_action: 3\n",
      "reward: 0.9447651554738608\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.1442215   0.07516795  0.0630817   0.45488131  0.05746609  0.20518149]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 1.30685723  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "action: 0\n",
      "argmax next_action: 3\n",
      "reward: 0.9429522382432951\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422147  0.07516793  0.0630817   0.45488131  0.05746609  0.20518149]\n",
      "target [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "target + tderr: [ 1.31832254  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "action: 0\n",
      "argmax next_action: 3\n",
      "reward: 0.9779172592030326\n",
      "next_action [ 0.13986205  0.070917    0.0599833   0.4784835   0.05363334  0.19712088]\n",
      "behavioural [ 0.15228666  0.08425859  0.07051608  0.42550659  0.06783158  0.19960055]\n",
      "target [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "target + tderr: [ 0.138631    0.06969203  1.35216939  0.48287073  0.05233217  0.19749497]\n",
      "action: 2\n",
      "argmax next_action: 3\n",
      "reward: 0.9917708802978169\n",
      "next_action [ 0.13846093  0.06952428  0.05884152  0.48347369  0.05215491  0.19754465]\n",
      "behavioural [ 0.14546727  0.07650387  0.06417615  0.45049819  0.05894516  0.20440933]\n",
      "target [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "target + tderr: [ 0.13843787  0.06950153  0.05882287  1.36976171  0.0521309   0.19755137]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: 1.0063378149246138\n",
      "next_action [ 0.13843472  0.06949845  0.05882033  0.48356655  0.05212763  0.19755226]\n",
      "behavioural [ 0.14439327  0.07535081  0.06323156  0.4542799   0.05766767  0.20507681]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target [ 0.13843432  0.06949806  0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "target + tderr: [ 0.13843432  0.06949806  0.05882001  0.48356801  1.38553381  0.19755244]\n",
      "action: 4\n",
      "argmax next_action: 3\n",
      "reward: 1.0216939338046545\n",
      "next_action [ 0.13843426  0.069498    0.05881996  0.48356816  0.05212716  0.19755244]\n",
      "behavioural [ 0.14424479  0.07519273  0.06310202  0.45479983  0.0574934   0.20516732]\n",
      "target [ 0.13843423  0.06949798  0.05881995  0.48356828  0.05212715  0.19755246]\n",
      "target + tderr: [ 0.13843423  0.06949798  0.05881995  0.48356828  0.05212715  1.40284216]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: 1.0389459270202823\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422464  0.07517131  0.06308445  0.45487025  0.05746979  0.20517959]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 0.13843423  0.06949797  0.05881993  0.48356828  1.41722119  0.19755241]\n",
      "action: 4\n",
      "argmax next_action: 3\n",
      "reward: 1.053317343976052\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422193  0.07516839  0.06308208  0.45487982  0.05746659  0.20518126]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  1.43603992]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: 1.0721350701492616\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422153  0.075168    0.06308176  0.45488104  0.05746615  0.20518148]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  1.44808328]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: 1.0841783148074364\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422148  0.07516794  0.06308171  0.45488125  0.0574661   0.20518151]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 0.13843423  0.06949797  0.05881993  0.48356828  1.45417249  0.19755241]\n",
      "action: 4\n",
      "argmax next_action: 3\n",
      "reward: 1.0902674387867983\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.1442215   0.07516795  0.0630817   0.45488131  0.05746609  0.20518149]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 1.46915078  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "action: 0\n",
      "argmax next_action: 3\n",
      "reward: 1.1052457560911613\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422147  0.07516793  0.0630817   0.45488131  0.05746609  0.20518149]\n",
      "target [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "target + tderr: [ 1.28734303  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "action: 0\n",
      "argmax next_action: 3\n",
      "reward: 0.9469377736886901\n",
      "next_action [ 0.13986205  0.070917    0.0599833   0.4784835   0.05363334  0.19712088]\n",
      "behavioural [ 0.15228666  0.08425859  0.07051608  0.42550659  0.06783158  0.19960055]\n",
      "target [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "target + tderr: [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  1.30762768]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: 0.947229153439993\n",
      "next_action [ 0.13846093  0.06952428  0.05884152  0.48347369  0.05215491  0.19754465]\n",
      "behavioural [ 0.14546727  0.07650387  0.06417615  0.45049819  0.05894516  0.20440933]\n",
      "target [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "target + tderr: [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   1.31129909]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: 0.947875115178675\n",
      "next_action [ 0.13843472  0.06949845  0.05882033  0.48356655  0.05212763  0.19755226]\n",
      "behavioural [ 0.14439327  0.07535081  0.06323156  0.4542799   0.05766767  0.20507681]\n",
      "target [ 0.13843432  0.06949806  0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "target + tderr: [ 0.13843432  0.06949806  0.05882001  1.31716192  0.05212722  0.19755244]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: 0.9533220174009868\n",
      "next_action [ 0.13843426  0.069498    0.05881996  0.48356816  0.05212716  0.19755244]\n",
      "behavioural [ 0.14424479  0.07519273  0.06310202  0.45479983  0.0574934   0.20516732]\n",
      "target [ 0.13843423  0.06949798  0.05881995  0.48356828  0.05212715  0.19755246]\n",
      "target + tderr: [  1.38434231e-01   6.94979802e-02   5.88199496e-02  -1.00000000e+02\n",
      "   5.21271490e-02   1.97552457e-01]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: -100.0\n",
      "next_action [ 0.13843426  0.069498    0.05881996  0.48356816  0.05212716  0.19755244]\n",
      "behavioural [ 0.14424479  0.07519273  0.06310202  0.45479983  0.0574934   0.20516732]\n",
      "target [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "target + tderr: [ 1.28734303  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "action: 0\n",
      "argmax next_action: 3\n",
      "reward: 0.9469377736886901\n",
      "next_action [ 0.13986205  0.070917    0.0599833   0.4784835   0.05363334  0.19712088]\n",
      "behavioural [ 0.15228666  0.08425859  0.07051608  0.42550659  0.06783158  0.19960055]\n",
      "target [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "target + tderr: [ 0.138631    1.30762768  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "action: 1\n",
      "argmax next_action: 3\n",
      "reward: 0.947229153439993\n",
      "next_action [ 0.13846093  0.06952428  0.05884152  0.48347369  0.05215491  0.19754465]\n",
      "behavioural [ 0.14546727  0.07650387  0.06417615  0.45049819  0.05894516  0.20440933]\n",
      "target [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "target + tderr: [ 0.13843787  0.06950153  0.05882287  1.31041026  0.0521309   0.19755137]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: 0.9469862871650688\n",
      "next_action [ 0.13843472  0.06949845  0.05882033  0.48356655  0.05212763  0.19755226]\n",
      "behavioural [ 0.14439327  0.07535081  0.06323156  0.4542799   0.05766767  0.20507681]\n",
      "target [ 0.13843432  0.06949806  0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "target + tderr: [ 1.30779111  0.06949806  0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "action: 0\n",
      "argmax next_action: 3\n",
      "reward: 0.9439512875825946\n",
      "next_action [ 0.13843426  0.069498    0.05881996  0.48356816  0.05212716  0.19755244]\n",
      "behavioural [ 0.14424479  0.07519273  0.06310202  0.45479983  0.0574934   0.20516732]\n",
      "target [ 0.13843423  0.06949798  0.05881995  0.48356828  0.05212715  0.19755246]\n",
      "target + tderr: [ 0.13843423  0.06949798  0.05881995  1.30515456  0.05212715  0.19755246]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: 0.9412583711401524\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422464  0.07517131  0.06308445  0.45487025  0.05746979  0.20517959]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 0.13843423  0.06949797  0.05881993  1.30559349  0.05212714  0.19755241]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: 0.9416896360463727\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422193  0.07516839  0.06308208  0.45487982  0.05746659  0.20518126]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 0.13843423  0.06949797  0.05881993  1.30998302  0.05212714  0.19755241]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: 0.9460781795487984\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422153  0.075168    0.06308176  0.45488104  0.05746615  0.20518148]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  1.31783319]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: 0.9539282239602159\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422148  0.07516794  0.06308171  0.45488125  0.0574661   0.20518151]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [  1.38434231e-01   6.94979727e-02   5.88199347e-02   4.83568281e-01\n",
      "  -1.00000000e+02   1.97552413e-01]\n",
      "action: 4\n",
      "argmax next_action: 3\n",
      "reward: -100.0\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422148  0.07516794  0.06308171  0.45488125  0.0574661   0.20518151]\n",
      "target [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "target + tderr: [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  1.28734303]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: 0.9469377736886901\n",
      "next_action [ 0.13986205  0.070917    0.0599833   0.4784835   0.05363334  0.19712088]\n",
      "behavioural [ 0.15228666  0.08425859  0.07051608  0.42550659  0.06783158  0.19960055]\n",
      "target [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "target + tderr: [ 0.138631    0.06969203  0.0589791   1.30725145  0.05233217  0.19749497]\n",
      "action: 3\n",
      "argmax next_action: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: 0.9468528646512652\n",
      "next_action [ 0.13846093  0.06952428  0.05884152  0.48347369  0.05215491  0.19754465]\n",
      "behavioural [ 0.14546727  0.07650387  0.06417615  0.45049819  0.05894516  0.20440933]\n",
      "target [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "target + tderr: [ 0.13843787  1.3085413   0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "action: 1\n",
      "argmax next_action: 3\n",
      "reward: 0.9451173207209318\n",
      "next_action [ 0.13843472  0.06949845  0.05882033  0.48356655  0.05212763  0.19755226]\n",
      "behavioural [ 0.14439327  0.07535081  0.06323156  0.4542799   0.05766767  0.20507681]\n",
      "target [ 0.13843432  0.06949806  0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "target + tderr: [  1.38434321e-01  -1.00000000e+02   5.88200055e-02   4.83568013e-01\n",
      "   5.21272197e-02   1.97552443e-01]\n",
      "action: 1\n",
      "argmax next_action: 3\n",
      "reward: -100.0\n",
      "next_action [ 0.13843472  0.06949845  0.05882033  0.48356655  0.05212763  0.19755226]\n",
      "behavioural [ 0.14439327  0.07535081  0.06323156  0.4542799   0.05766767  0.20507681]\n",
      "target [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "target + tderr: [ 0.14771423  0.07921243  0.06676368  1.28734303  0.06276181  0.194103  ]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: 0.9469377736886901\n",
      "next_action [ 0.13986205  0.070917    0.0599833   0.4784835   0.05363334  0.19712088]\n",
      "behavioural [ 0.15228666  0.08425859  0.07051608  0.42550659  0.06783158  0.19960055]\n",
      "target [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "target + tderr: [ 0.138631    1.30733633  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "action: 1\n",
      "argmax next_action: 3\n",
      "reward: 0.9469377736886901\n",
      "next_action [ 0.13846093  0.06952428  0.05884152  0.48347369  0.05215491  0.19754465]\n",
      "behavioural [ 0.14546727  0.07650387  0.06417615  0.45049819  0.05894516  0.20440933]\n",
      "target [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "target + tderr: [ 0.13843787  0.06950153  0.05882287  1.31008506  0.0521309   0.19755137]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: 0.9466611356412048\n",
      "next_action [ 0.13843472  0.06949845  0.05882033  0.48356655  0.05212763  0.19755226]\n",
      "behavioural [ 0.14439327  0.07535081  0.06323156  0.4542799   0.05766767  0.20507681]\n",
      "target [ 0.13843432  0.06949806  0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "target + tderr: [ 0.13843432  0.06949806  0.05882001  0.48356801  0.05212722  1.30705583]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: 0.943215947593413\n",
      "next_action [ 0.13843426  0.069498    0.05881996  0.48356816  0.05212716  0.19755244]\n",
      "behavioural [ 0.14424479  0.07519273  0.06310202  0.45479983  0.0574934   0.20516732]\n",
      "target [ 0.13843423  0.06949798  0.05881995  0.48356828  0.05212715  0.19755246]\n",
      "target + tderr: [ 0.13843423  0.06949798  0.05881995  1.29694331  0.05212715  0.19755246]\n",
      "action: 3\n",
      "argmax next_action: 3\n",
      "reward: 0.9330471491117579\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422464  0.07517131  0.06308445  0.45487025  0.05746979  0.20517959]\n",
      "target [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "target + tderr: [  1.38434231e-01   6.94979727e-02  -1.00000000e+02   4.83568281e-01\n",
      "   5.21271378e-02   1.97552413e-01]\n",
      "action: 2\n",
      "argmax next_action: 3\n",
      "reward: -100.0\n",
      "next_action [ 0.13843423  0.06949797  0.05881993  0.48356828  0.05212714  0.19755241]\n",
      "behavioural [ 0.14422464  0.07517131  0.06308445  0.45487025  0.05746979  0.20517959]\n",
      "target [ 0.14771423  0.07921243  0.06676368  0.44944486  0.06276181  0.194103  ]\n",
      "target + tderr: [ 0.14771423  0.07921243  0.06676368  0.44944486  1.28734303  0.194103  ]\n",
      "action: 4\n",
      "argmax next_action: 3\n",
      "reward: 0.9469377736886901\n",
      "next_action [ 0.13986205  0.070917    0.0599833   0.4784835   0.05363334  0.19712088]\n",
      "behavioural [ 0.15228666  0.08425859  0.07051608  0.42550659  0.06783158  0.19960055]\n",
      "target [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  0.19749497]\n",
      "target + tderr: [ 0.138631    0.06969203  0.0589791   0.48287073  0.05233217  1.30741799]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: 0.9470193796151806\n",
      "next_action [ 0.13846093  0.06952428  0.05884152  0.48347369  0.05215491  0.19754465]\n",
      "behavioural [ 0.14546727  0.07650387  0.06417615  0.45049819  0.05894516  0.20440933]\n",
      "target [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   0.19755137]\n",
      "target + tderr: [ 0.13843787  0.06950153  0.05882287  0.48355547  0.0521309   1.31043613]\n",
      "action: 5\n",
      "argmax next_action: 3\n",
      "reward: 0.9470122049038944\n",
      "next_action [ 0.13843472  0.06949845  0.05882033  0.48356655  0.05212763  0.19755226]\n",
      "behavioural [ 0.14439327  0.07535081  0.06323156  0.4542799   0.05766767  0.20507681]\n",
      "target [ 0.13843432  0.06949806  0.05882001  0.48356801  0.05212722  0.19755244]\n",
      "target + tderr: [ 0.13843432  0.06949806  1.31041014  0.48356801  0.05212722  0.19755244]\n",
      "action: 2\n",
      "argmax next_action: 3\n",
      "reward: 0.9465702729984393\n",
      "next_action [ 0.13843426  0.069498    0.05881996  0.48356816  0.05212716  0.19755244]\n",
      "behavioural [ 0.14424479  0.07519273  0.06310202  0.45479983  0.0574934   0.20516732]\n",
      "target [ 0.13843423  0.06949798  0.05881995  0.48356828  0.05212715  0.19755246]\n",
      "target + tderr: [  1.38434231e-01   6.94979802e-02   5.88199496e-02   4.83568281e-01\n",
      "  -1.00000000e+02   1.97552457e-01]\n",
      "action: 4\n",
      "argmax next_action: 3\n",
      "reward: -100.0\n",
      "next_action [ 0.13843426  0.069498    0.05881996  0.48356816  0.05212716  0.19755244]\n",
      "behavioural [ 0.14424479  0.07519273  0.06310202  0.45479983  0.0574934   0.20516732]\n"
     ]
    }
   ],
   "source": [
    "for mini in batch:\n",
    "    #print(\"reset\")\n",
    "    agent.model.reset_states() # we do this because the RNN is stateful\n",
    "    agent.target_model.reset_states()\n",
    "\n",
    "    for s,a,r,s_,done in mini:\n",
    "        s = s[None][None]\n",
    "        s_ = s_[None][None]\n",
    "        #print(\"predict\")\n",
    "        target = agent.model.predict(s)[0]\n",
    "        #print(\"target {}\".format(target))\n",
    "        if done:\n",
    "            target[a] = r\n",
    "        else:\n",
    "            a_ = agent.model.predict(s_)[0]\n",
    "            t = agent.target_model.predict(s)[0]\n",
    "            target[a] = r + agent.gamma * t[np.argmax(a_)]\n",
    "        #print(\"fit\")\n",
    "        '''\n",
    "        print(\"target + tderr: {}\".format(target))\n",
    "        print(\"action: {}\".format(a))\n",
    "        print(\"argmax next_action: {}\".format(np.argmax(a_)))\n",
    "        print(\"reward: {}\".format(r))\n",
    "        print(\"next_action {}\".format(a_))\n",
    "        print(\"behavioural {}\".format(t))\n",
    "        '''\n",
    "        res = self.model.fit(s, target, epochs=1,batch_size=1, verbose=0,shuffle=False)\n",
    "        self.save_scalar(self.loss_count,\"Loss\",res.history['loss'][0])\n",
    "        self.loss_count +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-21T22:17:22.803152Z",
     "start_time": "2018-01-21T22:17:22.790311Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b_s,b_a,b_r,b_s_,b_done = agent.memory.sample(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-21T22:25:46.116684Z",
     "start_time": "2018-01-21T22:25:46.113701Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T16:13:21.886637Z",
     "start_time": "2018-01-23T16:13:21.870007Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 3 required positional arguments: 'batch_size', 'name', and 'preprocessor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-8355cbdf5868>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mpre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAtariPreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m84\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m84\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mt_agent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstateCnt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactionCnt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcapacity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwindow_sz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreprocessor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"fake\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 3 required positional arguments: 'batch_size', 'name', and 'preprocessor'"
     ]
    }
   ],
   "source": [
    "stateCnt = atari_env.observation_space.shape\n",
    "actionCnt = atari_env.action_space.n\n",
    "capacity = 1000\n",
    "epsilon = 1\n",
    "gamma =  0.99\n",
    "window_sz = 5\n",
    "lr = 0.0001\n",
    "name = \"DRQN-Batch\"\n",
    "preprocessor = True\n",
    "pre = AtariPreprocessor((84,84,1))\n",
    "t_agent = Agent(stateCnt,actionCnt,capacity,epsilon,gamma,window_sz,lr,name,preprocessor,\"fake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T03:31:02.831928Z",
     "start_time": "2018-01-23T03:31:02.762131Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "prebatch_s,batch_a,batch_r,prebatch_s_,batch_done = agent.longmem.sample(batch_size)# a batch of episode of parameter length\n",
    "\n",
    "batch_s = agent.preprocessor.process_batch(prebatch_s)\n",
    "batch_s_ = agent.preprocessor.process_batch(prebatch_s_)\n",
    "a_ = agent.model.predict(batch_s_)\n",
    "a_idx = np.argmax(a_,axis=1)\n",
    "behaviour_q = agent.target_model.predict(batch_s_)\n",
    "target = agent.model.predict(batch_s)\n",
    "\n",
    "target[range(batch_size),batch_a.astype('int')] = batch_r + agent.gamma * (behaviour_q[range(batch_size),a_idx]) \n",
    "#loss = agent.model.train_on_batch(batch_s,target)\n",
    "#self.save_scalar(self.loss_count,\"/Loss\",loss)\n",
    "#self.loss_count +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T03:16:10.037547Z",
     "start_time": "2018-01-23T03:16:10.030345Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 5, 84, 84, 1)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T03:28:07.718308Z",
     "start_time": "2018-01-23T03:28:07.713695Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_img = np.squeeze(batch_s[0][2]*255.0,-1)\n",
    "img = Image.fromarray(t_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T03:27:58.194330Z",
     "start_time": "2018-01-23T03:27:58.050764Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7846727c50>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7846775588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T03:28:13.904304Z",
     "start_time": "2018-01-23T03:28:13.765997Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7846852cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T03:26:45.568266Z",
     "start_time": "2018-01-23T03:26:45.540249Z"
    },
    "code_folding": [
     1
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://gist.github.com/soply/f3eec2e79c165e39c9d540e916142ae1\n",
    "def show_images(images, cols = 1, titles = None):\n",
    "    \"\"\"Display a list of images in a single figure with matplotlib.\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    images: List of np.arrays compatible with plt.imshow.\n",
    "    \n",
    "    cols (Default = 1): Number of columns in figure (number of rows is \n",
    "                        set to np.ceil(n_images/float(cols))).\n",
    "    \n",
    "    titles: List of titles corresponding to each image. Must have\n",
    "            the same length as titles.\n",
    "    \"\"\"\n",
    "    assert((titles is None)or (len(images) == len(titles)))\n",
    "    n_images = len(images)\n",
    "    if titles is None: titles = ['Image (%d)' % i for i in range(1,n_images + 1)]\n",
    "    fig = plt.figure()\n",
    "    for n, (image, title) in enumerate(zip(images, titles)):\n",
    "        a = fig.add_subplot(cols, np.ceil(n_images/float(cols)), n + 1)\n",
    "        if image.ndim == 2:\n",
    "            plt.gray()\n",
    "        plt.imshow(np.squeeze(image,-1) )\n",
    "        a.set_title(title)\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T03:31:54.103494Z",
     "start_time": "2018-01-23T03:31:54.095818Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prebatch_s,batch_a,batch_r,prebatch_s_,batch_done = agent.longmem.sample(batch_size)# a batch of episode of parameter length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T03:34:48.819264Z",
     "start_time": "2018-01-23T03:34:48.814485Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 20,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0], dtype=int8)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T03:36:03.129384Z",
     "start_time": "2018-01-23T03:36:03.124937Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shortmem_s = agent.shortmem.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T03:36:12.716016Z",
     "start_time": "2018-01-23T03:36:11.777880Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABq8AAAFQCAYAAAAhlOROAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuqF5BQAAAAAAQDf+fzq1h61xrq/oAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7845c95ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_images(shortmem_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T03:40:33.428923Z",
     "start_time": "2018-01-23T03:40:12.757314Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error starting mission: A mission is already running.\n",
      "Error starting mission: A mission is already running.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T04:17:36.300842Z",
     "start_time": "2018-01-23T04:17:34.680582Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = [] \n",
    "for i in range(1):\n",
    "    # play loop\n",
    "    pre_s = atari_env.reset()\n",
    "    mem_s = pre.process_state_for_memory(pre_s) #scaled and grayscaled\n",
    "    net_s = pre.process_for_network(mem_s) # normalized\n",
    "    done = False\n",
    "    t_agent.shortmem.forget # forget short term memory for recurrent network \n",
    "    t_agent.shortmem.add(net_s)\n",
    "    for t in itertools.count():\n",
    "        hist_s = t_agent.shortmem.get()\n",
    "        # take action using net_s and receive a\n",
    "        a = t_agent.act(hist_s)\n",
    "        #atari_env.render()\n",
    "\n",
    "        pre_s_, r, done, info = atari_env.step(a)\n",
    "        \n",
    "        mem_s_ = pre.process_state_for_memory(pre_s) #scaled and grayscaled\n",
    "        net_s_ = pre.process_for_network(mem_s) # normalized\n",
    "        test.append(mem_s_)\n",
    "        t_agent.shortmem.add(net_s_)\n",
    "        t_agent.remember(mem_s,a,r,done)\n",
    "\n",
    "        #R[-1] += r\n",
    "        if done:\n",
    "\n",
    "            #agent.save_scalar(e,\"/reward per episode\",R[-1])\n",
    "            #print(\"episode: {}/{}, score: {}, e: {}\".format(e, episodes, t, agent.epsilon))\n",
    "            #exp.metric(\"reward\",R[-1])\n",
    "            #update(e,R[-1],handle1,rplot)\n",
    "            #R = [0.0]\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T04:11:20.221647Z",
     "start_time": "2018-01-23T04:11:20.213604Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prebatch_s,batch_a,batch_r,prebatch_s_,batch_done = t_agent.longmem.sample(batch_size)# a batch of episode of parameter length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T04:11:20.634467Z",
     "start_time": "2018-01-23T04:11:20.631223Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "short_mem = t_agent.shortmem.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T04:11:23.219683Z",
     "start_time": "2018-01-23T04:11:21.145949Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABq8AAAFQCAYAAAAhlOROAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7838e70710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABq8AAAFQCAYAAAAhlOROAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7838e70a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 10\n",
    "show_images(prebatch_s[idx])\n",
    "show_images(prebatch_s_[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T04:11:37.648301Z",
     "start_time": "2018-01-23T04:11:36.606827Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABq8AAAFQCAYAAAAhlOROAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7839276b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_images(short_mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-01-23T04:13:42.315Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-01-23T04:13:06.329Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-318-97695afcdfeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-175-295e4bacd630>\u001b[0m in \u001b[0;36mshow_images\u001b[0;34m(images, cols, titles)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_images\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/casper/lib/python3.5/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36madd_subplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1068\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_axstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1070\u001b[0;31m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubplot_class_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojection_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_axstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/casper/lib/python3.5/site-packages/matplotlib/axes/_subplots.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fig, *args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# _axes_class is set in the subplot_class_factory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_axes_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/casper/lib/python3.5/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fig, rect, facecolor, frameon, sharex, sharey, label, xscale, yscale, axisbg, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m  \u001b[0;31m# a dict from events to (id, func)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcla\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;31m# funcs used to format x and y - fall back on major formatters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt_xdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/casper/lib/python3.5/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mcla\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1082\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis_on\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/casper/lib/python3.5/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mset_clip_path\u001b[0;34m(self, clippath, transform)\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArtist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclippath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajorTicks\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminorTicks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m             \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclippath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/casper/lib/python3.5/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mset_clip_path\u001b[0;34m(self, clippath, transform)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclippath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArtist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclippath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgridline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclippath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/casper/lib/python3.5/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mset_clip_path\u001b[0;34m(self, path, transform)\u001b[0m\n\u001b[1;32m    652\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRectangle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m                 self.clipbox = TransformedBbox(Bbox.unit(),\n\u001b[0;32m--> 654\u001b[0;31m                                                path.get_transform())\n\u001b[0m\u001b[1;32m    655\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clippath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m                 \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/casper/lib/python3.5/site-packages/matplotlib/patches.py\u001b[0m in \u001b[0;36mget_transform\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mPatch\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \"\"\"\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_patch_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArtist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_data_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/casper/lib/python3.5/site-packages/matplotlib/patches.py\u001b[0m in \u001b[0;36mget_patch_transform\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_patch_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_patch_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rect_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/casper/lib/python3.5/site-packages/matplotlib/patches.py\u001b[0m in \u001b[0;36m_update_patch_transform\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0mrot_trans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAffine2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         \u001b[0mrot_trans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate_deg_around\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mangle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rect_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBboxTransformTo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rect_transform\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrot_trans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/casper/lib/python3.5/site-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36mrotate_deg_around\u001b[0;34m(self, x, y, degrees)\u001b[0m\n\u001b[1;32m   2036\u001b[0m         \u001b[0;31m# Cast to float to avoid wraparound issues with uint8's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2037\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2038\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate_deg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdegrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/casper/lib/python3.5/site-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36mrotate_deg\u001b[0;34m(self, degrees)\u001b[0m\n\u001b[1;32m   2014\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2015\u001b[0m         \"\"\"\n\u001b[0;32m-> 2016\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdegrees\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m180.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2018\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrotate_around\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/casper/lib/python3.5/site-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36mrotate\u001b[0;34m(self, theta)\u001b[0m\n\u001b[1;32m   2001\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2002\u001b[0m         rotate_mtx = np.array([[a, -b, 0.0], [b, a, 0.0], [0.0, 0.0, 1.0]],\n\u001b[0;32m-> 2003\u001b[0;31m                               float)\n\u001b[0m\u001b[1;32m   2004\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mtx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrotate_mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mtx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "show_images(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T04:08:07.378987Z",
     "start_time": "2018-01-23T04:08:07.352839Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_s = atari_env.reset()\n",
    "mem_s = pre.process_state_for_memory(pre_s) #scaled and grayscaled\n",
    "net_s = pre.process_for_network(mem_s) # normalized\n",
    "done = False\n",
    "t_agent.shortmem.forget() # forget short term memory for recurrent network \n",
    "t_agent.shortmem.add(net_s)\n",
    "atari_env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T04:10:24.567009Z",
     "start_time": "2018-01-23T04:10:24.549728Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = t_agent.act(hist_s)\n",
    "atari_env.render()\n",
    "\n",
    "pre_s_, r, done, info = atari_env.step(a)\n",
    "\n",
    "mem_s_ = pre.process_state_for_memory(pre_s) #scaled and grayscaled\n",
    "net_s_ = pre.process_for_network(mem_s) # normalized\n",
    "t_agent.shortmem.add(net_s_)\n",
    "t_agent.remember(mem_s,a,r,done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T04:10:10.483097Z",
     "start_time": "2018-01-23T04:10:10.478315Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_agent.act(hist_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T04:07:06.561286Z",
     "start_time": "2018-01-23T04:07:06.391977Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAEICAYAAAB/KknhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f783d0ab3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_images(net_s[None]*255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T04:09:09.964710Z",
     "start_time": "2018-01-23T04:09:09.958517Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist_s = t_agent.shortmem.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T04:09:11.505633Z",
     "start_time": "2018-01-23T04:09:10.475291Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABq8AAAFQCAYAAAAhlOROAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABgMP5/p+kl1wUt1cwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f783bc765c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_images(hist_s*255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T04:01:25.960783Z",
     "start_time": "2018-01-23T04:01:25.951488Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 84, 84, 1)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_agent.shortmem.mem_hist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T04:02:48.070304Z",
     "start_time": "2018-01-23T04:02:48.063977Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_agent.shortmem.current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:casper]",
   "language": "python",
   "name": "conda-env-casper-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
