{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MalmoPython\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import numpy as numpy\n",
    "import time\n",
    "from IPython.display import clear_output,display\n",
    "import logging\n",
    "import math\n",
    "actions = {\n",
    "    'strafe':{\n",
    "        'left': 'strafe -1',\n",
    "        'right': 'strafe 1'\n",
    "    },\n",
    "    'move':{\n",
    "        'back':'move -1',\n",
    "        'forward':'move 1'\n",
    "    },\n",
    "    'pitch':{\n",
    "        'up':'pitch -0.03',\n",
    "        'down':'pitch 0.03'\n",
    "    },\n",
    "    'turn':{\n",
    "        'anti':'turn -1',\n",
    "        'clk':'turn 1'\n",
    "    },\n",
    "    'jump':{\n",
    "        'on':'jump 1',\n",
    "        'off':'jump 0'\n",
    "    },\n",
    "    'attack':{\n",
    "        'on': 'attack 1',\n",
    "        'off': 'attack 0'\n",
    "    },\n",
    "    'use':{\n",
    "        'on': 'use 1',\n",
    "        'off': 'use 0'\n",
    "    },\n",
    "    'crouch':{\n",
    "        'on':'crouch 1',\n",
    "        'off':'crouch 0'\n",
    "    }\n",
    "}\n",
    "# Create default Malmo objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_actions = {\n",
    "    'strafe':{\n",
    "        'left': 'strafe -1',\n",
    "        'right': 'strafe 1'\n",
    "    },\n",
    "    'move':{\n",
    "        'back':'move -1',\n",
    "        'forward':'move 1'\n",
    "    }   \n",
    "}\n",
    "# flatten dict of actions\n",
    "ractions = []\n",
    "for action_type in simple_actions.keys():\n",
    "    \n",
    "    for action in simple_actions[action_type]:\n",
    "        ractions.append(simple_actions[action_type][action])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Brain:\n",
    "    def __init__(self, stateCnt, actionCnt):\n",
    "        self.stateCnt = stateCnt\n",
    "        self.actionCnt = actionCnt\n",
    "\n",
    "        self.model = self._createModel()\n",
    "        # self.model.load_weights(\"cartpole-basic.h5\")\n",
    "\n",
    "    def _createModel(self):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(output_dim=64, activation='relu', input_dim=self.stateCnt))\n",
    "        model.add(Dense(output_dim=self.actionCnt, activation='linear'))\n",
    "\n",
    "        opt = RMSprop(lr=0.00025)\n",
    "        model.compile(loss='mse', optimizer=opt)\n",
    "\n",
    "        return model\n",
    "\n",
    "    def train(self, x, y, epoch=1, verbose=0):\n",
    "        self.model.fit(x, y, batch_size=64, nb_epoch=epoch, verbose=verbose)\n",
    "\n",
    "    def predict(self, s):\n",
    "        return numpy.array(self.model.predict(s))\n",
    "\n",
    "    def predictOne(self, s):\n",
    "        return self.predict(s.reshape(1, self.stateCnt)).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self, x, y):\n",
    "    model.fit(x, y, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory:   # stored as ( s, a, r, s_ )\n",
    "    samples = []\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "\n",
    "    def add(self, sample):\n",
    "        self.samples.append(sample)        \n",
    "\n",
    "        if len(self.samples) > self.capacity:\n",
    "            self.samples.pop(0)\n",
    "\n",
    "    def sample(self, n):\n",
    "        n = min(n, len(self.samples))\n",
    "        return random.sample(self.samples, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEMORY_CAPACITY = 100000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "GAMMA = 0.99\n",
    "\n",
    "MAX_EPSILON = 1\n",
    "MIN_EPSILON = 0.01\n",
    "LAMBDA = 0.001      # speed of decay\n",
    "\n",
    "class Agent:\n",
    "    steps = 0\n",
    "    epsilon = MAX_EPSILON\n",
    "\n",
    "    def __init__(self, stateCnt, actionCnt,actions):\n",
    "        self.stateCnt = stateCnt\n",
    "        self.actionCnt = actionCnt\n",
    "        self.actions = actions\n",
    "\n",
    "        self.brain = Brain(stateCnt, actionCnt)\n",
    "        self.memory = Memory(MEMORY_CAPACITY)\n",
    "        \n",
    "    def act(self, s):\n",
    "        # Epsilon greedy action selection\n",
    "        if random.random() < self.epsilon:\n",
    "            act_int = random.randint(0, self.actionCnt-1)\n",
    "        else:\n",
    "            act_int = numpy.argmax(self.brain.predictOne(s))\n",
    "        return self.actions[act_int],act_int\n",
    "\n",
    "    def observe(self, sample):  # in (s, a, r, s_) format\n",
    "        self.memory.add(sample)        \n",
    "\n",
    "        # slowly decrease Epsilon based on our eperience\n",
    "        self.steps += 1\n",
    "        self.epsilon = MIN_EPSILON + (MAX_EPSILON - MIN_EPSILON) * math.exp(-LAMBDA * self.steps)\n",
    "\n",
    "    def replay(self):    \n",
    "        batch = self.memory.sample(BATCH_SIZE)\n",
    "        batchLen = len(batch)\n",
    "\n",
    "        no_state = numpy.zeros(self.stateCnt)\n",
    "\n",
    "        states = numpy.array([ o[0] for o in batch ])\n",
    "        states_ = numpy.array([ (no_state if o[3] is None else o[3]) for o in batch ])\n",
    "\n",
    "        p = agent.brain.predict(states)\n",
    "        p_ = agent.brain.predict(states_)\n",
    "\n",
    "        x = numpy.zeros((batchLen, self.stateCnt))\n",
    "        y = numpy.zeros((batchLen, self.actionCnt))\n",
    "        \n",
    "        for i in range(batchLen):\n",
    "            o = batch[i]\n",
    "            s = o[0]\n",
    "            a = o[1]\n",
    "            r = o[2]\n",
    "            s_ = o[3]\n",
    "            \n",
    "            t = p[i]\n",
    "            if s_ is None:\n",
    "                t[a] = r\n",
    "            else:\n",
    "                t[a] = r + GAMMA * numpy.amax(p_[i])\n",
    "                \n",
    "\n",
    "            x[i] = s\n",
    "            y[i] = t\n",
    "            \n",
    "            self.brain.train(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Env:\n",
    "    def __init__(self, agent,agent_host):\n",
    "        self.world_state = None\n",
    "        self.agent = agent\n",
    "        self.agent_host = agent_host\n",
    "        self.my_mission_record = MalmoPython.MissionRecordSpec()\n",
    "        self.episode_length = 100\n",
    "        self.data = None\n",
    "    def parse_state(self):\n",
    "        #data = json.loads(state.observations[-1].text)\n",
    "        \n",
    "        self.world_state = self.agent_host.peekWorldState()\n",
    "        while self.world_state.is_mission_running and all(e.text=='{}' for e in self.world_state.observations):\n",
    "            self.world_state = self.agent_host.peekWorldState()\n",
    "   \n",
    "        # If there are some new observations\n",
    "        if self.world_state.number_of_observations_since_last_state > 0:\n",
    "            print(\"observed\")\n",
    "            self.data = json.loads(self.world_state.observations[-1].text)\n",
    "        \n",
    "        state = self.world_state\n",
    "            \n",
    "        #data = json.loads(state.observations[-1].text)\n",
    "        # get reward if detected, else reward is -1\n",
    "        reward = -1\n",
    "        if state.number_of_rewards_since_last_state > 0:\n",
    "            reward = state.rewards[0].getValue()\n",
    "    \n",
    "        # reformat grid to a vector that only show the floor with blocks\n",
    "        grid = self.data['grid'][:16]\n",
    "        new_grid = list()\n",
    "        for i,item in enumerate(grid):\n",
    "            if 'lava' in item:\n",
    "                new_grid.append(1)\n",
    "            else:\n",
    "                new_grid.append(0)\n",
    "        #self.data['grid'] = new_grid\n",
    "        \n",
    "        return(reward,new_grid,self.data,state)\n",
    "        \n",
    "    def startworld(self,world_file):\n",
    "        \n",
    "        with open('CliffWalking.xml','r') as f:\n",
    "            my_mission = MalmoPython.MissionSpec(f.read(), True)\n",
    "        my_mission_record = MalmoPython.MissionRecordSpec()\n",
    "        # Attempt to start a mission:\n",
    "        max_retries = 3\n",
    "        for retry in range(max_retries):\n",
    "            try:\n",
    "                self.agent_host.startMission( my_mission, my_mission_record )\n",
    "                sys.stdout.write(\"Mission Started\")\n",
    "                break\n",
    "            except RuntimeError as e:\n",
    "                if retry == max_retries - 1:\n",
    "                    print \"Error starting mission:\",e\n",
    "                    exit(1)\n",
    "                else:\n",
    "                    time.sleep(2)\n",
    "        # Loop until mission starts:\n",
    "        print \"Waiting for the mission to start \",\n",
    "        self.world_state = self.agent_host.getWorldState()\n",
    "        while (not self.world_state.has_mission_begun):\n",
    "            sys.stdout.write(\".\")\n",
    "            time.sleep(0.1)\n",
    "            self.world_state = self.agent_host.getWorldState()\n",
    "            for error in self.world_state.errors:\n",
    "                print \"Error:\",error.text\n",
    "                \n",
    "        ## wait until a valid observation        \n",
    "        while self.world_state.is_mission_running and all(e.text=='{}' for e in self.world_state.observations):\n",
    "            self.world_state = self.agent_host.peekWorldState()\n",
    "        #populate emtpy fields for init\n",
    "        self.data = json.loads(self.world_state.observations[-1].text)\n",
    "        \n",
    "        return self.parse_state() \n",
    "    def run(self,world,epochs=0):\n",
    "        # load world\n",
    "        R = 0\n",
    "        for i in range(epochs):\n",
    "            _, s, obs,ws = self.startworld(world)\n",
    "            mission_run = ws.is_mission_running\n",
    "            while(mission_run):\n",
    "                # get state\n",
    "                time.sleep(1)\n",
    "                \n",
    "                # act\n",
    "                send_a,a = agent.act(s)\n",
    "                print(\"action:{}\".format(send_a))\n",
    "                self.agent_host.sendCommand(send_a)\n",
    "\n",
    "                \n",
    "                # observe\n",
    "                #print(a)\n",
    "                r,s_prime,obs,ws = self.parse_state()\n",
    "                mission_run = ws.is_mission_running\n",
    "                #print(\"sample:{}\".format(a))\n",
    "                self.agent.observe((s,a,r,s_prime))\n",
    "                self.agent.replay()\n",
    "                \n",
    "                s = s_prime\n",
    "                R += r\n",
    "                if (not  mission_run):\n",
    "                    print(\"episode done\")\n",
    "                    time.sleep(1)\n",
    "                \n",
    "            print(\"done epoch: {}\".format(i))\n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "                \n",
    "        #loop\n",
    "        # observe\n",
    "        \n",
    "        # take action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for manual code execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: unrecognised option '-f'\n",
      "Malmo version: 0.31.0\n",
      "\n",
      "Allowed options:\n",
      "  -h [ --help ]         show description of allowed options\n",
      "  --test                run this as an integration test\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "agent_host = MalmoPython.AgentHost()\n",
    "try:\n",
    "    agent_host.parse( sys.argv )\n",
    "except RuntimeError as e:\n",
    "    print 'ERROR:',e\n",
    "    print agent_host.getUsage()\n",
    "    exit(1)\n",
    "if agent_host.receivedArgument(\"help\"):\n",
    "    print agent_host.getUsage()\n",
    "    exit(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the mission to start .....\n"
     ]
    }
   ],
   "source": [
    "# load world\n",
    "with open('CliffWalking.xml','r') as f:\n",
    "    my_mission = MalmoPython.MissionSpec(f.read(), True)\n",
    "my_mission_record = MalmoPython.MissionRecordSpec()\n",
    " \n",
    "# Attempt to start a mission:\n",
    "max_retries = 3\n",
    "\n",
    "for retry in range(max_retries):\n",
    "    try:\n",
    "        agent_host.startMission( my_mission, my_mission_record )\n",
    "        break\n",
    "    except RuntimeError as e:\n",
    "        if retry == max_retries - 1:\n",
    "            print \"Error starting mission:\",e\n",
    "            exit(1)\n",
    "        else:\n",
    "            time.sleep(2)\n",
    "\n",
    "# Loop until mission starts:\n",
    "print \"Waiting for the mission to start \",\n",
    "world_state = agent_host.getWorldState()\n",
    "\n",
    "while not world_state.has_mission_begun:\n",
    "    sys.stdout.write(\".\")\n",
    "    time.sleep(0.1)\n",
    "    world_state = agent_host.getWorldState()\n",
    "    for error in world_state.errors:\n",
    "        print \"Error:\",error.text\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mission StartedWaiting for the mission to start ..... observed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-1,\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " {u'Air': 300,\n",
       "  u'DamageDealt': 0,\n",
       "  u'DamageTaken': 0,\n",
       "  u'DistanceTravelled': 2688,\n",
       "  u'Food': 20,\n",
       "  u'IsAlive': True,\n",
       "  u'Life': 20.0,\n",
       "  u'MobsKilled': 0,\n",
       "  u'Name': u'Cristina',\n",
       "  u'Pitch': 0.0,\n",
       "  u'PlayersKilled': 0,\n",
       "  u'Score': 0,\n",
       "  u'TimeAlive': 24819,\n",
       "  u'TotalTime': 24828,\n",
       "  u'WorldTime': 6000,\n",
       "  u'XP': 0,\n",
       "  u'XPos': 4.5,\n",
       "  u'YPos': 46.0,\n",
       "  u'Yaw': 0.0,\n",
       "  u'ZPos': 1.5,\n",
       "  u'grid': [u'air',\n",
       "   u'air',\n",
       "   u'air',\n",
       "   u'air',\n",
       "   u'air',\n",
       "   u'air',\n",
       "   u'air',\n",
       "   u'air',\n",
       "   u'air',\n",
       "   u'air',\n",
       "   u'air',\n",
       "   u'air',\n",
       "   u'air',\n",
       "   u'air',\n",
       "   u'air',\n",
       "   u'air',\n",
       "   u'air',\n",
       "   u'air',\n",
       "   u'air',\n",
       "   u'air',\n",
       "   u'air',\n",
       "   u'air',\n",
       "   u'air',\n",
       "   u'air',\n",
       "   u'air']},\n",
       " <MalmoPython.WorldState at 0x7f8f419525f0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_env = Env(None,agent_host)\n",
    "\n",
    "\"\"\"\n",
    "while world_state.is_mission_running:\n",
    "    time.sleep(2)\n",
    "    world_state = agent_host.getWorldState()\n",
    "    # print(chose_act)\n",
    "    clear_output(wait=True)\n",
    "    display(test_env.parse_state())\n",
    "    # agent_host.sendCommand(chose_act)\n",
    "    for error in world_state.errors:\n",
    "        print \"Error:\",error.text\n",
    "\"\"\"\n",
    "\n",
    "test_env.startworld('CliffWalking.xml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-1,\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " {u'Air': 300,\n",
       "  u'DamageDealt': 0,\n",
       "  u'DamageTaken': 0,\n",
       "  u'DistanceTravelled': 2688,\n",
       "  u'Food': 20,\n",
       "  u'IsAlive': True,\n",
       "  u'Life': 20.0,\n",
       "  u'MobsKilled': 0,\n",
       "  u'Name': u'Cristina',\n",
       "  u'Pitch': 0.0,\n",
       "  u'PlayersKilled': 0,\n",
       "  u'Score': 0,\n",
       "  u'TimeAlive': 20737,\n",
       "  u'TotalTime': 20746,\n",
       "  u'WorldTime': 6000,\n",
       "  u'XP': 0,\n",
       "  u'XPos': 4.5,\n",
       "  u'YPos': 46.0,\n",
       "  u'Yaw': 0.0,\n",
       "  u'ZPos': 1.5,\n",
       "  u'grid': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]},\n",
       " <MalmoPython.WorldState at 0x7f49eeef3320>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_env.parse_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_host.sendCommand('quit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4703282292062327e-323"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = numpy.ndarray([1,2,3])\n",
    "numpy.amax(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-101.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_host.getWorldState().rewards[0].getValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda2/envs/mine-env/lib/python2.7/site-packages/ipykernel/__main__.py:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=64, activation=\"relu\", input_dim=16)`\n",
      "/home/ubuntu/miniconda2/envs/mine-env/lib/python2.7/site-packages/ipykernel/__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=4, activation=\"linear\")`\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(16,len(ractions),ractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Env(agent,agent_host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mission StartedWaiting for the mission to start ..... observed\n",
      "action:move -1\n",
      "observed\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected dense_9_input to have shape (None, 16) but got array with shape (60, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-844618d05be3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CliffWalking.xml\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-a52ff6508ba3>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, world, epochs)\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0;31m#print(\"sample:{}\".format(a))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms_prime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms_prime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-6a27add680d8>\u001b[0m in \u001b[0;36mreplay\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mstates_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mno_state\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mp_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-48055fc941e6>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredictOne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/miniconda2/envs/mine-env/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/miniconda2/envs/mine-env/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1574\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1575\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1576\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1577\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1578\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/miniconda2/envs/mine-env/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking : expected dense_9_input to have shape (None, 16) but got array with shape (60, 1)"
     ]
    }
   ],
   "source": [
    "env.run(\"CliffWalking.xml\",100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mine-env]",
   "language": "python",
   "name": "conda-env-mine-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
