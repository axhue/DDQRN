{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MalmoPython\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import numpy as numpy\n",
    "import time\n",
    "from IPython.display import clear_output,display\n",
    "import logging\n",
    "import math\n",
    "actions = {\n",
    "    'strafe':{\n",
    "        'left': 'strafe -1',\n",
    "        'right': 'strafe 1'\n",
    "    },\n",
    "    'move':{\n",
    "        'back':'move -1',\n",
    "        'forward':'move 1'\n",
    "    },\n",
    "    'pitch':{\n",
    "        'up':'pitch -0.03',\n",
    "        'down':'pitch 0.03'\n",
    "    },\n",
    "    'turn':{\n",
    "        'anti':'turn -1',\n",
    "        'clk':'turn 1'\n",
    "    },\n",
    "    'jump':{\n",
    "        'on':'jump 1',\n",
    "        'off':'jump 0'\n",
    "    },\n",
    "    'attack':{\n",
    "        'on': 'attack 1',\n",
    "        'off': 'attack 0'\n",
    "    },\n",
    "    'use':{\n",
    "        'on': 'use 1',\n",
    "        'off': 'use 0'\n",
    "    },\n",
    "    'crouch':{\n",
    "        'on':'crouch 1',\n",
    "        'off':'crouch 0'\n",
    "    }\n",
    "}\n",
    "# Create default Malmo objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_actions = {\n",
    "    'strafe':{\n",
    "        'left': 'strafe -1',\n",
    "        'right': 'strafe 1'\n",
    "    },\n",
    "    'move':{\n",
    "        'back':'move -1',\n",
    "        'forward':'move 1'\n",
    "    }   \n",
    "}\n",
    "# flatten dict of actions\n",
    "ractions = []\n",
    "for action_type in simple_actions.keys():\n",
    "    \n",
    "    for action in simple_actions[action_type]:\n",
    "        ractions.append(simple_actions[action_type][action])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Brain:\n",
    "    def __init__(self, stateCnt, actionCnt):\n",
    "        self.stateCnt = stateCnt\n",
    "        self.actionCnt = actionCnt\n",
    "\n",
    "        self.model = self._createModel()\n",
    "        # self.model.load_weights(\"cartpole-basic.h5\")\n",
    "\n",
    "    def _createModel(self):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(output_dim=64, activation='relu', input_dim=self.stateCnt))\n",
    "        model.add(Dense(output_dim=self.actionCnt, activation='linear'))\n",
    "\n",
    "        opt = RMSprop(lr=0.00025)\n",
    "        model.compile(loss='mse', optimizer=opt)\n",
    "\n",
    "        return model\n",
    "\n",
    "    def train(self, x, y, epoch=1, verbose=0):\n",
    "        self.model.fit(x, y, batch_size=64, nb_epoch=epoch, verbose=verbose)\n",
    "\n",
    "    def predict(self, s):\n",
    "        return numpy.array(self.model.predict(s))\n",
    "\n",
    "    def predictOne(self, s):\n",
    "        return self.predict(s.reshape(1, self.stateCnt)).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self, x, y):\n",
    "    model.fit(x, y, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory:   # stored as ( s, a, r, s_ )\n",
    "    samples = []\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "\n",
    "    def add(self, sample):\n",
    "        self.samples.append(sample)        \n",
    "\n",
    "        if len(self.samples) > self.capacity:\n",
    "            self.samples.pop(0)\n",
    "\n",
    "    def sample(self, n):\n",
    "        n = min(n, len(self.samples))\n",
    "        return random.sample(self.samples, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEMORY_CAPACITY = 100000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "GAMMA = 0.99\n",
    "\n",
    "MAX_EPSILON = 1\n",
    "MIN_EPSILON = 0.01\n",
    "LAMBDA = 0.001      # speed of decay\n",
    "\n",
    "class Agent:\n",
    "    steps = 0\n",
    "    epsilon = MAX_EPSILON\n",
    "\n",
    "    def __init__(self, stateCnt, actionCnt,actions):\n",
    "        self.stateCnt = stateCnt\n",
    "        self.actionCnt = actionCnt\n",
    "        self.actions = actions\n",
    "\n",
    "        self.brain = Brain(stateCnt, actionCnt)\n",
    "        self.memory = Memory(MEMORY_CAPACITY)\n",
    "        \n",
    "    def act(self, s):\n",
    "        # Epsilon greedy action selection\n",
    "        if random.random() < self.epsilon:\n",
    "            act_int = random.randint(0, self.actionCnt-1)\n",
    "        else:\n",
    "            act_int = numpy.argmax(self.brain.predictOne(s))\n",
    "        return self.actions[act_int],act_int\n",
    "\n",
    "    def observe(self, sample):  # in (s, a, r, s_) format\n",
    "        self.memory.add(sample)        \n",
    "\n",
    "        # slowly decrease Epsilon based on our eperience\n",
    "        self.steps += 1\n",
    "        self.epsilon = MIN_EPSILON + (MAX_EPSILON - MIN_EPSILON) * math.exp(-LAMBDA * self.steps)\n",
    "\n",
    "    def replay(self):    \n",
    "        batch = self.memory.sample(BATCH_SIZE)\n",
    "        batchLen = len(batch)\n",
    "\n",
    "        no_state = numpy.zeros(self.stateCnt)\n",
    "\n",
    "        states = numpy.array([ o[0] for o in batch ])\n",
    "        states_ = numpy.array([ (no_state if o[3] is None else o[3]) for o in batch ])\n",
    "\n",
    "        p = agent.brain.predict(states)\n",
    "        p_ = agent.brain.predict(states_)\n",
    "\n",
    "        x = numpy.zeros((batchLen, self.stateCnt))\n",
    "        y = numpy.zeros((batchLen, self.actionCnt))\n",
    "        \n",
    "        for i in range(batchLen):\n",
    "            o = batch[i]\n",
    "            s = o[0]\n",
    "            a = o[1]\n",
    "            r = o[2]\n",
    "            s_ = o[3]\n",
    "            \n",
    "            t = p[i]\n",
    "            if s_ is None:\n",
    "                t[a] = r\n",
    "            else:\n",
    "                t[a] = r + GAMMA * numpy.amax(p_[i])\n",
    "                \n",
    "\n",
    "            x[i] = s\n",
    "            y[i] = t\n",
    "            \n",
    "            self.brain.train(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-36-e1a23fc5f01a>, line 82)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-36-e1a23fc5f01a>\"\u001b[0;36m, line \u001b[0;32m82\u001b[0m\n\u001b[0;31m    done = obs.is_mission running\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class Env:\n",
    "    def __init__(self, agent,agent_host):\n",
    "        self.world_state = None\n",
    "        self.agent = agent\n",
    "        self.agent_host = agent_host\n",
    "        self.my_mission_record = MalmoPython.MissionRecordSpec()\n",
    "        self.episode_length = 100\n",
    "        self.data = None\n",
    "    def parse_state(self):\n",
    "        #data = json.loads(state.observations[-1].text)\n",
    "        \n",
    "        self.world_state = self.agent_host.peekWorldState()\n",
    "        while self.world_state.is_mission_running and all(e.text=='{}' for e in self.world_state.observations):\n",
    "            self.world_state = self.agent_host.peekWorldState()\n",
    "   \n",
    "        # If there are some new observations\n",
    "        if self.world_state.number_of_observations_since_last_state > 0:\n",
    "            print(\"observed\")\n",
    "            self.data = json.loads(self.world_state.observations[-1].text)\n",
    "        \n",
    "        state = self.world_state\n",
    "            \n",
    "        #data = json.loads(state.observations[-1].text)\n",
    "        # get reward if detected, else reward is -1\n",
    "        reward = -1\n",
    "        if state.number_of_rewards_since_last_state > 0:\n",
    "            reward = state.rewards[0].getValue()\n",
    "    \n",
    "        # reformat grid to a vector that only show the floor with blocks\n",
    "        grid = self.data['grid'][:9]\n",
    "        new_grid = list()\n",
    "        for i,item in enumerate(grid):\n",
    "            if item == 'lava':\n",
    "                new_grid.append(1)\n",
    "            else:\n",
    "                new_grid.append(0)\n",
    "        self.data['grid'] = new_grid\n",
    "        \n",
    "        return(reward,new_grid,self.data)\n",
    "        \n",
    "    def startworld(self,world_file):\n",
    "        \n",
    "        with open('CliffWalking.xml','r') as f:\n",
    "            my_mission = MalmoPython.MissionSpec(f.read(), True)\n",
    "        my_mission_record = MalmoPython.MissionRecordSpec()\n",
    "        # Attempt to start a mission:\n",
    "        max_retries = 3\n",
    "        for retry in range(max_retries):\n",
    "            try:\n",
    "                self.agent_host.startMission( my_mission, my_mission_record )\n",
    "                sys.stdout.write(\"Mission Started\")\n",
    "                break\n",
    "            except RuntimeError as e:\n",
    "                if retry == max_retries - 1:\n",
    "                    print \"Error starting mission:\",e\n",
    "                    exit(1)\n",
    "                else:\n",
    "                    time.sleep(2)\n",
    "        # Loop until mission starts:\n",
    "        print \"Waiting for the mission to start \",\n",
    "        self.world_state = self.agent_host.getWorldState()\n",
    "        while (not self.world_state.has_mission_begun):\n",
    "            sys.stdout.write(\".\")\n",
    "            time.sleep(0.1)\n",
    "            self.world_state = self.agent_host.getWorldState()\n",
    "            for error in self.world_state.errors:\n",
    "                print \"Error:\",error.text\n",
    "                \n",
    "        ## wait until a valid observation        \n",
    "        while self.world_state.is_mission_running and all(e.text=='{}' for e in self.world_state.observations):\n",
    "            self.world_state = self.agent_host.peekWorldState()\n",
    "        #populate emtpy fields for init\n",
    "        self.data = json.loads(self.world_state.observations[-1].text)\n",
    "        \n",
    "        return self.parse_state() \n",
    "    def run(self,world,epochs=0):\n",
    "        # load world\n",
    "        R = 0\n",
    "        for i in range(epochs):\n",
    "            _, s, obs = self.startworld(world)\n",
    "            print(\"restarting world\")\n",
    "            done = obs.is_mission running\n",
    "            while(not done):\n",
    "                # get state\n",
    "                time.sleep(1)\n",
    "                \n",
    "                # act\n",
    "                send_a,a = agent.act(s)\n",
    "                #print(\"action:{}\".format(send_a))\n",
    "                self.agent_host.sendCommand(send_a)\n",
    "\n",
    "                \n",
    "                # observe\n",
    "                #print(a)\n",
    "                r,s_prime,obs = self.parse_state()\n",
    "                done = obs.is_mission running\n",
    "                #print(\"sample:{}\".format(a))\n",
    "                self.agent.observe((s,a,r,s_prime))\n",
    "                self.agent.replay()\n",
    "                \n",
    "                s = s_prime\n",
    "                R += r\n",
    "                if (done):\n",
    "                    print(\"episode done\")\n",
    "                \n",
    "            print(\"done epoch: {}\".format(i))\n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "                \n",
    "        #loop\n",
    "        # observe\n",
    "        \n",
    "        # take action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for manual code execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: unrecognised option '-f'\n",
      "Malmo version: 0.31.0\n",
      "\n",
      "Allowed options:\n",
      "  -h [ --help ]         show description of allowed options\n",
      "  --test                run this as an integration test\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "agent_host = MalmoPython.AgentHost()\n",
    "try:\n",
    "    agent_host.parse( sys.argv )\n",
    "except RuntimeError as e:\n",
    "    print 'ERROR:',e\n",
    "    print agent_host.getUsage()\n",
    "    exit(1)\n",
    "if agent_host.receivedArgument(\"help\"):\n",
    "    print agent_host.getUsage()\n",
    "    exit(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the mission to start .....\n"
     ]
    }
   ],
   "source": [
    "# load world\n",
    "with open('CliffWalking.xml','r') as f:\n",
    "    my_mission = MalmoPython.MissionSpec(f.read(), True)\n",
    "my_mission_record = MalmoPython.MissionRecordSpec()\n",
    " \n",
    "# Attempt to start a mission:\n",
    "max_retries = 3\n",
    "\n",
    "for retry in range(max_retries):\n",
    "    try:\n",
    "        agent_host.startMission( my_mission, my_mission_record )\n",
    "        break\n",
    "    except RuntimeError as e:\n",
    "        if retry == max_retries - 1:\n",
    "            print \"Error starting mission:\",e\n",
    "            exit(1)\n",
    "        else:\n",
    "            time.sleep(2)\n",
    "\n",
    "# Loop until mission starts:\n",
    "print \"Waiting for the mission to start \",\n",
    "world_state = agent_host.getWorldState()\n",
    "\n",
    "while not world_state.has_mission_begun:\n",
    "    sys.stdout.write(\".\")\n",
    "    time.sleep(0.1)\n",
    "    world_state = agent_host.getWorldState()\n",
    "    for error in world_state.errors:\n",
    "        print \"Error:\",error.text\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mission StartedWaiting for the mission to start ..... observed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-1,\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " {u'Air': 300,\n",
       "  u'DamageDealt': 0,\n",
       "  u'DamageTaken': 0,\n",
       "  u'DistanceTravelled': 96,\n",
       "  u'Food': 20,\n",
       "  u'IsAlive': True,\n",
       "  u'Life': 20.0,\n",
       "  u'MobsKilled': 0,\n",
       "  u'Name': u'Cristina',\n",
       "  u'Pitch': 0.0,\n",
       "  u'PlayersKilled': 0,\n",
       "  u'Score': 0,\n",
       "  u'TimeAlive': 2752,\n",
       "  u'TotalTime': 2798,\n",
       "  u'WorldTime': 6000,\n",
       "  u'XP': 0,\n",
       "  u'XPos': 4.5,\n",
       "  u'YPos': 46.0,\n",
       "  u'Yaw': 0.0,\n",
       "  u'ZPos': 1.5,\n",
       "  u'grid': [0, 0, 0, 0, 0, 0, 0, 0, 0]})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_env = Env(None,agent_host)\n",
    "\n",
    "\"\"\"\n",
    "while world_state.is_mission_running:\n",
    "    time.sleep(2)\n",
    "    world_state = agent_host.getWorldState()\n",
    "    # print(chose_act)\n",
    "    clear_output(wait=True)\n",
    "    display(test_env.parse_state())\n",
    "    # agent_host.sendCommand(chose_act)\n",
    "    for error in world_state.errors:\n",
    "        print \"Error:\",error.text\n",
    "\"\"\"\n",
    "\n",
    "test_env.startworld('CliffWalking.xml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " observed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-1,\n",
       " [1, 1, 1, 0, 0, 1, 0, 1, 1],\n",
       " {u'Air': 300,\n",
       "  u'DamageDealt': 0,\n",
       "  u'DamageTaken': 0,\n",
       "  u'DistanceTravelled': 48,\n",
       "  u'Food': 20,\n",
       "  u'IsAlive': True,\n",
       "  u'Life': 20.0,\n",
       "  u'MobsKilled': 0,\n",
       "  u'Name': u'Cristina',\n",
       "  u'Pitch': 0.0,\n",
       "  u'PlayersKilled': 0,\n",
       "  u'Score': 0,\n",
       "  u'TimeAlive': 96405,\n",
       "  u'TotalTime': 96416,\n",
       "  u'WorldTime': 6000,\n",
       "  u'XP': 0,\n",
       "  u'XPos': 4.5,\n",
       "  u'YPos': 46.0,\n",
       "  u'Yaw': 0.0,\n",
       "  u'ZPos': 1.5,\n",
       "  u'grid': [1, 1, 1, 0, 0, 1, 0, 1, 1]})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_env.parse_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_host.sendCommand('quit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4703282292062327e-323"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = numpy.ndarray([1,2,3])\n",
    "numpy.amax(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-101.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_host.getWorldState().rewards[0].getValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda2/envs/mine-env/lib/python2.7/site-packages/ipykernel/__main__.py:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=64, activation=\"relu\", input_dim=9)`\n",
      "/home/ubuntu/miniconda2/envs/mine-env/lib/python2.7/site-packages/ipykernel/__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=4, activation=\"linear\")`\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(9,len(ractions),ractions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Env(agent,agent_host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mission StartedWaiting for the mission to start ..... observed\n",
      "restarting world\n",
      "observed\n",
      "episode done\n",
      "observed\n",
      "episode done\n",
      "observed\n",
      "episode done\n",
      "observed\n",
      "episode done\n",
      "observed\n",
      "episode done\n",
      "observed\n",
      "episode done\n",
      "observed\n",
      "episode done\n",
      "observed\n",
      "episode done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-338f19e27333>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CliffWalking.xml\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-0af056064047>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, world, epochs)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;31m# get state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;31m# act\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env.run(\"CliffWalking.xml\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mine-env]",
   "language": "python",
   "name": "conda-env-mine-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
